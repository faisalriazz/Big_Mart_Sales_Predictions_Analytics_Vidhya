{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Mart Sales Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:54:14.087401Z",
     "start_time": "2020-12-05T11:54:14.084401Z"
    }
   },
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:58.829085Z",
     "start_time": "2020-12-05T19:58:56.321109Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:55:08.808846Z",
     "start_time": "2020-12-05T11:55:08.790857Z"
    }
   },
   "source": [
    "### importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:58.891114Z",
     "start_time": "2020-12-05T19:58:58.831095Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the test and train csv files\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:58.952901Z",
     "start_time": "2020-12-05T19:58:58.894092Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data exploration of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.062220Z",
     "start_time": "2020-12-05T19:58:58.955887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of train set are (8523, 12)\n",
      "dimension of test set are (5681, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dimension of train set are {}\\ndimension of test set are {}\\n'.format(train.shape,test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.170492Z",
     "start_time": "2020-12-05T19:58:59.065194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.296425Z",
     "start_time": "2020-12-05T19:58:59.173492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.857645</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>140.992782</td>\n",
       "      <td>1997.831867</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.643456</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>62.275067</td>\n",
       "      <td>8.371760</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.773750</td>\n",
       "      <td>0.026989</td>\n",
       "      <td>93.826500</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>143.012800</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.850000</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>185.643700</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  7060.000000      8523.000000  8523.000000                8523.000000   \n",
       "mean     12.857645         0.066132   140.992782                1997.831867   \n",
       "std       4.643456         0.051598    62.275067                   8.371760   \n",
       "min       4.555000         0.000000    31.290000                1985.000000   \n",
       "25%       8.773750         0.026989    93.826500                1987.000000   \n",
       "50%      12.600000         0.053931   143.012800                1999.000000   \n",
       "75%      16.850000         0.094585   185.643700                2004.000000   \n",
       "max      21.350000         0.328391   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.390300Z",
     "start_time": "2020-12-05T19:58:59.300423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.514725Z",
     "start_time": "2020-12-05T19:58:59.394301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape is (8523, 11)\n",
      "ytrain shape is (8523,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Extracting X and y from train dataset\n",
    "X = train.iloc[:,0:-1]\n",
    "y =train['Item_Outlet_Sales']\n",
    "print(\"Xtrain shape is {}\\nytrain shape is {}\\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.623843Z",
     "start_time": "2020-12-05T19:58:59.518728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "X['Outlet_Age']=X['Outlet_Establishment_Year'].max() - X['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.764145Z",
     "start_time": "2020-12-05T19:58:59.626135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Outlet_Age  \n",
       "0  Supermarket Type1          10  \n",
       "1  Supermarket Type2           0  \n",
       "2  Supermarket Type1          10  \n",
       "3      Grocery Store          11  \n",
       "4  Supermarket Type1          22  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:58:59.872836Z",
     "start_time": "2020-12-05T19:58:59.767146Z"
    }
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "X = X.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.026676Z",
     "start_time": "2020-12-05T19:58:59.874809Z"
    }
   },
   "outputs": [],
   "source": [
    "### Item visibilty of 0 does not make any sense so imputing these 0 values with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.229504Z",
     "start_time": "2020-12-05T19:59:00.029677Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Visibility']=X['Item_Visibility'].mask(X['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.367944Z",
     "start_time": "2020-12-05T19:59:00.231496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             1463\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          526\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             2410\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.477307Z",
     "start_time": "2020-12-05T19:59:00.370941Z"
    }
   },
   "outputs": [],
   "source": [
    "### missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.618404Z",
     "start_time": "2020-12-05T19:59:00.483271Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Weight'].fillna(X['Item_Weight'].mean(),inplace=True)\n",
    "X['Outlet_Size'].fillna(X['Outlet_Size'].mode()[0],inplace=True)\n",
    "X['Item_Visibility'].fillna(X['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.774483Z",
     "start_time": "2020-12-05T19:59:00.620381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             0\n",
       "Item_Fat_Content        0\n",
       "Item_Visibility         0\n",
       "Item_Type               0\n",
       "Item_MRP                0\n",
       "Outlet_Size             0\n",
       "Outlet_Location_Type    0\n",
       "Outlet_Type             0\n",
       "Outlet_Age              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:00.914813Z",
     "start_time": "2020-12-05T19:59:00.777488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5089\n",
       "Regular    2889\n",
       "LF          316\n",
       "reg         117\n",
       "low fat     112\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.055988Z",
     "start_time": "2020-12-05T19:59:00.917809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "X['Item_Fat_Content'] = X['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.240664Z",
     "start_time": "2020-12-05T19:59:01.057995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5517\n",
       "Regular    3006\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.395935Z",
     "start_time": "2020-12-05T19:59:01.243662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label encoding the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.520466Z",
     "start_time": "2020-12-05T19:59:01.398303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>4</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>14</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>10</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>6</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>9</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  Item_MRP  \\\n",
       "0         9.30                 0         0.016047          4  249.8092   \n",
       "1         5.92                 1         0.019278         14   48.2692   \n",
       "2        17.50                 0         0.016760         10  141.6180   \n",
       "3        19.20                 1         0.070482          6  182.0950   \n",
       "4         8.93                 0         0.070482          9   53.8614   \n",
       "\n",
       "   Outlet_Size  Outlet_Location_Type  Outlet_Type  Outlet_Age  \n",
       "0            1                     0            1          10  \n",
       "1            1                     2            2           0  \n",
       "2            1                     0            1          10  \n",
       "3            1                     2            0          11  \n",
       "4            0                     2            1          22  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "X['Item_Fat_Content']=label_encoder.fit_transform(X['Item_Fat_Content']) \n",
    "#,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "X['Outlet_Size']=label_encoder.fit_transform(X['Outlet_Size'])\n",
    "X['Outlet_Location_Type']=label_encoder.fit_transform(X['Outlet_Location_Type'])\n",
    "X['Outlet_Type']=label_encoder.fit_transform(X['Outlet_Type'])\n",
    "X['Item_Type']=label_encoder.fit_transform(X['Item_Type'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.692636Z",
     "start_time": "2020-12-05T19:59:01.528459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021157</td>\n",
       "      <td>-0.017763</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>-0.007225</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.008301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <td>-0.021157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>-0.139434</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>-0.017763</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035922</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>-0.179380</td>\n",
       "      <td>0.078316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Type</th>\n",
       "      <td>0.028015</td>\n",
       "      <td>-0.139434</td>\n",
       "      <td>-0.035922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>-0.004970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>-0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Size</th>\n",
       "      <td>-0.007225</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614311</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>-0.193389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <td>0.004088</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-0.614311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467219</td>\n",
       "      <td>0.089216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.179380</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>0.467219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Age</th>\n",
       "      <td>0.008301</td>\n",
       "      <td>-0.003151</td>\n",
       "      <td>0.078316</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.193389</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.122304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Item_Weight  Item_Fat_Content  Item_Visibility  \\\n",
       "Item_Weight              1.000000         -0.021157        -0.017763   \n",
       "Item_Fat_Content        -0.021157          1.000000         0.049915   \n",
       "Item_Visibility         -0.017763          0.049915         1.000000   \n",
       "Item_Type                0.028015         -0.139434        -0.035922   \n",
       "Item_MRP                 0.024756          0.006063        -0.005515   \n",
       "Outlet_Size             -0.007225         -0.000622         0.072297   \n",
       "Outlet_Location_Type     0.004088         -0.001598        -0.027742   \n",
       "Outlet_Type             -0.000566          0.002199        -0.179380   \n",
       "Outlet_Age               0.008301         -0.003151         0.078316   \n",
       "\n",
       "                      Item_Type  Item_MRP  Outlet_Size  Outlet_Location_Type  \\\n",
       "Item_Weight            0.028015  0.024756    -0.007225              0.004088   \n",
       "Item_Fat_Content      -0.139434  0.006063    -0.000622             -0.001598   \n",
       "Item_Visibility       -0.035922 -0.005515     0.072297             -0.027742   \n",
       "Item_Type              1.000000  0.032651    -0.001859              0.003084   \n",
       "Item_MRP               0.032651  1.000000     0.006059              0.000232   \n",
       "Outlet_Size           -0.001859  0.006059     1.000000             -0.614311   \n",
       "Outlet_Location_Type   0.003084  0.000232    -0.614311              1.000000   \n",
       "Outlet_Type            0.003053 -0.001975    -0.201483              0.467219   \n",
       "Outlet_Age            -0.004970 -0.005020    -0.193389              0.089216   \n",
       "\n",
       "                      Outlet_Type  Outlet_Age  \n",
       "Item_Weight             -0.000566    0.008301  \n",
       "Item_Fat_Content         0.002199   -0.003151  \n",
       "Item_Visibility         -0.179380    0.078316  \n",
       "Item_Type                0.003053   -0.004970  \n",
       "Item_MRP                -0.001975   -0.005020  \n",
       "Outlet_Size             -0.201483   -0.193389  \n",
       "Outlet_Location_Type     0.467219    0.089216  \n",
       "Outlet_Type              1.000000    0.122304  \n",
       "Outlet_Age               0.122304    1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking correlation to check if there is any highly correlated variable\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:01.878888Z",
     "start_time": "2020-12-05T19:59:01.695632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (8523, 9) \n",
      "y shape is (8523,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape is {} \\ny shape is {} \\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:02.051625Z",
     "start_time": "2020-12-05T19:59:01.880854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28252456, 0.        , 0.03839895, 0.26666667, 0.92750715,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.08127419, 1.        , 0.04834585, 0.93333333, 0.0720684 ,\n",
       "        0.5       , 1.        , 0.66666667, 0.        ],\n",
       "       [0.77076511, 0.        , 0.04059334, 0.66666667, 0.46828841,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.87198571, 1.        , 0.20598459, 0.4       , 0.64009348,\n",
       "        0.5       , 1.        , 0.        , 0.45833333],\n",
       "       [0.26049419, 0.        , 0.20598459, 0.6       , 0.09580456,\n",
       "        0.        , 1.        , 0.33333333, 0.91666667]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the X from 0 to 1 using MinMaxScalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X=min_max_scaler.fit_transform(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:02.175976Z",
     "start_time": "2020-12-05T19:59:02.054623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5966, 9) (5966,)\n",
      "(2557, 9) (2557,)\n"
     ]
    }
   ],
   "source": [
    "# Test Train split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y, test_size = 0.3 ,shuffle = True,random_state =0)\n",
    "print(X_train.shape,y_train.shape);print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:05.071663Z",
     "start_time": "2020-12-05T19:59:02.178973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building the Model using Keras\n",
    "from keras.models import Sequential\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense , Dropout\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:05.086657Z",
     "start_time": "2020-12-05T19:59:05.074662Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the input and output neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:05.226628Z",
     "start_time": "2020-12-05T19:59:05.091651Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(InputLayer(input_shape=(input_neurons,)))\n",
    "# model.add(Dense(units=500,activation='relu',name='Input_Layer1'))\n",
    "# model.add(Dense(units=100,activation='relu',name='hidden_Layer1'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(units=50,activation='relu',name='hidden_Layer2'))\n",
    "# model.add(Dense(units=output_neurons,activation='linear',name ='output_Layer'))\n",
    "# model.compile(loss= \"MSE\" , optimizer=\"RMSprop\", metrics=[\"MAE\"])\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:05.493460Z",
     "start_time": "2020-12-05T19:59:05.229626Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(input_neurons,)))\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dense(units=32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=output_neurons,activation='linear'))\n",
    "learning_rate = 0.01\n",
    "opt=RMSprop(lr=learning_rate)\n",
    "#model.compile(loss='MSE', optimizer='Adam',metrics=['MAE'])\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:27.879547Z",
     "start_time": "2020-12-05T19:59:05.496459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5966 samples, validate on 2557 samples\n",
      "Epoch 1/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 7486778.4252 - mae: 2153.1025 - val_loss: 7594828.8483 - val_mae: 2136.9651\n",
      "Epoch 2/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 6603327.8550 - mae: 1955.5461 - val_loss: 5673021.0264 - val_mae: 1739.1353\n",
      "Epoch 3/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 4339053.1062 - mae: 1495.5557 - val_loss: 3259281.9106 - val_mae: 1326.5742\n",
      "Epoch 4/500\n",
      "5966/5966 [==============================] - 0s 9us/step - loss: 2781475.5567 - mae: 1252.7629 - val_loss: 2710913.9004 - val_mae: 1295.1969\n",
      "Epoch 5/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2612109.6078 - mae: 1259.1437 - val_loss: 2652591.4048 - val_mae: 1279.7847\n",
      "Epoch 6/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2531191.3200 - mae: 1242.6748 - val_loss: 2571869.8092 - val_mae: 1270.7684\n",
      "Epoch 7/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2484609.2454 - mae: 1229.7830 - val_loss: 2505769.1173 - val_mae: 1232.3925\n",
      "Epoch 8/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2358793.8993 - mae: 1196.7427 - val_loss: 2363888.5389 - val_mae: 1226.6193\n",
      "Epoch 9/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2247219.4307 - mae: 1169.2646 - val_loss: 2226878.3155 - val_mae: 1168.9435\n",
      "Epoch 10/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 2073463.0976 - mae: 1125.0210 - val_loss: 2061760.2906 - val_mae: 1107.6997\n",
      "Epoch 11/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1933693.0335 - mae: 1071.8090 - val_loss: 1867498.1736 - val_mae: 1083.7950\n",
      "Epoch 12/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1800797.3866 - mae: 1028.3063 - val_loss: 1763002.7833 - val_mae: 1023.1533\n",
      "Epoch 13/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1686846.1420 - mae: 982.9449 - val_loss: 1673179.1999 - val_mae: 1021.1295\n",
      "Epoch 14/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1614379.6969 - mae: 948.4958 - val_loss: 1633834.7156 - val_mae: 942.5112\n",
      "Epoch 15/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1578667.3996 - mae: 930.7870 - val_loss: 1636941.7154 - val_mae: 930.8960\n",
      "Epoch 16/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1536004.2033 - mae: 906.9041 - val_loss: 1530541.3574 - val_mae: 919.5754\n",
      "Epoch 17/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1498222.1270 - mae: 900.1101 - val_loss: 1515366.5194 - val_mae: 940.4474\n",
      "Epoch 18/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1561413.4842 - mae: 913.1550 - val_loss: 1508711.9351 - val_mae: 911.1676\n",
      "Epoch 19/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1488320.9446 - mae: 889.6806 - val_loss: 1519865.8901 - val_mae: 943.4233\n",
      "Epoch 20/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1542536.2004 - mae: 907.2094 - val_loss: 1490917.3460 - val_mae: 908.6194\n",
      "Epoch 21/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1496916.4259 - mae: 892.2644 - val_loss: 1482667.4845 - val_mae: 919.3727\n",
      "Epoch 22/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1498753.1171 - mae: 895.1234 - val_loss: 1619055.5131 - val_mae: 921.9017\n",
      "Epoch 23/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1568293.0392 - mae: 910.2656 - val_loss: 1487927.1808 - val_mae: 904.8895\n",
      "Epoch 24/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1478685.9585 - mae: 886.8791 - val_loss: 1475011.9955 - val_mae: 914.3436\n",
      "Epoch 25/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1461977.7811 - mae: 888.2588 - val_loss: 1523327.6558 - val_mae: 904.4135\n",
      "Epoch 26/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1544466.3639 - mae: 904.7114 - val_loss: 1549762.6417 - val_mae: 907.4630\n",
      "Epoch 27/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1487986.9562 - mae: 892.2702 - val_loss: 1519750.5893 - val_mae: 903.3322\n",
      "Epoch 28/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1451286.5452 - mae: 881.4713 - val_loss: 1467771.5267 - val_mae: 907.8002\n",
      "Epoch 29/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1479981.5521 - mae: 891.1091 - val_loss: 1474327.8510 - val_mae: 917.5577\n",
      "Epoch 30/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1485787.6985 - mae: 892.2226 - val_loss: 1558046.1896 - val_mae: 907.5375\n",
      "Epoch 31/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1468940.2503 - mae: 884.8765 - val_loss: 1467108.6181 - val_mae: 911.9982\n",
      "Epoch 32/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1554633.3064 - mae: 907.6781 - val_loss: 1464564.7775 - val_mae: 904.2565\n",
      "Epoch 33/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1483488.2763 - mae: 891.1633 - val_loss: 1485040.7468 - val_mae: 898.6165\n",
      "Epoch 34/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1446750.9817 - mae: 874.5038 - val_loss: 1525567.5279 - val_mae: 900.8011\n",
      "Epoch 35/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1476688.0629 - mae: 883.1685 - val_loss: 1476214.2086 - val_mae: 921.7280\n",
      "Epoch 36/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1458369.5458 - mae: 878.6500 - val_loss: 1455479.2661 - val_mae: 900.4500\n",
      "Epoch 37/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1548160.2958 - mae: 906.3438 - val_loss: 1455183.3764 - val_mae: 898.5044\n",
      "Epoch 38/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1452034.5905 - mae: 877.9649 - val_loss: 1462529.9101 - val_mae: 894.0399\n",
      "Epoch 39/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1500704.8921 - mae: 887.6101 - val_loss: 1473585.8482 - val_mae: 921.9652\n",
      "Epoch 40/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1453030.7107 - mae: 882.1716 - val_loss: 1461235.6996 - val_mae: 892.1207\n",
      "Epoch 41/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1486784.5213 - mae: 887.8318 - val_loss: 1531604.7886 - val_mae: 897.4812\n",
      "Epoch 42/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1452032.5530 - mae: 873.8706 - val_loss: 1442272.7898 - val_mae: 897.7264\n",
      "Epoch 43/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1461982.2064 - mae: 879.9821 - val_loss: 1441812.6264 - val_mae: 901.6563\n",
      "Epoch 44/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1464270.3282 - mae: 879.8444 - val_loss: 1448396.5086 - val_mae: 909.4938\n",
      "Epoch 45/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1470159.8411 - mae: 883.2910 - val_loss: 1457931.6608 - val_mae: 885.2857\n",
      "Epoch 46/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1457202.6317 - mae: 874.4525 - val_loss: 1453783.8920 - val_mae: 883.6413\n",
      "Epoch 47/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1403200.5207 - mae: 860.9468 - val_loss: 1440516.0549 - val_mae: 881.5221\n",
      "Epoch 48/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1459942.7402 - mae: 879.8399 - val_loss: 1542520.3456 - val_mae: 892.8242\n",
      "Epoch 49/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1445866.7241 - mae: 869.9367 - val_loss: 1418476.5880 - val_mae: 890.6764\n",
      "Epoch 50/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1443136.8708 - mae: 870.3320 - val_loss: 1411415.7285 - val_mae: 884.3732\n",
      "Epoch 51/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1479064.1580 - mae: 876.6617 - val_loss: 1426209.5409 - val_mae: 899.9695\n",
      "Epoch 52/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1426442.4111 - mae: 864.5944 - val_loss: 1407604.0465 - val_mae: 877.0765\n",
      "Epoch 53/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1464305.2769 - mae: 879.4158 - val_loss: 1484634.0572 - val_mae: 877.8358\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 7us/step - loss: 1409081.9197 - mae: 859.9857 - val_loss: 1399124.7695 - val_mae: 876.4515\n",
      "Epoch 55/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1412902.3008 - mae: 858.0141 - val_loss: 1436744.1553 - val_mae: 907.2858\n",
      "Epoch 56/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1470380.3185 - mae: 883.0613 - val_loss: 1400619.1586 - val_mae: 886.1746\n",
      "Epoch 57/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1423841.7057 - mae: 859.9874 - val_loss: 1394114.1528 - val_mae: 881.5414\n",
      "Epoch 58/500\n",
      "5966/5966 [==============================] - 0s 5us/step - loss: 1409253.2851 - mae: 859.7702 - val_loss: 1386498.0919 - val_mae: 874.0625\n",
      "Epoch 59/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1397449.8403 - mae: 853.5849 - val_loss: 1381792.5329 - val_mae: 869.7459\n",
      "Epoch 60/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1381970.4311 - mae: 849.8668 - val_loss: 1388618.0026 - val_mae: 859.6567\n",
      "Epoch 61/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1473796.9258 - mae: 875.2084 - val_loss: 1380890.3037 - val_mae: 860.9548\n",
      "Epoch 62/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1393036.8149 - mae: 848.3033 - val_loss: 1373740.9369 - val_mae: 861.5239\n",
      "Epoch 63/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1384271.4325 - mae: 848.9283 - val_loss: 1405797.5826 - val_mae: 892.1783\n",
      "Epoch 64/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1452447.1722 - mae: 869.4344 - val_loss: 1370037.0121 - val_mae: 869.4107\n",
      "Epoch 65/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1379067.2337 - mae: 846.9139 - val_loss: 1363968.0712 - val_mae: 855.8108\n",
      "Epoch 66/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1394346.5585 - mae: 856.2216 - val_loss: 1461976.4592 - val_mae: 861.2724\n",
      "Epoch 67/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1398506.6995 - mae: 845.5602 - val_loss: 1391474.9353 - val_mae: 886.0369\n",
      "Epoch 68/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1392647.1202 - mae: 850.2078 - val_loss: 1357850.3601 - val_mae: 862.1967\n",
      "Epoch 69/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1399390.4203 - mae: 850.4524 - val_loss: 1365348.8624 - val_mae: 870.6352\n",
      "Epoch 70/500\n",
      "5966/5966 [==============================] - 0s 5us/step - loss: 1366931.6395 - mae: 841.4470 - val_loss: 1349244.4733 - val_mae: 849.4434\n",
      "Epoch 71/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1378014.1528 - mae: 848.6593 - val_loss: 1452203.0050 - val_mae: 855.6862\n",
      "Epoch 72/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1409531.3726 - mae: 852.1693 - val_loss: 1404357.4887 - val_mae: 846.9551\n",
      "Epoch 73/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1367527.1988 - mae: 836.7324 - val_loss: 1340196.1963 - val_mae: 850.1255\n",
      "Epoch 74/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1395517.4833 - mae: 845.6899 - val_loss: 1341534.1327 - val_mae: 854.2838\n",
      "Epoch 75/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1374402.8152 - mae: 842.1060 - val_loss: 1336243.9158 - val_mae: 848.2256\n",
      "Epoch 76/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1361266.3348 - mae: 839.2684 - val_loss: 1365967.6350 - val_mae: 840.3070\n",
      "Epoch 77/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1396414.5554 - mae: 848.0355 - val_loss: 1377239.1545 - val_mae: 840.1631\n",
      "Epoch 78/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1340741.9890 - mae: 829.8263 - val_loss: 1425982.3150 - val_mae: 847.0195\n",
      "Epoch 79/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1401560.9531 - mae: 848.3537 - val_loss: 1386801.0747 - val_mae: 839.9337\n",
      "Epoch 80/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1371138.7448 - mae: 841.4608 - val_loss: 1341242.4305 - val_mae: 836.2671\n",
      "Epoch 81/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1337585.3700 - mae: 831.6349 - val_loss: 1412187.9424 - val_mae: 843.1273\n",
      "Epoch 82/500\n",
      "5966/5966 [==============================] - 0s 5us/step - loss: 1360067.3075 - mae: 835.0360 - val_loss: 1360254.3918 - val_mae: 834.9103\n",
      "Epoch 83/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1388152.1700 - mae: 838.8320 - val_loss: 1386164.0538 - val_mae: 837.3119\n",
      "Epoch 84/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1336945.2856 - mae: 828.6047 - val_loss: 1375154.7230 - val_mae: 835.0372\n",
      "Epoch 85/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1364624.9431 - mae: 835.8439 - val_loss: 1360016.4908 - val_mae: 833.1033\n",
      "Epoch 86/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1334320.5663 - mae: 830.6846 - val_loss: 1475926.0613 - val_mae: 854.1532\n",
      "Epoch 87/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1400412.2971 - mae: 841.9820 - val_loss: 1338448.0162 - val_mae: 831.1137\n",
      "Epoch 88/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1361098.9237 - mae: 831.9529 - val_loss: 1325424.5131 - val_mae: 830.5026\n",
      "Epoch 89/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1349256.4149 - mae: 829.7747 - val_loss: 1385396.6905 - val_mae: 834.7710\n",
      "Epoch 90/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1378247.3243 - mae: 840.6335 - val_loss: 1343458.3363 - val_mae: 829.3810\n",
      "Epoch 91/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1365020.4482 - mae: 831.1318 - val_loss: 1384025.3115 - val_mae: 834.4236\n",
      "Epoch 92/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1338444.4456 - mae: 825.5776 - val_loss: 1314701.3628 - val_mae: 829.3870\n",
      "Epoch 93/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1378220.4269 - mae: 833.7639 - val_loss: 1318242.9885 - val_mae: 827.6807\n",
      "Epoch 94/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1336098.9336 - mae: 824.1191 - val_loss: 1311058.2803 - val_mae: 828.6064\n",
      "Epoch 95/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1332620.6786 - mae: 826.0302 - val_loss: 1417334.7997 - val_mae: 839.3094\n",
      "Epoch 96/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1365609.2057 - mae: 833.3741 - val_loss: 1407916.3214 - val_mae: 837.2498\n",
      "Epoch 97/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1348734.5357 - mae: 832.7947 - val_loss: 1321180.4342 - val_mae: 824.3793\n",
      "Epoch 98/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1321007.9657 - mae: 818.9075 - val_loss: 1339328.9631 - val_mae: 824.9224\n",
      "Epoch 99/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1390071.2179 - mae: 840.2390 - val_loss: 1406574.4124 - val_mae: 836.3226\n",
      "Epoch 100/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1320242.7767 - mae: 822.1913 - val_loss: 1309941.8815 - val_mae: 823.3268\n",
      "Epoch 101/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1314122.4677 - mae: 816.8450 - val_loss: 1358021.0981 - val_mae: 827.4087\n",
      "Epoch 102/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1324055.1938 - mae: 822.8864 - val_loss: 1586382.3222 - val_mae: 879.8830\n",
      "Epoch 103/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1376123.3100 - mae: 834.4766 - val_loss: 1330963.1972 - val_mae: 822.6935\n",
      "Epoch 104/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1346041.7720 - mae: 829.7257 - val_loss: 1363442.2738 - val_mae: 826.7830\n",
      "Epoch 105/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1318003.6139 - mae: 819.4974 - val_loss: 1300360.9334 - val_mae: 822.4987\n",
      "Epoch 106/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1328859.3268 - mae: 824.6400 - val_loss: 1298107.3992 - val_mae: 834.2593\n",
      "Epoch 107/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1328236.7788 - mae: 822.7839 - val_loss: 1409945.0970 - val_mae: 835.1308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1353622.5308 - mae: 828.3555 - val_loss: 1313504.5241 - val_mae: 819.8856\n",
      "Epoch 109/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1301595.4424 - mae: 816.4363 - val_loss: 1332877.9209 - val_mae: 820.5156\n",
      "Epoch 110/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1345917.9056 - mae: 826.9371 - val_loss: 1304474.6128 - val_mae: 818.4105\n",
      "Epoch 111/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1319922.9325 - mae: 818.6936 - val_loss: 1335026.8193 - val_mae: 858.7214\n",
      "Epoch 112/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1366017.7938 - mae: 837.8594 - val_loss: 1305191.8180 - val_mae: 841.0682\n",
      "Epoch 113/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1326034.4888 - mae: 825.9587 - val_loss: 1311090.9190 - val_mae: 817.4044\n",
      "Epoch 114/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1293917.2616 - mae: 811.1934 - val_loss: 1308394.6127 - val_mae: 817.2038\n",
      "Epoch 115/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1323069.4089 - mae: 820.4244 - val_loss: 1536626.4433 - val_mae: 864.9438\n",
      "Epoch 116/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1358980.5461 - mae: 829.4402 - val_loss: 1319823.8220 - val_mae: 817.1490\n",
      "Epoch 117/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1333287.3905 - mae: 817.5162 - val_loss: 1321429.5883 - val_mae: 850.7379\n",
      "Epoch 118/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1333602.2001 - mae: 822.1363 - val_loss: 1294547.9763 - val_mae: 815.6006\n",
      "Epoch 119/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1333928.9404 - mae: 820.4088 - val_loss: 1347948.6812 - val_mae: 864.8413\n",
      "Epoch 120/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1318260.3674 - mae: 820.0490 - val_loss: 1296419.5881 - val_mae: 815.0136\n",
      "Epoch 121/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1300635.0383 - mae: 811.6312 - val_loss: 1376124.4827 - val_mae: 877.4197\n",
      "Epoch 122/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1393606.4628 - mae: 844.2029 - val_loss: 1302749.3945 - val_mae: 813.8415\n",
      "Epoch 123/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1295036.7218 - mae: 814.7127 - val_loss: 1319086.3786 - val_mae: 815.6683\n",
      "Epoch 124/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1300351.0317 - mae: 813.0339 - val_loss: 1389691.0045 - val_mae: 827.8071\n",
      "Epoch 125/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1313819.9722 - mae: 812.6739 - val_loss: 1316853.7629 - val_mae: 814.0873\n",
      "Epoch 126/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1341011.9108 - mae: 823.3854 - val_loss: 1310633.1517 - val_mae: 814.2258\n",
      "Epoch 127/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1295903.1917 - mae: 805.3362 - val_loss: 1278215.1592 - val_mae: 821.5305\n",
      "Epoch 128/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1289912.8765 - mae: 811.4521 - val_loss: 1398598.2152 - val_mae: 829.6215\n",
      "Epoch 129/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1368269.7581 - mae: 835.0389 - val_loss: 1301495.0919 - val_mae: 812.4934\n",
      "Epoch 130/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1301523.8635 - mae: 813.4247 - val_loss: 1275157.0047 - val_mae: 816.1640\n",
      "Epoch 131/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1302257.8973 - mae: 809.4227 - val_loss: 1329619.9067 - val_mae: 814.6846\n",
      "Epoch 132/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1314211.9826 - mae: 812.5737 - val_loss: 1283293.1692 - val_mae: 828.5822\n",
      "Epoch 133/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1335855.4138 - mae: 822.0089 - val_loss: 1280577.8844 - val_mae: 826.7339\n",
      "Epoch 134/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1360819.4535 - mae: 829.6556 - val_loss: 1276982.7344 - val_mae: 812.7780\n",
      "Epoch 135/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1302715.3666 - mae: 811.1986 - val_loss: 1274771.6988 - val_mae: 819.6575\n",
      "Epoch 136/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1365789.8618 - mae: 831.9847 - val_loss: 1281132.8264 - val_mae: 811.5887\n",
      "Epoch 137/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1296837.4903 - mae: 811.1719 - val_loss: 1302454.2478 - val_mae: 841.4756\n",
      "Epoch 138/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1318767.0942 - mae: 817.9422 - val_loss: 1268946.0544 - val_mae: 813.9471\n",
      "Epoch 139/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1289721.7260 - mae: 809.9759 - val_loss: 1286102.4151 - val_mae: 809.1954\n",
      "Epoch 140/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1328493.3901 - mae: 816.7776 - val_loss: 1414940.6164 - val_mae: 832.0080\n",
      "Epoch 141/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1321221.4419 - mae: 815.4155 - val_loss: 1279449.0264 - val_mae: 808.2651\n",
      "Epoch 142/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1314891.0131 - mae: 816.8580 - val_loss: 1300668.9319 - val_mae: 808.7949\n",
      "Epoch 143/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1314671.3486 - mae: 819.5662 - val_loss: 1448208.0734 - val_mae: 840.5895\n",
      "Epoch 144/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1332952.3023 - mae: 816.7507 - val_loss: 1308104.4302 - val_mae: 809.9492\n",
      "Epoch 145/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1327434.6155 - mae: 819.3411 - val_loss: 1364002.1316 - val_mae: 819.6617\n",
      "Epoch 146/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1311254.9058 - mae: 808.8070 - val_loss: 1303713.7033 - val_mae: 808.4822\n",
      "Epoch 147/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1310618.5561 - mae: 813.4771 - val_loss: 1481587.5489 - val_mae: 848.8955\n",
      "Epoch 148/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1338702.9047 - mae: 814.0295 - val_loss: 1269476.7932 - val_mae: 807.1818\n",
      "Epoch 149/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1323865.5114 - mae: 817.0883 - val_loss: 1263840.3877 - val_mae: 809.6233\n",
      "Epoch 150/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1298875.7694 - mae: 810.0483 - val_loss: 1353981.2513 - val_mae: 817.5522\n",
      "Epoch 151/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1296151.3793 - mae: 809.8151 - val_loss: 1292374.6919 - val_mae: 808.2764\n",
      "Epoch 152/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1339905.3255 - mae: 822.2938 - val_loss: 1265012.8621 - val_mae: 813.2563\n",
      "Epoch 153/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1295149.3463 - mae: 809.0656 - val_loss: 1265813.3672 - val_mae: 816.5567\n",
      "Epoch 154/500\n",
      "5966/5966 [==============================] - 0s 9us/step - loss: 1329231.5347 - mae: 820.9448 - val_loss: 1283816.7475 - val_mae: 831.8207\n",
      "Epoch 155/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1302660.3150 - mae: 813.8883 - val_loss: 1262400.6208 - val_mae: 812.4684\n",
      "Epoch 156/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1296560.5017 - mae: 807.2628 - val_loss: 1263962.1897 - val_mae: 815.3199\n",
      "Epoch 157/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1314528.7846 - mae: 809.8228 - val_loss: 1299438.2534 - val_mae: 841.3996\n",
      "Epoch 158/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1320268.3198 - mae: 820.0026 - val_loss: 1260573.0035 - val_mae: 813.3467\n",
      "Epoch 159/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1292703.8731 - mae: 808.0040 - val_loss: 1402665.1713 - val_mae: 828.0779\n",
      "Epoch 160/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1288376.9060 - mae: 807.1284 - val_loss: 1314117.9570 - val_mae: 809.3885\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 6us/step - loss: 1303650.9726 - mae: 810.6448 - val_loss: 1313995.9554 - val_mae: 809.1254\n",
      "Epoch 162/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1289535.0049 - mae: 802.7715 - val_loss: 1322152.3014 - val_mae: 853.9865\n",
      "Epoch 163/500\n",
      "5966/5966 [==============================] - 0s 5us/step - loss: 1338543.8732 - mae: 821.9586 - val_loss: 1258547.1294 - val_mae: 814.8071\n",
      "Epoch 164/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1272407.1002 - mae: 802.3850 - val_loss: 1262661.9566 - val_mae: 805.8727\n",
      "Epoch 165/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1319542.9940 - mae: 815.5859 - val_loss: 1270064.0704 - val_mae: 824.6051\n",
      "Epoch 166/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1279408.6664 - mae: 808.4517 - val_loss: 1296497.8199 - val_mae: 806.0754\n",
      "Epoch 167/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1302102.9480 - mae: 807.4706 - val_loss: 1328048.3054 - val_mae: 810.6949\n",
      "Epoch 168/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1308720.9318 - mae: 812.2076 - val_loss: 1316550.5814 - val_mae: 808.2382\n",
      "Epoch 169/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1344784.2762 - mae: 827.0231 - val_loss: 1360705.4075 - val_mae: 817.4854\n",
      "Epoch 170/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1277159.3080 - mae: 805.5699 - val_loss: 1284847.4288 - val_mae: 803.3506\n",
      "Epoch 171/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1271340.5342 - mae: 799.2969 - val_loss: 1385331.8602 - val_mae: 823.7186\n",
      "Epoch 172/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1331476.4481 - mae: 817.3075 - val_loss: 1288789.3428 - val_mae: 804.0684\n",
      "Epoch 173/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1276473.0569 - mae: 801.7387 - val_loss: 1273214.0753 - val_mae: 827.3379\n",
      "Epoch 174/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1315420.3617 - mae: 815.7266 - val_loss: 1295527.0792 - val_mae: 805.1523\n",
      "Epoch 175/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1329553.0267 - mae: 812.9785 - val_loss: 1253850.7238 - val_mae: 805.1519\n",
      "Epoch 176/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1252847.4668 - mae: 795.8574 - val_loss: 1291909.9806 - val_mae: 803.5085\n",
      "Epoch 177/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1312016.8553 - mae: 815.7050 - val_loss: 1377865.8917 - val_mae: 821.5981\n",
      "Epoch 178/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1261932.6302 - mae: 798.8189 - val_loss: 1300442.2272 - val_mae: 804.9042\n",
      "Epoch 179/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1274081.8230 - mae: 800.7237 - val_loss: 1290604.1545 - val_mae: 802.6318\n",
      "Epoch 180/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1294649.8816 - mae: 807.2666 - val_loss: 1473841.7363 - val_mae: 845.8421\n",
      "Epoch 181/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1291751.1148 - mae: 805.1045 - val_loss: 1267815.8871 - val_mae: 799.7455\n",
      "Epoch 182/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1254415.3230 - mae: 795.3035 - val_loss: 1265486.5873 - val_mae: 802.1398\n",
      "Epoch 183/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1256943.7577 - mae: 797.6317 - val_loss: 1537406.1512 - val_mae: 864.2930\n",
      "Epoch 184/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1363184.4459 - mae: 829.8159 - val_loss: 1296677.9737 - val_mae: 804.3830\n",
      "Epoch 185/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1296104.3376 - mae: 810.4023 - val_loss: 1279098.2796 - val_mae: 801.2319\n",
      "Epoch 186/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1263780.4333 - mae: 795.6260 - val_loss: 1253398.3062 - val_mae: 799.0861\n",
      "Epoch 187/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1317562.3378 - mae: 818.4418 - val_loss: 1412321.0442 - val_mae: 829.7693\n",
      "Epoch 188/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1255081.7695 - mae: 794.7592 - val_loss: 1256496.7257 - val_mae: 797.8207\n",
      "Epoch 189/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1267341.4598 - mae: 799.0948 - val_loss: 1245832.0693 - val_mae: 810.3188\n",
      "Epoch 190/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1289953.2189 - mae: 808.8035 - val_loss: 1247904.2101 - val_mae: 809.2866\n",
      "Epoch 191/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1299500.1077 - mae: 808.9965 - val_loss: 1241233.4813 - val_mae: 800.4662\n",
      "Epoch 192/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1270359.5396 - mae: 802.7686 - val_loss: 1247931.2281 - val_mae: 812.5074\n",
      "Epoch 193/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1314538.7373 - mae: 814.4320 - val_loss: 1293581.6376 - val_mae: 802.1948\n",
      "Epoch 194/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1243603.1625 - mae: 789.6619 - val_loss: 1300233.7100 - val_mae: 844.8536\n",
      "Epoch 195/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1317791.7961 - mae: 816.9276 - val_loss: 1257012.2147 - val_mae: 819.3707\n",
      "Epoch 196/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1273569.8519 - mae: 801.2380 - val_loss: 1245650.3741 - val_mae: 810.7840\n",
      "Epoch 197/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1294449.7718 - mae: 809.2057 - val_loss: 1401980.6693 - val_mae: 826.6714\n",
      "Epoch 198/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1249196.7249 - mae: 796.7141 - val_loss: 1326943.3977 - val_mae: 808.2352\n",
      "Epoch 199/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1319027.6478 - mae: 814.5579 - val_loss: 1280829.9306 - val_mae: 799.6945\n",
      "Epoch 200/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1280661.3345 - mae: 800.5406 - val_loss: 1264682.1031 - val_mae: 797.1332\n",
      "Epoch 201/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1251070.9053 - mae: 790.8979 - val_loss: 1277824.0170 - val_mae: 799.2051\n",
      "Epoch 202/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1340269.3976 - mae: 820.2166 - val_loss: 1343186.8789 - val_mae: 811.6451\n",
      "Epoch 203/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1292950.7058 - mae: 806.4259 - val_loss: 1339784.5211 - val_mae: 811.0773\n",
      "Epoch 204/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1274325.9640 - mae: 800.6676 - val_loss: 1242687.9883 - val_mae: 794.9050\n",
      "Epoch 205/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1293781.0376 - mae: 807.3127 - val_loss: 1248993.8407 - val_mae: 814.7007\n",
      "Epoch 206/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1269682.0295 - mae: 797.2831 - val_loss: 1246907.0592 - val_mae: 796.0380\n",
      "Epoch 207/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1224047.4749 - mae: 787.6812 - val_loss: 1328959.1656 - val_mae: 855.9961\n",
      "Epoch 208/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1347579.3613 - mae: 823.7134 - val_loss: 1235755.2162 - val_mae: 800.1410\n",
      "Epoch 209/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1258105.2373 - mae: 793.2024 - val_loss: 1249610.3860 - val_mae: 795.2516\n",
      "Epoch 210/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1299463.6785 - mae: 805.9318 - val_loss: 1482666.1267 - val_mae: 848.4068\n",
      "Epoch 211/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1295155.2782 - mae: 808.3819 - val_loss: 1276568.9290 - val_mae: 797.4043\n",
      "Epoch 212/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1267650.1917 - mae: 798.7253 - val_loss: 1340072.1184 - val_mae: 811.5688\n",
      "Epoch 213/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1275472.7587 - mae: 799.3609 - val_loss: 1312028.9683 - val_mae: 804.7231\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 7us/step - loss: 1313032.9165 - mae: 813.2963 - val_loss: 1321779.7153 - val_mae: 807.5547\n",
      "Epoch 215/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1278975.9342 - mae: 801.8312 - val_loss: 1309460.9096 - val_mae: 804.1133\n",
      "Epoch 216/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1255976.4217 - mae: 794.0788 - val_loss: 1237205.0062 - val_mae: 804.5848\n",
      "Epoch 217/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1267115.5582 - mae: 800.6145 - val_loss: 1264071.0923 - val_mae: 824.4907\n",
      "Epoch 218/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1299156.5763 - mae: 808.6276 - val_loss: 1261410.2888 - val_mae: 823.6405\n",
      "Epoch 219/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1253501.9147 - mae: 797.6509 - val_loss: 1232955.7685 - val_mae: 797.8163\n",
      "Epoch 220/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1263270.3998 - mae: 799.1832 - val_loss: 1240639.0609 - val_mae: 795.2391\n",
      "Epoch 221/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1242813.0103 - mae: 792.5500 - val_loss: 1240804.4493 - val_mae: 794.7582\n",
      "Epoch 222/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1330278.8925 - mae: 818.8467 - val_loss: 1309200.7717 - val_mae: 804.4151\n",
      "Epoch 223/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1262869.4154 - mae: 795.5512 - val_loss: 1285396.9574 - val_mae: 798.9940\n",
      "Epoch 224/500\n",
      "5966/5966 [==============================] - 0s 9us/step - loss: 1261368.0867 - mae: 800.2365 - val_loss: 1280778.4269 - val_mae: 797.6519\n",
      "Epoch 225/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1259963.7695 - mae: 799.8297 - val_loss: 1426193.2371 - val_mae: 832.6529\n",
      "Epoch 226/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1302080.8760 - mae: 813.5294 - val_loss: 1356282.5729 - val_mae: 814.0498\n",
      "Epoch 227/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1298670.5916 - mae: 804.4077 - val_loss: 1233853.3458 - val_mae: 799.6190\n",
      "Epoch 228/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1265286.6621 - mae: 798.1170 - val_loss: 1233484.3964 - val_mae: 804.8835\n",
      "Epoch 229/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1248754.3904 - mae: 792.5541 - val_loss: 1238078.8634 - val_mae: 807.2335\n",
      "Epoch 230/500\n",
      "5966/5966 [==============================] - 0s 9us/step - loss: 1292640.8395 - mae: 803.6588 - val_loss: 1235613.4987 - val_mae: 805.8405\n",
      "Epoch 231/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1270932.2446 - mae: 799.3004 - val_loss: 1236101.9125 - val_mae: 804.8665\n",
      "Epoch 232/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1241514.0915 - mae: 790.5223 - val_loss: 1318531.1512 - val_mae: 806.8905\n",
      "Epoch 233/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1307693.2843 - mae: 813.0471 - val_loss: 1250725.6729 - val_mae: 795.8384\n",
      "Epoch 234/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1262110.4784 - mae: 792.4284 - val_loss: 1235018.7140 - val_mae: 804.6853\n",
      "Epoch 235/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1268288.0694 - mae: 800.5829 - val_loss: 1229421.3175 - val_mae: 795.7922\n",
      "Epoch 236/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1288507.3499 - mae: 807.2781 - val_loss: 1251967.1677 - val_mae: 818.0736\n",
      "Epoch 237/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1245493.3480 - mae: 793.7147 - val_loss: 1256705.3319 - val_mae: 793.2281\n",
      "Epoch 238/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1272820.8145 - mae: 798.3448 - val_loss: 1238231.1581 - val_mae: 793.0812\n",
      "Epoch 239/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1244145.1886 - mae: 795.1357 - val_loss: 1416612.1463 - val_mae: 830.2852\n",
      "Epoch 240/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1283807.6243 - mae: 798.6556 - val_loss: 1287791.1879 - val_mae: 798.3862\n",
      "Epoch 241/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1242183.1669 - mae: 791.2111 - val_loss: 1239600.8678 - val_mae: 791.9324\n",
      "Epoch 242/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1296981.2075 - mae: 805.6045 - val_loss: 1231539.4790 - val_mae: 801.1611\n",
      "Epoch 243/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1256714.3662 - mae: 794.7908 - val_loss: 1262481.6098 - val_mae: 793.8000\n",
      "Epoch 244/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1245946.2037 - mae: 789.7015 - val_loss: 1233939.4742 - val_mae: 792.0944\n",
      "Epoch 245/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1268082.1602 - mae: 795.0921 - val_loss: 1243633.9681 - val_mae: 811.3609\n",
      "Epoch 246/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1263704.6022 - mae: 801.3075 - val_loss: 1330325.1805 - val_mae: 807.0272\n",
      "Epoch 247/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1289377.4917 - mae: 801.3859 - val_loss: 1385725.2355 - val_mae: 821.0724\n",
      "Epoch 248/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1238053.0887 - mae: 790.6793 - val_loss: 1233877.1319 - val_mae: 795.4596\n",
      "Epoch 249/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1219446.1470 - mae: 781.8068 - val_loss: 1238636.8375 - val_mae: 805.1311\n",
      "Epoch 250/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1390171.6130 - mae: 833.7781 - val_loss: 1250704.2066 - val_mae: 793.5081\n",
      "Epoch 251/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1253506.7835 - mae: 798.1934 - val_loss: 1309462.8539 - val_mae: 802.3350\n",
      "Epoch 252/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1257943.6649 - mae: 797.4789 - val_loss: 1309687.3522 - val_mae: 802.8962\n",
      "Epoch 253/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1251828.2865 - mae: 793.6575 - val_loss: 1241750.4794 - val_mae: 811.6949\n",
      "Epoch 254/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1294407.8078 - mae: 806.6948 - val_loss: 1246256.0249 - val_mae: 815.3994\n",
      "Epoch 255/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1269765.8646 - mae: 799.6760 - val_loss: 1242984.6242 - val_mae: 793.9297\n",
      "Epoch 256/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1277279.1788 - mae: 804.5582 - val_loss: 1375381.9553 - val_mae: 818.7902\n",
      "Epoch 257/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1266485.5437 - mae: 797.3699 - val_loss: 1252365.4967 - val_mae: 792.3776\n",
      "Epoch 258/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1230458.4257 - mae: 783.6278 - val_loss: 1234148.2538 - val_mae: 794.2160\n",
      "Epoch 259/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1278202.8737 - mae: 802.1312 - val_loss: 1232898.9524 - val_mae: 804.9082\n",
      "Epoch 260/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1259212.7871 - mae: 795.0803 - val_loss: 1229666.2640 - val_mae: 794.4928\n",
      "Epoch 261/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1250824.7040 - mae: 794.6603 - val_loss: 1265232.8402 - val_mae: 793.7195\n",
      "Epoch 262/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1283638.8661 - mae: 808.3629 - val_loss: 1345814.2891 - val_mae: 810.7564\n",
      "Epoch 263/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1243431.9246 - mae: 792.5503 - val_loss: 1239494.1885 - val_mae: 809.9584\n",
      "Epoch 264/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1272665.4225 - mae: 800.4742 - val_loss: 1229875.6763 - val_mae: 802.3471\n",
      "Epoch 265/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1291491.6542 - mae: 804.5789 - val_loss: 1271956.2341 - val_mae: 795.5888\n",
      "Epoch 266/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1260092.3702 - mae: 796.5130 - val_loss: 1231981.6280 - val_mae: 803.9205\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 7us/step - loss: 1276698.0624 - mae: 798.7075 - val_loss: 1226462.5478 - val_mae: 796.8295\n",
      "Epoch 268/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1251572.9024 - mae: 791.5975 - val_loss: 1229440.5421 - val_mae: 801.4216\n",
      "Epoch 269/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1270363.2668 - mae: 803.5620 - val_loss: 1458671.8512 - val_mae: 839.9526\n",
      "Epoch 270/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1275410.3783 - mae: 799.3406 - val_loss: 1284946.6696 - val_mae: 797.9489\n",
      "Epoch 271/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1248363.2470 - mae: 792.6823 - val_loss: 1294939.3716 - val_mae: 798.6645\n",
      "Epoch 272/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1309883.2959 - mae: 811.6075 - val_loss: 1335974.3407 - val_mae: 808.1131\n",
      "Epoch 273/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1249688.7960 - mae: 790.7914 - val_loss: 1282548.2996 - val_mae: 797.7310\n",
      "Epoch 274/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1235367.9891 - mae: 784.9625 - val_loss: 1226432.2370 - val_mae: 795.7875\n",
      "Epoch 275/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1315720.1762 - mae: 814.3708 - val_loss: 1243601.8913 - val_mae: 792.7679\n",
      "Epoch 276/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1242048.7782 - mae: 793.9703 - val_loss: 1261697.2048 - val_mae: 792.7919\n",
      "Epoch 277/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1271549.4866 - mae: 792.7724 - val_loss: 1236953.3986 - val_mae: 790.7476\n",
      "Epoch 278/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1245855.6365 - mae: 789.8300 - val_loss: 1243040.9364 - val_mae: 813.8007\n",
      "Epoch 279/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1306129.0607 - mae: 814.1665 - val_loss: 1244460.5177 - val_mae: 790.7815\n",
      "Epoch 280/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1264907.2698 - mae: 797.9122 - val_loss: 1228938.7714 - val_mae: 792.1802\n",
      "Epoch 281/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1254859.4275 - mae: 796.5268 - val_loss: 1229265.0837 - val_mae: 792.7462\n",
      "Epoch 282/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1222277.5761 - mae: 786.5707 - val_loss: 1230141.0062 - val_mae: 788.5216\n",
      "Epoch 283/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1324695.2006 - mae: 812.7457 - val_loss: 1229739.2686 - val_mae: 798.6553\n",
      "Epoch 284/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1243350.8368 - mae: 792.5353 - val_loss: 1227470.7219 - val_mae: 799.7698\n",
      "Epoch 285/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1243456.2204 - mae: 790.0770 - val_loss: 1273007.5912 - val_mae: 794.2698\n",
      "Epoch 286/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1282957.2754 - mae: 805.3005 - val_loss: 1227821.0853 - val_mae: 794.0409\n",
      "Epoch 287/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1253590.4870 - mae: 792.1997 - val_loss: 1240735.9170 - val_mae: 790.1608\n",
      "Epoch 288/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1239704.5228 - mae: 790.0196 - val_loss: 1231821.4472 - val_mae: 793.6713\n",
      "Epoch 289/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1304639.8548 - mae: 804.4998 - val_loss: 1228051.4180 - val_mae: 794.8043\n",
      "Epoch 290/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1237864.0325 - mae: 786.0804 - val_loss: 1238376.5886 - val_mae: 793.7126\n",
      "Epoch 291/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1283219.2188 - mae: 803.3167 - val_loss: 1509593.4009 - val_mae: 853.1337\n",
      "Epoch 292/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1283855.1057 - mae: 799.2312 - val_loss: 1239280.7408 - val_mae: 790.9686\n",
      "Epoch 293/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1210382.9331 - mae: 777.5195 - val_loss: 1229307.6546 - val_mae: 791.3599\n",
      "Epoch 294/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1236136.5971 - mae: 786.2091 - val_loss: 1245490.9109 - val_mae: 790.6422\n",
      "Epoch 295/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1254591.6441 - mae: 796.2047 - val_loss: 1611649.8285 - val_mae: 882.8295\n",
      "Epoch 296/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1295807.8416 - mae: 802.7057 - val_loss: 1265160.6200 - val_mae: 792.7338\n",
      "Epoch 297/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1231555.0243 - mae: 786.5521 - val_loss: 1369559.3316 - val_mae: 815.7748\n",
      "Epoch 298/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1227937.9187 - mae: 787.3482 - val_loss: 1377387.4631 - val_mae: 818.4516\n",
      "Epoch 299/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1273291.0999 - mae: 801.5617 - val_loss: 1417977.4593 - val_mae: 827.9608\n",
      "Epoch 300/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1263814.2492 - mae: 794.7507 - val_loss: 1233298.8292 - val_mae: 790.7054\n",
      "Epoch 301/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1245025.2814 - mae: 793.2574 - val_loss: 1277958.8891 - val_mae: 794.9525\n",
      "Epoch 302/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1274854.2496 - mae: 797.7774 - val_loss: 1344250.2843 - val_mae: 808.7845\n",
      "Epoch 303/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1233472.3747 - mae: 786.7807 - val_loss: 1281550.2047 - val_mae: 795.6057\n",
      "Epoch 304/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1269807.7827 - mae: 798.4083 - val_loss: 1224544.2711 - val_mae: 792.4567\n",
      "Epoch 305/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1279388.1412 - mae: 799.1736 - val_loss: 1234771.9925 - val_mae: 790.6512\n",
      "Epoch 306/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1235540.0870 - mae: 790.0396 - val_loss: 1273814.1332 - val_mae: 793.7696\n",
      "Epoch 307/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1287047.6787 - mae: 804.3204 - val_loss: 1345852.4901 - val_mae: 808.6684\n",
      "Epoch 308/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1251585.8630 - mae: 790.4856 - val_loss: 1375657.0416 - val_mae: 816.6721\n",
      "Epoch 309/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1225356.0298 - mae: 782.9968 - val_loss: 1221378.7399 - val_mae: 793.0294\n",
      "Epoch 310/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1210377.4105 - mae: 779.5905 - val_loss: 1224232.1177 - val_mae: 786.6827\n",
      "Epoch 311/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1241565.7288 - mae: 792.5353 - val_loss: 1223192.9245 - val_mae: 797.6313\n",
      "Epoch 312/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1225509.9962 - mae: 783.9639 - val_loss: 1268836.5714 - val_mae: 792.2700\n",
      "Epoch 313/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1229077.6619 - mae: 786.6732 - val_loss: 1445350.6842 - val_mae: 835.5962\n",
      "Epoch 314/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1252341.5258 - mae: 795.2208 - val_loss: 1244510.6777 - val_mae: 788.8337\n",
      "Epoch 315/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1237439.3197 - mae: 791.0812 - val_loss: 1453420.8720 - val_mae: 838.2560\n",
      "Epoch 316/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1264780.5448 - mae: 795.5695 - val_loss: 1234297.8694 - val_mae: 788.6736\n",
      "Epoch 317/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1233065.8613 - mae: 788.5988 - val_loss: 1465713.1175 - val_mae: 840.4105\n",
      "Epoch 318/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1264372.9842 - mae: 796.9299 - val_loss: 1245193.5206 - val_mae: 790.0320\n",
      "Epoch 319/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1240828.4740 - mae: 787.5422 - val_loss: 1356415.0182 - val_mae: 811.5632\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 7us/step - loss: 1263561.5085 - mae: 795.8113 - val_loss: 1407308.9543 - val_mae: 824.1237\n",
      "Epoch 321/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1232784.0072 - mae: 788.2907 - val_loss: 1263737.8267 - val_mae: 791.7692\n",
      "Epoch 322/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1229182.8790 - mae: 782.6231 - val_loss: 1241282.5826 - val_mae: 790.1804\n",
      "Epoch 323/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1240035.2347 - mae: 788.5941 - val_loss: 1216128.1324 - val_mae: 791.2689\n",
      "Epoch 324/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1246000.6141 - mae: 793.9184 - val_loss: 1220989.9911 - val_mae: 787.6832\n",
      "Epoch 325/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1246919.0642 - mae: 791.1410 - val_loss: 1225129.5108 - val_mae: 788.4332\n",
      "Epoch 326/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1235051.9338 - mae: 786.3878 - val_loss: 1236468.8229 - val_mae: 789.0426\n",
      "Epoch 327/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1267770.9929 - mae: 794.4288 - val_loss: 1271372.3084 - val_mae: 830.9748\n",
      "Epoch 328/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1242805.8499 - mae: 794.4220 - val_loss: 1317145.6489 - val_mae: 800.9993\n",
      "Epoch 329/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1229849.1492 - mae: 780.7192 - val_loss: 1226206.6741 - val_mae: 786.8649\n",
      "Epoch 330/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1208753.2159 - mae: 777.9614 - val_loss: 1317257.4034 - val_mae: 801.9070\n",
      "Epoch 331/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1266576.5032 - mae: 796.1855 - val_loss: 1274301.1830 - val_mae: 792.9435\n",
      "Epoch 332/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1212451.5674 - mae: 778.4398 - val_loss: 1353650.7403 - val_mae: 810.3979\n",
      "Epoch 333/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1280756.5994 - mae: 800.6205 - val_loss: 1323075.5948 - val_mae: 802.9155\n",
      "Epoch 334/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1222880.4253 - mae: 780.9522 - val_loss: 1418118.7390 - val_mae: 827.1240\n",
      "Epoch 335/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1233228.1276 - mae: 785.6827 - val_loss: 1298591.0358 - val_mae: 797.8429\n",
      "Epoch 336/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1205739.3994 - mae: 776.4374 - val_loss: 1225488.7690 - val_mae: 786.5786\n",
      "Epoch 337/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1254304.5838 - mae: 793.6321 - val_loss: 1222766.2272 - val_mae: 787.6445\n",
      "Epoch 338/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1247493.2459 - mae: 787.7523 - val_loss: 1219201.9150 - val_mae: 793.7475\n",
      "Epoch 339/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1240770.9414 - mae: 790.5905 - val_loss: 1356021.8224 - val_mae: 810.3918\n",
      "Epoch 340/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220845.7693 - mae: 780.8549 - val_loss: 1239358.6455 - val_mae: 789.2636\n",
      "Epoch 341/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1213384.4570 - mae: 779.7018 - val_loss: 1624091.9680 - val_mae: 883.9071\n",
      "Epoch 342/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1259202.0495 - mae: 797.1175 - val_loss: 1300963.8752 - val_mae: 797.9158\n",
      "Epoch 343/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1230730.9988 - mae: 786.6676 - val_loss: 1278801.8574 - val_mae: 793.5449\n",
      "Epoch 344/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1260733.2821 - mae: 798.8973 - val_loss: 1273159.4920 - val_mae: 791.9540\n",
      "Epoch 345/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1205810.8053 - mae: 773.9717 - val_loss: 1223300.7523 - val_mae: 786.0679\n",
      "Epoch 346/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223957.5877 - mae: 785.2484 - val_loss: 1441625.1151 - val_mae: 832.1373\n",
      "Epoch 347/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1288545.5143 - mae: 801.8065 - val_loss: 1276069.1313 - val_mae: 793.9019\n",
      "Epoch 348/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1211983.8266 - mae: 780.8482 - val_loss: 1347607.0603 - val_mae: 807.7861\n",
      "Epoch 349/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1239706.2854 - mae: 782.1911 - val_loss: 1369001.0947 - val_mae: 814.0063\n",
      "Epoch 350/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1229423.2428 - mae: 783.1860 - val_loss: 1247207.9219 - val_mae: 786.6688\n",
      "Epoch 351/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223564.6612 - mae: 782.9651 - val_loss: 1261527.5970 - val_mae: 789.0657\n",
      "Epoch 352/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1221498.9495 - mae: 779.9459 - val_loss: 1214707.8549 - val_mae: 784.1124\n",
      "Epoch 353/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1240802.8245 - mae: 785.6735 - val_loss: 1214487.8333 - val_mae: 791.3857\n",
      "Epoch 354/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1225769.3419 - mae: 785.9103 - val_loss: 1223930.6157 - val_mae: 786.7255\n",
      "Epoch 355/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1216647.3630 - mae: 782.7374 - val_loss: 1315998.5409 - val_mae: 799.6121\n",
      "Epoch 356/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1199208.9394 - mae: 773.6302 - val_loss: 1246111.1858 - val_mae: 788.7087\n",
      "Epoch 357/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1243181.8706 - mae: 789.2958 - val_loss: 1218124.8640 - val_mae: 786.2811\n",
      "Epoch 358/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1257194.9708 - mae: 791.2620 - val_loss: 1217337.1927 - val_mae: 786.8605\n",
      "Epoch 359/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1219208.8094 - mae: 782.0697 - val_loss: 1229093.9035 - val_mae: 786.4522\n",
      "Epoch 360/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1218104.3756 - mae: 777.2795 - val_loss: 1214138.4745 - val_mae: 785.2909\n",
      "Epoch 361/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1232926.3160 - mae: 786.3713 - val_loss: 1217062.5388 - val_mae: 787.2744\n",
      "Epoch 362/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1247337.2267 - mae: 789.1852 - val_loss: 1218006.1152 - val_mae: 786.0059\n",
      "Epoch 363/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1251719.6957 - mae: 791.5999 - val_loss: 1241470.3149 - val_mae: 785.8750\n",
      "Epoch 364/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1230580.9565 - mae: 785.9072 - val_loss: 1237198.2850 - val_mae: 785.1732\n",
      "Epoch 365/500\n",
      "5966/5966 [==============================] - 0s 8us/step - loss: 1219919.3350 - mae: 782.1086 - val_loss: 1221683.1076 - val_mae: 783.7855\n",
      "Epoch 366/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1234182.0946 - mae: 787.6951 - val_loss: 1362549.8191 - val_mae: 810.6510\n",
      "Epoch 367/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1212390.5166 - mae: 779.1196 - val_loss: 1227684.0525 - val_mae: 784.5925\n",
      "Epoch 368/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1228616.9485 - mae: 784.9353 - val_loss: 1224116.4911 - val_mae: 785.9454\n",
      "Epoch 369/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1252436.7836 - mae: 789.8014 - val_loss: 1229676.5350 - val_mae: 785.3342\n",
      "Epoch 370/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1206588.9893 - mae: 778.0786 - val_loss: 1231892.0727 - val_mae: 782.1957\n",
      "Epoch 371/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220803.3275 - mae: 776.1392 - val_loss: 1293381.0198 - val_mae: 794.7452\n",
      "Epoch 372/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1238093.1172 - mae: 786.7642 - val_loss: 1381158.3844 - val_mae: 814.8356\n",
      "Epoch 373/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 8us/step - loss: 1216932.5903 - mae: 773.3825 - val_loss: 1452906.6576 - val_mae: 833.5211\n",
      "Epoch 374/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1262319.4410 - mae: 795.4667 - val_loss: 1360371.3276 - val_mae: 809.8187\n",
      "Epoch 375/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1213462.8489 - mae: 776.2424 - val_loss: 1348574.1170 - val_mae: 806.9451\n",
      "Epoch 376/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1233528.6692 - mae: 781.9760 - val_loss: 1216432.4501 - val_mae: 788.4273\n",
      "Epoch 377/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1230948.6431 - mae: 786.1134 - val_loss: 1302893.7769 - val_mae: 797.1660\n",
      "Epoch 378/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1222699.4068 - mae: 782.5325 - val_loss: 1457760.6976 - val_mae: 834.0515\n",
      "Epoch 379/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1219810.2889 - mae: 779.5740 - val_loss: 1312600.9346 - val_mae: 798.1343\n",
      "Epoch 380/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223594.1994 - mae: 776.0954 - val_loss: 1223672.7073 - val_mae: 783.9464\n",
      "Epoch 381/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1209520.6606 - mae: 775.9423 - val_loss: 1263850.4161 - val_mae: 788.3022\n",
      "Epoch 382/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1269211.2449 - mae: 795.7673 - val_loss: 1303217.8049 - val_mae: 795.5193\n",
      "Epoch 383/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1189052.4436 - mae: 774.1132 - val_loss: 1244447.8877 - val_mae: 786.7914\n",
      "Epoch 384/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1205365.9954 - mae: 777.9113 - val_loss: 1461142.3832 - val_mae: 835.1212\n",
      "Epoch 385/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1259069.4449 - mae: 788.5406 - val_loss: 1319197.7989 - val_mae: 798.6934\n",
      "Epoch 386/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1198732.6121 - mae: 772.6069 - val_loss: 1357121.5066 - val_mae: 807.9252\n",
      "Epoch 387/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1199640.2179 - mae: 776.3674 - val_loss: 1248238.6590 - val_mae: 785.9258\n",
      "Epoch 388/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1231993.9565 - mae: 782.6722 - val_loss: 1218445.6819 - val_mae: 788.6934\n",
      "Epoch 389/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1225763.5209 - mae: 785.3248 - val_loss: 1452271.8211 - val_mae: 831.4432\n",
      "Epoch 390/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1236231.8207 - mae: 779.6294 - val_loss: 1287043.6303 - val_mae: 793.4137\n",
      "Epoch 391/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1253267.0652 - mae: 790.4975 - val_loss: 1238925.1079 - val_mae: 785.9859\n",
      "Epoch 392/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1204558.0040 - mae: 772.8925 - val_loss: 1354881.5134 - val_mae: 807.3867\n",
      "Epoch 393/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220094.2994 - mae: 777.1425 - val_loss: 1240622.2137 - val_mae: 785.7401\n",
      "Epoch 394/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1204316.9921 - mae: 776.5604 - val_loss: 1247726.5035 - val_mae: 786.1553\n",
      "Epoch 395/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223144.7696 - mae: 783.1430 - val_loss: 1241575.5997 - val_mae: 786.0496\n",
      "Epoch 396/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1200907.8478 - mae: 773.8127 - val_loss: 1526983.5406 - val_mae: 852.1590\n",
      "Epoch 397/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223986.6051 - mae: 784.8798 - val_loss: 1328815.0729 - val_mae: 800.2887\n",
      "Epoch 398/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220600.3040 - mae: 778.9144 - val_loss: 1225185.1636 - val_mae: 785.4188\n",
      "Epoch 399/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1204480.1745 - mae: 774.7709 - val_loss: 1216615.9419 - val_mae: 796.1025\n",
      "Epoch 400/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1232084.1839 - mae: 788.4604 - val_loss: 1246767.7989 - val_mae: 785.2294\n",
      "Epoch 401/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1203114.0654 - mae: 775.2028 - val_loss: 1443702.1166 - val_mae: 829.6165\n",
      "Epoch 402/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1217276.9706 - mae: 781.6771 - val_loss: 1485690.1488 - val_mae: 840.8549\n",
      "Epoch 403/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1240400.8903 - mae: 789.6552 - val_loss: 1413924.5950 - val_mae: 821.2292\n",
      "Epoch 404/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1217066.5225 - mae: 781.1406 - val_loss: 1324484.3464 - val_mae: 799.2095\n",
      "Epoch 405/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1215076.5357 - mae: 776.1949 - val_loss: 1213055.5902 - val_mae: 784.3215\n",
      "Epoch 406/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220558.0295 - mae: 777.5193 - val_loss: 1371524.1675 - val_mae: 810.0873\n",
      "Epoch 407/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1213900.2875 - mae: 776.3453 - val_loss: 1555559.2509 - val_mae: 859.0239\n",
      "Epoch 408/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1216762.2748 - mae: 776.0385 - val_loss: 1293354.2071 - val_mae: 792.2584\n",
      "Epoch 409/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1188875.9562 - mae: 771.4243 - val_loss: 1431937.6719 - val_mae: 826.7872\n",
      "Epoch 410/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1253050.4916 - mae: 791.4318 - val_loss: 1486977.9868 - val_mae: 840.6536\n",
      "Epoch 411/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1219184.6559 - mae: 775.6491 - val_loss: 1272319.1188 - val_mae: 789.5193\n",
      "Epoch 412/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1209638.7529 - mae: 776.9335 - val_loss: 1232405.3321 - val_mae: 785.3162\n",
      "Epoch 413/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1231586.5164 - mae: 790.6144 - val_loss: 1302339.8970 - val_mae: 794.3367\n",
      "Epoch 414/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1192249.0894 - mae: 769.1019 - val_loss: 1320002.9981 - val_mae: 797.9001\n",
      "Epoch 415/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1194908.6338 - mae: 770.7186 - val_loss: 1495294.1818 - val_mae: 843.2580\n",
      "Epoch 416/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1224425.8953 - mae: 782.6344 - val_loss: 1341532.7425 - val_mae: 803.0416\n",
      "Epoch 417/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1218962.5750 - mae: 781.1586 - val_loss: 1237211.0795 - val_mae: 784.3800\n",
      "Epoch 418/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1207931.1253 - mae: 778.1582 - val_loss: 1346704.6072 - val_mae: 804.7488\n",
      "Epoch 419/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1196894.7700 - mae: 772.6783 - val_loss: 1389261.5901 - val_mae: 814.6623\n",
      "Epoch 420/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1255359.3219 - mae: 793.5476 - val_loss: 1327896.0291 - val_mae: 799.5485\n",
      "Epoch 421/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1216570.4880 - mae: 778.4893 - val_loss: 1455979.6711 - val_mae: 831.2095\n",
      "Epoch 422/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1216161.8774 - mae: 779.1238 - val_loss: 1309353.0264 - val_mae: 794.8378\n",
      "Epoch 423/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1207624.6707 - mae: 776.5319 - val_loss: 1232019.4593 - val_mae: 786.3383\n",
      "Epoch 424/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1244056.8302 - mae: 787.0037 - val_loss: 1339543.7478 - val_mae: 802.2422\n",
      "Epoch 425/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1202286.4998 - mae: 772.1026 - val_loss: 1232116.4913 - val_mae: 782.5894\n",
      "Epoch 426/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 7us/step - loss: 1234550.0616 - mae: 789.8048 - val_loss: 1303768.3655 - val_mae: 793.8798\n",
      "Epoch 427/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1222439.2841 - mae: 776.5540 - val_loss: 1243093.2567 - val_mae: 783.0190\n",
      "Epoch 428/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1181898.9053 - mae: 765.2927 - val_loss: 1407695.7591 - val_mae: 818.8994\n",
      "Epoch 429/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1239883.5278 - mae: 784.7228 - val_loss: 1304447.1467 - val_mae: 793.7460\n",
      "Epoch 430/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1203723.1174 - mae: 773.5056 - val_loss: 1224195.7282 - val_mae: 781.5596\n",
      "Epoch 431/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1196798.5576 - mae: 775.0859 - val_loss: 1267627.3752 - val_mae: 788.6251\n",
      "Epoch 432/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1223578.1586 - mae: 784.5988 - val_loss: 1261919.5249 - val_mae: 786.5350\n",
      "Epoch 433/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1210649.8341 - mae: 776.5306 - val_loss: 1407222.0027 - val_mae: 818.7512\n",
      "Epoch 434/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1216161.4717 - mae: 778.8654 - val_loss: 1404355.9592 - val_mae: 817.4870\n",
      "Epoch 435/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1188868.6360 - mae: 769.9406 - val_loss: 1375663.8408 - val_mae: 812.1003\n",
      "Epoch 436/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1212937.3248 - mae: 777.2858 - val_loss: 1237344.2030 - val_mae: 782.9127\n",
      "Epoch 437/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1230047.1769 - mae: 782.8430 - val_loss: 1262337.6468 - val_mae: 785.8635\n",
      "Epoch 438/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1199580.1583 - mae: 769.2931 - val_loss: 1227078.6925 - val_mae: 782.1351\n",
      "Epoch 439/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1233289.3079 - mae: 783.7078 - val_loss: 1299616.7332 - val_mae: 792.1216\n",
      "Epoch 440/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1189940.8985 - mae: 767.8785 - val_loss: 1214988.2590 - val_mae: 781.5461\n",
      "Epoch 441/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1240612.2539 - mae: 788.1489 - val_loss: 1468049.5461 - val_mae: 832.7747\n",
      "Epoch 442/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1199013.1844 - mae: 770.4140 - val_loss: 1351194.0858 - val_mae: 805.0118\n",
      "Epoch 443/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1216096.7152 - mae: 777.5186 - val_loss: 1324932.7518 - val_mae: 798.4846\n",
      "Epoch 444/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1201246.7231 - mae: 776.3371 - val_loss: 1447728.8481 - val_mae: 828.8535\n",
      "Epoch 445/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1232266.9072 - mae: 784.5764 - val_loss: 1395079.6209 - val_mae: 814.9583\n",
      "Epoch 446/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1208908.2598 - mae: 775.7037 - val_loss: 1318834.6438 - val_mae: 796.7938\n",
      "Epoch 447/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1198342.2428 - mae: 770.4103 - val_loss: 1289166.8031 - val_mae: 790.0963\n",
      "Epoch 448/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1220257.1670 - mae: 779.7274 - val_loss: 1210705.4332 - val_mae: 788.8373\n",
      "Epoch 449/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1230226.7147 - mae: 784.5875 - val_loss: 1230896.2539 - val_mae: 782.2616\n",
      "Epoch 450/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1201623.9392 - mae: 771.0552 - val_loss: 1316691.0280 - val_mae: 797.7538\n",
      "Epoch 451/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1222231.8133 - mae: 780.0898 - val_loss: 1241793.8925 - val_mae: 784.7717\n",
      "Epoch 452/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1215501.0903 - mae: 776.3603 - val_loss: 1249833.1818 - val_mae: 784.6832\n",
      "Epoch 453/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1190102.8232 - mae: 770.1946 - val_loss: 1290592.8425 - val_mae: 791.2533\n",
      "Epoch 454/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1220932.4164 - mae: 779.4419 - val_loss: 1359585.8452 - val_mae: 805.2537\n",
      "Epoch 455/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1217988.6425 - mae: 775.6797 - val_loss: 1423711.0851 - val_mae: 821.1740\n",
      "Epoch 456/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1213522.8978 - mae: 777.8343 - val_loss: 1405934.5643 - val_mae: 817.1620\n",
      "Epoch 457/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1224002.3318 - mae: 777.0624 - val_loss: 1268977.6603 - val_mae: 786.5056\n",
      "Epoch 458/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1183842.2371 - mae: 768.9331 - val_loss: 1441726.2330 - val_mae: 826.5911\n",
      "Epoch 459/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1211392.8202 - mae: 779.0350 - val_loss: 1521378.9918 - val_mae: 846.8975\n",
      "Epoch 460/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1232290.7524 - mae: 784.1143 - val_loss: 1320621.1843 - val_mae: 797.3141\n",
      "Epoch 461/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1208072.9710 - mae: 774.7563 - val_loss: 1291934.4326 - val_mae: 789.9676\n",
      "Epoch 462/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1181853.6791 - mae: 767.7115 - val_loss: 1233078.0637 - val_mae: 780.4597\n",
      "Epoch 463/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1240711.0028 - mae: 788.7449 - val_loss: 1426638.8689 - val_mae: 823.4233\n",
      "Epoch 464/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1212348.2306 - mae: 776.5793 - val_loss: 1366890.5642 - val_mae: 807.2371\n",
      "Epoch 465/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1177425.4465 - mae: 763.0229 - val_loss: 1240803.1329 - val_mae: 782.9327\n",
      "Epoch 466/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1228549.0451 - mae: 783.5454 - val_loss: 1248182.2308 - val_mae: 784.7957\n",
      "Epoch 467/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1192543.8361 - mae: 770.9819 - val_loss: 1435666.2999 - val_mae: 824.5617\n",
      "Epoch 468/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1213458.6277 - mae: 778.7762 - val_loss: 1387368.4117 - val_mae: 811.6306\n",
      "Epoch 469/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1227747.3949 - mae: 779.5297 - val_loss: 1556266.0793 - val_mae: 858.6700\n",
      "Epoch 470/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1203516.5659 - mae: 771.5809 - val_loss: 1322578.7342 - val_mae: 797.7056\n",
      "Epoch 471/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1224210.1666 - mae: 781.9537 - val_loss: 1521285.5526 - val_mae: 848.2057\n",
      "Epoch 472/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1193862.2839 - mae: 767.8888 - val_loss: 1296351.7304 - val_mae: 791.0460\n",
      "Epoch 473/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1199722.1791 - mae: 773.7285 - val_loss: 1343869.0799 - val_mae: 801.3368\n",
      "Epoch 474/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1210323.8411 - mae: 775.4149 - val_loss: 1286607.8850 - val_mae: 788.8361\n",
      "Epoch 475/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1227461.2670 - mae: 782.1948 - val_loss: 1473251.7813 - val_mae: 835.7177\n",
      "Epoch 476/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1182198.6701 - mae: 765.6572 - val_loss: 1263933.6221 - val_mae: 786.0556\n",
      "Epoch 477/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1218803.1935 - mae: 780.6983 - val_loss: 1255013.7829 - val_mae: 783.8387\n",
      "Epoch 478/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1195470.6616 - mae: 772.3326 - val_loss: 1284729.9624 - val_mae: 788.7000\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 6us/step - loss: 1203219.8999 - mae: 769.2235 - val_loss: 1278216.3702 - val_mae: 788.5750\n",
      "Epoch 480/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1182188.1121 - mae: 766.7361 - val_loss: 1209324.5331 - val_mae: 783.1522\n",
      "Epoch 481/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1213237.9876 - mae: 783.4413 - val_loss: 1397110.9210 - val_mae: 815.4609\n",
      "Epoch 482/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1174226.2836 - mae: 762.4177 - val_loss: 1224288.8355 - val_mae: 782.0289\n",
      "Epoch 483/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1197676.9001 - mae: 771.0862 - val_loss: 1287682.6036 - val_mae: 789.6855\n",
      "Epoch 484/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1202328.7874 - mae: 774.0878 - val_loss: 1232353.2605 - val_mae: 782.7022\n",
      "Epoch 485/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1199058.8980 - mae: 770.1779 - val_loss: 1257102.5336 - val_mae: 783.7474\n",
      "Epoch 486/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1198838.0213 - mae: 771.7741 - val_loss: 1653260.4348 - val_mae: 885.1093\n",
      "Epoch 487/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1238646.2280 - mae: 780.4976 - val_loss: 1360241.7406 - val_mae: 805.6003\n",
      "Epoch 488/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1179008.4566 - mae: 766.6481 - val_loss: 1457008.2901 - val_mae: 831.1260\n",
      "Epoch 489/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1180623.8257 - mae: 765.6989 - val_loss: 1220074.1880 - val_mae: 786.5778\n",
      "Epoch 490/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1260717.8776 - mae: 791.9796 - val_loss: 1256973.2634 - val_mae: 783.5793\n",
      "Epoch 491/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1199628.0709 - mae: 771.7208 - val_loss: 1222854.6010 - val_mae: 780.0262\n",
      "Epoch 492/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1203945.0807 - mae: 774.2383 - val_loss: 1280150.8251 - val_mae: 787.4512\n",
      "Epoch 493/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1209784.6077 - mae: 775.7300 - val_loss: 1588221.2200 - val_mae: 867.1618\n",
      "Epoch 494/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1216034.5362 - mae: 772.4933 - val_loss: 1288607.7261 - val_mae: 789.7261\n",
      "Epoch 495/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1205494.2209 - mae: 776.6971 - val_loss: 1392208.6827 - val_mae: 813.0073\n",
      "Epoch 496/500\n",
      "5966/5966 [==============================] - 0s 7us/step - loss: 1172220.6721 - mae: 764.5964 - val_loss: 1495363.1495 - val_mae: 841.3546\n",
      "Epoch 497/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1208637.3483 - mae: 774.1952 - val_loss: 1299811.0447 - val_mae: 791.8075\n",
      "Epoch 498/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1179537.7267 - mae: 765.6135 - val_loss: 1305768.8114 - val_mae: 793.0919\n",
      "Epoch 499/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1202638.8255 - mae: 774.9066 - val_loss: 1269606.9694 - val_mae: 785.8338\n",
      "Epoch 500/500\n",
      "5966/5966 [==============================] - 0s 6us/step - loss: 1198256.5626 - mae: 769.9692 - val_loss: 1249830.8887 - val_mae: 783.3333\n"
     ]
    }
   ],
   "source": [
    "# removing history from memory\n",
    "#del history\n",
    "# training the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=1024,validation_data =(X_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.050439Z",
     "start_time": "2020-12-05T19:59:27.882546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077.8517402935752\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.253314Z",
     "start_time": "2020-12-05T19:59:28.053441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1161764.3694686557, 745.2403564453125]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.628081Z",
     "start_time": "2020-12-05T19:59:28.255312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14d9426a908>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, 500)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "#plt.figure(figure)\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"mae\"], label=\"train_MAE\")\n",
    "plt.plot(N, history.history[\"val_mae\"], label=\"val_MAE\")\n",
    "plt.title(\"Training Loss and Mean Absolute Error on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/MAE\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "#plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.644074Z",
     "start_time": "2020-12-05T19:59:28.631080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the same transformations to test dataset\n",
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "test['Outlet_Age']=test['Outlet_Establishment_Year'].max() - test['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.752003Z",
     "start_time": "2020-12-05T19:59:28.648069Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = test[['Item_Identifier','Outlet_Identifier']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:28.877926Z",
     "start_time": "2020-12-05T19:59:28.754002Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "test = test.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.001849Z",
     "start_time": "2020-12-05T19:59:28.880925Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Visibility']=test['Item_Visibility'].mask(test['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.126774Z",
     "start_time": "2020-12-05T19:59:29.003849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight              976\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          353\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             1606\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.267685Z",
     "start_time": "2020-12-05T19:59:29.129770Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Weight'].fillna(test['Item_Weight'].mean(),inplace=True)\n",
    "test['Outlet_Size'].fillna(test['Outlet_Size'].mode()[0],inplace=True)\n",
    "test['Item_Visibility'].fillna(test['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.376615Z",
     "start_time": "2020-12-05T19:59:29.272681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    3396\n",
       "Regular    1935\n",
       "LF          206\n",
       "reg          78\n",
       "low fat      66\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "test['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.531518Z",
     "start_time": "2020-12-05T19:59:29.381613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.719410Z",
     "start_time": "2020-12-05T19:59:29.534517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>13</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>4</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>11</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>13</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.695633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>4</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  Item_MRP  \\\n",
       "0    20.750000                 0         0.007565         13  107.8622   \n",
       "1     8.300000                 1         0.038428          4   87.3198   \n",
       "2    14.600000                 0         0.099575         11  241.7538   \n",
       "3     7.315000                 0         0.015388         13  155.0340   \n",
       "4    12.695633                 1         0.118599          4  234.2300   \n",
       "\n",
       "   Outlet_Size  Outlet_Location_Type  Outlet_Type  Outlet_Age  \n",
       "0            1                     0            1          10  \n",
       "1            1                     1            1           2  \n",
       "2            1                     2            0          11  \n",
       "3            1                     1            1           2  \n",
       "4            1                     2            3          24  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "test['Item_Fat_Content']=label_encoder.fit_transform(test['Item_Fat_Content']) \n",
    "#,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "test['Outlet_Size']=label_encoder.fit_transform(test['Outlet_Size'])\n",
    "test['Outlet_Location_Type']=label_encoder.fit_transform(test['Outlet_Location_Type'])\n",
    "test['Outlet_Type']=label_encoder.fit_transform(test['Outlet_Type'])\n",
    "test['Item_Type']=label_encoder.fit_transform(test['Item_Type'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:29.984237Z",
     "start_time": "2020-12-05T19:59:29.723402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96427508, 0.        , 0.01241517, 0.86666667, 0.32341312,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.22298303, 1.        , 0.10884773, 0.26666667, 0.23584901,\n",
       "        0.5       , 0.5       , 0.33333333, 0.08333333],\n",
       "       [0.59809467, 0.        , 0.29990547, 0.73333333, 0.89413994,\n",
       "        0.5       , 1.        , 0.        , 0.45833333],\n",
       "       [0.16433462, 0.        , 0.03686028, 0.86666667, 0.52448781,\n",
       "        0.5       , 0.5       , 0.33333333, 0.08333333],\n",
       "       [0.48470577, 1.        , 0.35934822, 0.26666667, 0.86206897,\n",
       "        0.5       , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the test from 0 to 1 using MinMaxScalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler=MinMaxScaler()\n",
    "test=min_max_scaler.fit_transform(test)\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:30.233085Z",
     "start_time": "2020-12-05T19:59:29.987237Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:30.264065Z",
     "start_time": "2020-12-05T19:59:30.236083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1663.343018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1409.616577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>743.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2461.905029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5438.068848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2290.447021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2294.409424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1463.819336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3359.967529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>934.514709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1663.343018\n",
       "1              FDW14            OUT017        1409.616577\n",
       "2              NCN55            OUT010         743.222900\n",
       "3              FDQ58            OUT017        2461.905029\n",
       "4              FDY38            OUT027        5438.068848\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2290.447021\n",
       "5677           FDD47            OUT018        2294.409424\n",
       "5678           NCO17            OUT045        1463.819336\n",
       "5679           FDJ26            OUT017        3359.967529\n",
       "5680           FDU37            OUT045         934.514709\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Item_Outlet_Sales']=predictions\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T19:59:30.419965Z",
     "start_time": "2020-12-05T19:59:30.267063Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
