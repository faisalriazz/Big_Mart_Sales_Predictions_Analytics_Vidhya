{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Mart Sales Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:54:14.087401Z",
     "start_time": "2020-12-05T11:54:14.084401Z"
    }
   },
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:54.772472Z",
     "start_time": "2020-12-07T10:52:38.701574Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:55:08.808846Z",
     "start_time": "2020-12-05T11:55:08.790857Z"
    }
   },
   "source": [
    "### importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.118718Z",
     "start_time": "2020-12-07T10:52:54.775452Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the test and train csv files\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.134298Z",
     "start_time": "2020-12-07T10:52:55.121731Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data exploration of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.226911Z",
     "start_time": "2020-12-07T10:52:55.137268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of train set are (8523, 12)\n",
      "dimension of test set are (5681, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dimension of train set are {}\\ndimension of test set are {}\\n'.format(train.shape,test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.303872Z",
     "start_time": "2020-12-07T10:52:55.228902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.505996Z",
     "start_time": "2020-12-07T10:52:55.305871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.857645</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>140.992782</td>\n",
       "      <td>1997.831867</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.643456</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>62.275067</td>\n",
       "      <td>8.371760</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.773750</td>\n",
       "      <td>0.026989</td>\n",
       "      <td>93.826500</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>143.012800</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.850000</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>185.643700</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  7060.000000      8523.000000  8523.000000                8523.000000   \n",
       "mean     12.857645         0.066132   140.992782                1997.831867   \n",
       "std       4.643456         0.051598    62.275067                   8.371760   \n",
       "min       4.555000         0.000000    31.290000                1985.000000   \n",
       "25%       8.773750         0.026989    93.826500                1987.000000   \n",
       "50%      12.600000         0.053931   143.012800                1999.000000   \n",
       "75%      16.850000         0.094585   185.643700                2004.000000   \n",
       "max      21.350000         0.328391   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.552971Z",
     "start_time": "2020-12-07T10:52:55.507993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.630249Z",
     "start_time": "2020-12-07T10:52:55.558964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape is (8523, 11)\n",
      "ytrain shape is (8523,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Extracting X and y from train dataset\n",
    "X = train.iloc[:,0:-1]\n",
    "y =train['Item_Outlet_Sales']\n",
    "print(\"Xtrain shape is {}\\nytrain shape is {}\\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.862096Z",
     "start_time": "2020-12-07T10:52:55.633223Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "X['Outlet_Age']=X['Outlet_Establishment_Year'].max() - X['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:55.894085Z",
     "start_time": "2020-12-07T10:52:55.864104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Outlet_Age  \n",
       "0  Supermarket Type1          10  \n",
       "1  Supermarket Type2           0  \n",
       "2  Supermarket Type1          10  \n",
       "3      Grocery Store          11  \n",
       "4  Supermarket Type1          22  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.018982Z",
     "start_time": "2020-12-07T10:52:55.897083Z"
    }
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "X = X.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.234294Z",
     "start_time": "2020-12-07T10:52:56.020974Z"
    }
   },
   "outputs": [],
   "source": [
    "### Item visibilty of 0 does not make any sense so imputing these 0 values with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.405239Z",
     "start_time": "2020-12-07T10:52:56.236268Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Visibility']=X['Item_Visibility'].mask(X['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.466346Z",
     "start_time": "2020-12-07T10:52:56.407687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             1463\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          526\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             2410\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.591305Z",
     "start_time": "2020-12-07T10:52:56.468343Z"
    }
   },
   "outputs": [],
   "source": [
    "### missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.653469Z",
     "start_time": "2020-12-07T10:52:56.594277Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Weight'].fillna(X['Item_Weight'].mean(),inplace=True)\n",
    "X['Outlet_Size'].fillna(X['Outlet_Size'].mode()[0],inplace=True)\n",
    "X['Item_Visibility'].fillna(X['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.732096Z",
     "start_time": "2020-12-07T10:52:56.655436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             0\n",
       "Item_Fat_Content        0\n",
       "Item_Visibility         0\n",
       "Item_Type               0\n",
       "Item_MRP                0\n",
       "Outlet_Size             0\n",
       "Outlet_Location_Type    0\n",
       "Outlet_Type             0\n",
       "Outlet_Age              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.856043Z",
     "start_time": "2020-12-07T10:52:56.734095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5089\n",
       "Regular    2889\n",
       "LF          316\n",
       "reg         117\n",
       "low fat     112\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:56.948650Z",
     "start_time": "2020-12-07T10:52:56.858044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "X['Item_Fat_Content'] = X['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.011624Z",
     "start_time": "2020-12-07T10:52:56.950624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5517\n",
       "Regular    3006\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.089689Z",
     "start_time": "2020-12-07T10:52:57.013615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label encoding the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.243731Z",
     "start_time": "2020-12-07T10:52:57.091919Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Import label encoder \n",
    "# from sklearn import preprocessing\n",
    "# # label_encoder object knows how to understand word labels. \n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# X['Item_Fat_Content']=label_encoder.fit_transform(X['Item_Fat_Content']) \n",
    "# #,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "# X['Outlet_Size']=label_encoder.fit_transform(X['Outlet_Size'])\n",
    "# X['Outlet_Location_Type']=label_encoder.fit_transform(X['Outlet_Location_Type'])\n",
    "# X['Outlet_Type']=label_encoder.fit_transform(X['Outlet_Type'])\n",
    "# X['Item_Type']=label_encoder.fit_transform(X['Item_Type'])\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.415946Z",
     "start_time": "2020-12-07T10:52:57.253728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Fat_is_Low Fat</th>\n",
       "      <th>Fat_is_Regular</th>\n",
       "      <th>Type_is_Baking Goods</th>\n",
       "      <th>Type_is_Breads</th>\n",
       "      <th>Type_is_Breakfast</th>\n",
       "      <th>Type_is_Canned</th>\n",
       "      <th>...</th>\n",
       "      <th>Loc_is_Tier 1</th>\n",
       "      <th>Loc_is_Tier 2</th>\n",
       "      <th>Loc_is_Tier 3</th>\n",
       "      <th>Size_is_High</th>\n",
       "      <th>Size_is_Medium</th>\n",
       "      <th>Size_is_Small</th>\n",
       "      <th>Outlet_is_Grocery Store</th>\n",
       "      <th>Outlet_is_Supermarket Type1</th>\n",
       "      <th>Outlet_is_Supermarket Type2</th>\n",
       "      <th>Outlet_is_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Age  Fat_is_Low Fat  \\\n",
       "0         9.30         0.016047  249.8092          10               1   \n",
       "1         5.92         0.019278   48.2692           0               0   \n",
       "2        17.50         0.016760  141.6180          10               1   \n",
       "3        19.20         0.070482  182.0950          11               0   \n",
       "4         8.93         0.070482   53.8614          22               1   \n",
       "\n",
       "   Fat_is_Regular  Type_is_Baking Goods  Type_is_Breads  Type_is_Breakfast  \\\n",
       "0               0                     0               0                  0   \n",
       "1               1                     0               0                  0   \n",
       "2               0                     0               0                  0   \n",
       "3               1                     0               0                  0   \n",
       "4               0                     0               0                  0   \n",
       "\n",
       "   Type_is_Canned  ...  Loc_is_Tier 1  Loc_is_Tier 2  Loc_is_Tier 3  \\\n",
       "0               0  ...              1              0              0   \n",
       "1               0  ...              0              0              1   \n",
       "2               0  ...              1              0              0   \n",
       "3               0  ...              0              0              1   \n",
       "4               0  ...              0              0              1   \n",
       "\n",
       "   Size_is_High  Size_is_Medium  Size_is_Small  Outlet_is_Grocery Store  \\\n",
       "0             0               1              0                        0   \n",
       "1             0               1              0                        0   \n",
       "2             0               1              0                        0   \n",
       "3             0               1              0                        1   \n",
       "4             1               0              0                        0   \n",
       "\n",
       "   Outlet_is_Supermarket Type1  Outlet_is_Supermarket Type2  \\\n",
       "0                            1                            0   \n",
       "1                            0                            1   \n",
       "2                            1                            0   \n",
       "3                            0                            0   \n",
       "4                            1                            0   \n",
       "\n",
       "   Outlet_is_Supermarket Type3  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas dummy variables for categorical variables \n",
    "#pd.get_dummies(df, prefix=['A', 'D'], columns=['A', 'D'])\n",
    "X_dum=pd.get_dummies(X,columns=['Item_Fat_Content','Item_Type','Outlet_Location_Type','Outlet_Size','Outlet_Type'],prefix=['Fat_is','Type_is','Loc_is','Size_is','Outlet_is'])\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.556735Z",
     "start_time": "2020-12-07T10:52:57.418945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Weight',\n",
       " 'Item_Visibility',\n",
       " 'Item_MRP',\n",
       " 'Outlet_Age',\n",
       " 'Fat_is_Low Fat',\n",
       " 'Fat_is_Regular',\n",
       " 'Type_is_Baking Goods',\n",
       " 'Type_is_Breads',\n",
       " 'Type_is_Breakfast',\n",
       " 'Type_is_Canned',\n",
       " 'Type_is_Dairy',\n",
       " 'Type_is_Frozen Foods',\n",
       " 'Type_is_Fruits and Vegetables',\n",
       " 'Type_is_Hard Drinks',\n",
       " 'Type_is_Health and Hygiene',\n",
       " 'Type_is_Household',\n",
       " 'Type_is_Meat',\n",
       " 'Type_is_Others',\n",
       " 'Type_is_Seafood',\n",
       " 'Type_is_Snack Foods',\n",
       " 'Type_is_Soft Drinks',\n",
       " 'Type_is_Starchy Foods',\n",
       " 'Loc_is_Tier 1',\n",
       " 'Loc_is_Tier 2',\n",
       " 'Loc_is_Tier 3',\n",
       " 'Size_is_High',\n",
       " 'Size_is_Medium',\n",
       " 'Size_is_Small',\n",
       " 'Outlet_is_Grocery Store',\n",
       " 'Outlet_is_Supermarket Type1',\n",
       " 'Outlet_is_Supermarket Type2',\n",
       " 'Outlet_is_Supermarket Type3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_dum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.697646Z",
     "start_time": "2020-12-07T10:52:57.559732Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### checking correlation to check if there is any highly correlated variable\n",
    "# X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.759783Z",
     "start_time": "2020-12-07T10:52:57.699645Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"X shape is {} \\ny shape is {} \\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.836837Z",
     "start_time": "2020-12-07T10:52:57.761775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xdummy shape is (8523, 32) \n",
      "y shape is (8523,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Xdummy shape is {} \\ny shape is {} \\n\".format(X_dum.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:57.915218Z",
     "start_time": "2020-12-07T10:52:57.839837Z"
    }
   },
   "outputs": [],
   "source": [
    "# #normalizing the X from 0 to 1 using MinMaxScalar\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# min_max_scaler=MinMaxScaler()\n",
    "# X=min_max_scaler.fit_transform(X)\n",
    "# X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:58.024694Z",
     "start_time": "2020-12-07T10:52:57.917587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Fat_is_Low Fat</th>\n",
       "      <th>Fat_is_Regular</th>\n",
       "      <th>Type_is_Baking Goods</th>\n",
       "      <th>Type_is_Breads</th>\n",
       "      <th>Type_is_Breakfast</th>\n",
       "      <th>Type_is_Canned</th>\n",
       "      <th>...</th>\n",
       "      <th>Loc_is_Tier 1</th>\n",
       "      <th>Loc_is_Tier 2</th>\n",
       "      <th>Loc_is_Tier 3</th>\n",
       "      <th>Size_is_High</th>\n",
       "      <th>Size_is_Medium</th>\n",
       "      <th>Size_is_Small</th>\n",
       "      <th>Outlet_is_Grocery Store</th>\n",
       "      <th>Outlet_is_Supermarket Type1</th>\n",
       "      <th>Outlet_is_Supermarket Type2</th>\n",
       "      <th>Outlet_is_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>0.048346</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.040593</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>0.205985</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.205985</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Age  Fat_is_Low Fat  \\\n",
       "0     0.282525         0.038399  0.927507    0.416667               1   \n",
       "1     0.081274         0.048346  0.072068    0.000000               0   \n",
       "2     0.770765         0.040593  0.468288    0.416667               1   \n",
       "3     0.871986         0.205985  0.640093    0.458333               0   \n",
       "4     0.260494         0.205985  0.095805    0.916667               1   \n",
       "\n",
       "   Fat_is_Regular  Type_is_Baking Goods  Type_is_Breads  Type_is_Breakfast  \\\n",
       "0               0                     0               0                  0   \n",
       "1               1                     0               0                  0   \n",
       "2               0                     0               0                  0   \n",
       "3               1                     0               0                  0   \n",
       "4               0                     0               0                  0   \n",
       "\n",
       "   Type_is_Canned  ...  Loc_is_Tier 1  Loc_is_Tier 2  Loc_is_Tier 3  \\\n",
       "0               0  ...              1              0              0   \n",
       "1               0  ...              0              0              1   \n",
       "2               0  ...              1              0              0   \n",
       "3               0  ...              0              0              1   \n",
       "4               0  ...              0              0              1   \n",
       "\n",
       "   Size_is_High  Size_is_Medium  Size_is_Small  Outlet_is_Grocery Store  \\\n",
       "0             0               1              0                        0   \n",
       "1             0               1              0                        0   \n",
       "2             0               1              0                        0   \n",
       "3             0               1              0                        1   \n",
       "4             1               0              0                        0   \n",
       "\n",
       "   Outlet_is_Supermarket Type1  Outlet_is_Supermarket Type2  \\\n",
       "0                            1                            0   \n",
       "1                            0                            1   \n",
       "2                            1                            0   \n",
       "3                            0                            0   \n",
       "4                            1                            0   \n",
       "\n",
       "   Outlet_is_Supermarket Type3  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ['Item_Weight','Item_Visibility','Item_MRP','Outlet_Age',]:\n",
    "    X_dum[i] = (X_dum[i]-X_dum[i].min())/(X_dum[i].max()-X_dum[i].min())\n",
    "\n",
    "X_dum.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:58.118640Z",
     "start_time": "2020-12-07T10:52:58.027691Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalizing the continuous variables only\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# min_max_scaler=MinMaxScaler()\n",
    "# X_dum=min_max_scaler.fit_transform(X[['Item_Weight','Item_Visibility','Item_MRP','Outlet_Age',]])\n",
    "# X_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:58.196904Z",
     "start_time": "2020-12-07T10:52:58.120614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test Train split \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test= train_test_split(X,y, test_size = 0.3 ,shuffle = True,random_state =0)\n",
    "# print(X_train.shape,y_train.shape);print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:52:58.446034Z",
     "start_time": "2020-12-07T10:52:58.198849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5966, 32) (5966,)\n",
      "(2557, 32) (2557,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X_dum,y, test_size = 0.3 ,shuffle = True,random_state =0)\n",
    "print(X_train.shape,y_train.shape);print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:15.969842Z",
     "start_time": "2020-12-07T10:52:58.449033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building the Model using Keras\n",
    "from keras.models import Sequential\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense , Dropout\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:15.984833Z",
     "start_time": "2020-12-07T10:53:15.973839Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the input and output neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.419266Z",
     "start_time": "2020-12-07T10:53:15.989830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (Dense)          (None, 500)               16500     \n",
      "_________________________________________________________________\n",
      "Layer1 (Dense)               (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Layer2 (Dense)               (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "hidden_Layer3 (Dense)        (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "output_Layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 202,001\n",
      "Trainable params: 202,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(input_neurons,)))\n",
    "model.add(Dense(units=500,activation='relu',name='Input_Layer'))\n",
    "model.add(Dense(units=300,activation='relu',name='Layer1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=100,activation='relu',name='Layer2'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(units=50,activation='relu',name='hidden_Layer3'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=output_neurons,activation='linear',name ='output_Layer'))\n",
    "\n",
    "model.compile(loss= \"mse\" , optimizer=\"RMSprop\", metrics=[\"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:56:11.330666Z",
     "start_time": "2020-12-07T10:53:50.946689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5966 samples, validate on 2557 samples\n",
      "Epoch 1/500\n",
      "5966/5966 [==============================] - 1s 98us/step - loss: 7552093.0000 - mae: 2167.5007 - val_loss: 7941321.5000 - val_mae: 2212.7563\n",
      "Epoch 2/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 7548600.5000 - mae: 2166.7090 - val_loss: 7933550.5000 - val_mae: 2211.0388\n",
      "Epoch 3/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 7541144.5000 - mae: 2165.0366 - val_loss: 7919744.0000 - val_mae: 2207.9875\n",
      "Epoch 4/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 7527723.5000 - mae: 2161.9890 - val_loss: 7897187.5000 - val_mae: 2202.9897\n",
      "Epoch 5/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 7505627.5000 - mae: 2157.0159 - val_loss: 7862253.0000 - val_mae: 2195.2244\n",
      "Epoch 6/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 7470623.5000 - mae: 2149.1003 - val_loss: 7809864.0000 - val_mae: 2183.5208\n",
      "Epoch 7/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 7418923.5000 - mae: 2137.2056 - val_loss: 7736074.5000 - val_mae: 2166.9646\n",
      "Epoch 8/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 7346227.5000 - mae: 2120.5061 - val_loss: 7636574.5000 - val_mae: 2144.5283\n",
      "Epoch 9/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 7248812.5000 - mae: 2098.2078 - val_loss: 7506666.5000 - val_mae: 2115.0818\n",
      "Epoch 10/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 7121474.0000 - mae: 2068.8606 - val_loss: 7342165.0000 - val_mae: 2078.2219\n",
      "Epoch 11/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 6956719.5000 - mae: 2031.7101 - val_loss: 7137035.5000 - val_mae: 2033.2397\n",
      "Epoch 12/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 6752916.0000 - mae: 1985.9886 - val_loss: 6890606.0000 - val_mae: 1980.4482\n",
      "Epoch 13/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 6520914.5000 - mae: 1934.3837 - val_loss: 6605403.0000 - val_mae: 1919.7056\n",
      "Epoch 14/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 6256437.0000 - mae: 1875.9529 - val_loss: 6284196.0000 - val_mae: 1852.8522\n",
      "Epoch 15/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 5935856.5000 - mae: 1806.7101 - val_loss: 5928775.5000 - val_mae: 1780.3080\n",
      "Epoch 16/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 5593195.0000 - mae: 1734.8842 - val_loss: 5548461.0000 - val_mae: 1704.5061\n",
      "Epoch 17/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 5232430.5000 - mae: 1660.9285 - val_loss: 5153445.0000 - val_mae: 1628.0371\n",
      "Epoch 18/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 4857052.5000 - mae: 1583.3389 - val_loss: 4756421.0000 - val_mae: 1553.7373\n",
      "Epoch 19/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 4469719.0000 - mae: 1504.4159 - val_loss: 4368595.5000 - val_mae: 1484.7848\n",
      "Epoch 20/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 4133869.0000 - mae: 1440.0244 - val_loss: 4008751.7500 - val_mae: 1424.8579\n",
      "Epoch 21/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 3770124.0000 - mae: 1379.0814 - val_loss: 3683949.5000 - val_mae: 1372.7992\n",
      "Epoch 22/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 3473738.5000 - mae: 1329.9969 - val_loss: 3409377.2500 - val_mae: 1333.3551\n",
      "Epoch 23/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 3248588.2500 - mae: 1300.4406 - val_loss: 3189018.5000 - val_mae: 1306.1727\n",
      "Epoch 24/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 3034795.5000 - mae: 1271.4603 - val_loss: 3020832.0000 - val_mae: 1291.1407\n",
      "Epoch 25/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 2924431.5000 - mae: 1268.5154 - val_loss: 2905336.2500 - val_mae: 1285.4117\n",
      "Epoch 26/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2798765.5000 - mae: 1256.6562 - val_loss: 2826280.7500 - val_mae: 1284.4961\n",
      "Epoch 27/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2784566.2500 - mae: 1268.3722 - val_loss: 2777886.2500 - val_mae: 1285.4113\n",
      "Epoch 28/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2733813.2500 - mae: 1269.3942 - val_loss: 2745468.7500 - val_mae: 1286.2207\n",
      "Epoch 29/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2717684.0000 - mae: 1270.0129 - val_loss: 2720697.7500 - val_mae: 1286.7946\n",
      "Epoch 30/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2714869.5000 - mae: 1274.5674 - val_loss: 2701749.5000 - val_mae: 1286.2684\n",
      "Epoch 31/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 2685412.2500 - mae: 1270.6140 - val_loss: 2686020.7500 - val_mae: 1284.9329\n",
      "Epoch 32/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 2654225.7500 - mae: 1268.0468 - val_loss: 2671801.5000 - val_mae: 1283.3024\n",
      "Epoch 33/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2655418.5000 - mae: 1270.5272 - val_loss: 2659585.0000 - val_mae: 1280.7225\n",
      "Epoch 34/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2625472.5000 - mae: 1262.4194 - val_loss: 2647110.0000 - val_mae: 1278.3800\n",
      "Epoch 35/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2654264.5000 - mae: 1265.7273 - val_loss: 2635676.0000 - val_mae: 1275.4829\n",
      "Epoch 36/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2638868.0000 - mae: 1263.3635 - val_loss: 2623604.5000 - val_mae: 1272.9392\n",
      "Epoch 37/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2638737.5000 - mae: 1270.5205 - val_loss: 2613534.2500 - val_mae: 1269.3420\n",
      "Epoch 38/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 2608582.7500 - mae: 1256.5522 - val_loss: 2599329.7500 - val_mae: 1267.6272\n",
      "Epoch 39/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2596355.7500 - mae: 1254.6178 - val_loss: 2585470.7500 - val_mae: 1265.8323\n",
      "Epoch 40/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2585060.2500 - mae: 1253.3900 - val_loss: 2573131.5000 - val_mae: 1263.1393\n",
      "Epoch 41/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2602278.0000 - mae: 1259.8076 - val_loss: 2564476.2500 - val_mae: 1258.4170\n",
      "Epoch 42/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2534743.0000 - mae: 1240.7197 - val_loss: 2548679.2500 - val_mae: 1257.1552\n",
      "Epoch 43/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2536338.7500 - mae: 1239.1935 - val_loss: 2535318.2500 - val_mae: 1254.6346\n",
      "Epoch 44/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2531132.0000 - mae: 1242.5365 - val_loss: 2526357.5000 - val_mae: 1249.6677\n",
      "Epoch 45/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2527606.7500 - mae: 1237.7948 - val_loss: 2510609.0000 - val_mae: 1248.0502\n",
      "Epoch 46/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2526403.7500 - mae: 1239.7520 - val_loss: 2502003.5000 - val_mae: 1242.4423\n",
      "Epoch 47/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2491266.2500 - mae: 1225.7332 - val_loss: 2484714.2500 - val_mae: 1241.3469\n",
      "Epoch 48/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2460116.5000 - mae: 1225.1603 - val_loss: 2471091.5000 - val_mae: 1237.8845\n",
      "Epoch 49/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2489057.2500 - mae: 1230.5322 - val_loss: 2464893.0000 - val_mae: 1230.6127\n",
      "Epoch 50/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2457364.0000 - mae: 1217.3691 - val_loss: 2440522.5000 - val_mae: 1232.3303\n",
      "Epoch 51/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2471769.7500 - mae: 1229.4927 - val_loss: 2435246.2500 - val_mae: 1223.3680\n",
      "Epoch 52/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2417414.2500 - mae: 1208.1322 - val_loss: 2412005.5000 - val_mae: 1223.6981\n",
      "Epoch 53/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2425367.0000 - mae: 1217.0812 - val_loss: 2402551.0000 - val_mae: 1216.4373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2390698.0000 - mae: 1202.1935 - val_loss: 2380891.0000 - val_mae: 1215.6196\n",
      "Epoch 55/500\n",
      "5966/5966 [==============================] - 0s 41us/step - loss: 2379173.2500 - mae: 1201.8428 - val_loss: 2367800.5000 - val_mae: 1209.0518\n",
      "Epoch 56/500\n",
      "5966/5966 [==============================] - 0s 42us/step - loss: 2373545.2500 - mae: 1196.5574 - val_loss: 2347111.2500 - val_mae: 1206.8876\n",
      "Epoch 57/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2351348.5000 - mae: 1192.0958 - val_loss: 2334671.2500 - val_mae: 1199.1654\n",
      "Epoch 58/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2337180.0000 - mae: 1189.1216 - val_loss: 2312213.5000 - val_mae: 1197.0145\n",
      "Epoch 59/500\n",
      "5966/5966 [==============================] - 0s 42us/step - loss: 2321947.5000 - mae: 1184.6252 - val_loss: 2296951.2500 - val_mae: 1189.6451\n",
      "Epoch 60/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2301237.7500 - mae: 1178.9801 - val_loss: 2276966.5000 - val_mae: 1184.8374\n",
      "Epoch 61/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2268397.5000 - mae: 1167.5291 - val_loss: 2256303.7500 - val_mae: 1179.3350\n",
      "Epoch 62/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2254134.7500 - mae: 1165.2849 - val_loss: 2235402.5000 - val_mae: 1173.8716\n",
      "Epoch 63/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2223307.0000 - mae: 1159.2421 - val_loss: 2209542.7500 - val_mae: 1170.2915\n",
      "Epoch 64/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2214378.2500 - mae: 1152.8081 - val_loss: 2196623.7500 - val_mae: 1158.6500\n",
      "Epoch 65/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2194223.7500 - mae: 1142.5142 - val_loss: 2159108.5000 - val_mae: 1162.7128\n",
      "Epoch 66/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2180455.2500 - mae: 1152.8596 - val_loss: 2166802.5000 - val_mae: 1139.6625\n",
      "Epoch 67/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2132477.2500 - mae: 1114.2236 - val_loss: 2110815.7500 - val_mae: 1162.5818\n",
      "Epoch 68/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2157861.2500 - mae: 1154.7719 - val_loss: 2153814.5000 - val_mae: 1121.4298\n",
      "Epoch 69/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 2122565.5000 - mae: 1100.1774 - val_loss: 2070693.3750 - val_mae: 1151.3966\n",
      "Epoch 70/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2073043.7500 - mae: 1141.1334 - val_loss: 2102782.7500 - val_mae: 1111.2920\n",
      "Epoch 71/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2063678.0000 - mae: 1085.4966 - val_loss: 2032012.1250 - val_mae: 1132.1000\n",
      "Epoch 72/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 2078018.5000 - mae: 1124.1444 - val_loss: 2046438.7500 - val_mae: 1102.5503\n",
      "Epoch 73/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 2062792.5000 - mae: 1094.7343 - val_loss: 1993476.2500 - val_mae: 1115.5370\n",
      "Epoch 74/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1972055.6250 - mae: 1089.4421 - val_loss: 1993056.6250 - val_mae: 1093.4053\n",
      "Epoch 75/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1984883.7500 - mae: 1073.0847 - val_loss: 1952995.2500 - val_mae: 1100.3058\n",
      "Epoch 76/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1949716.3750 - mae: 1078.9165 - val_loss: 1954812.3750 - val_mae: 1078.4266\n",
      "Epoch 77/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1943653.1250 - mae: 1059.7238 - val_loss: 1908907.3750 - val_mae: 1088.9476\n",
      "Epoch 78/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1937787.6250 - mae: 1076.9558 - val_loss: 1921652.3750 - val_mae: 1061.6588\n",
      "Epoch 79/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1931409.3750 - mae: 1050.4547 - val_loss: 1865162.5000 - val_mae: 1081.7502\n",
      "Epoch 80/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1933148.6250 - mae: 1079.8470 - val_loss: 1899364.2500 - val_mae: 1043.8573\n",
      "Epoch 81/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1880009.6250 - mae: 1026.1766 - val_loss: 1826097.1250 - val_mae: 1071.0973\n",
      "Epoch 82/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1846890.7500 - mae: 1055.7047 - val_loss: 1857131.7500 - val_mae: 1031.6047\n",
      "Epoch 83/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1859128.1250 - mae: 1021.1864 - val_loss: 1789578.7500 - val_mae: 1050.1770\n",
      "Epoch 84/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1826628.7500 - mae: 1039.2269 - val_loss: 1796014.7500 - val_mae: 1023.8035\n",
      "Epoch 85/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1837632.2500 - mae: 1020.6622 - val_loss: 1754719.8750 - val_mae: 1030.1372\n",
      "Epoch 86/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1799867.6250 - mae: 1026.1484 - val_loss: 1755947.5000 - val_mae: 1010.3102\n",
      "Epoch 87/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1777473.0000 - mae: 1001.6166 - val_loss: 1713413.8750 - val_mae: 1019.4725\n",
      "Epoch 88/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1773572.6250 - mae: 1016.4305 - val_loss: 1732485.8750 - val_mae: 991.5136\n",
      "Epoch 89/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1742502.0000 - mae: 977.4330 - val_loss: 1675593.1250 - val_mae: 1010.7875\n",
      "Epoch 90/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1722181.7500 - mae: 1004.1558 - val_loss: 1712526.8750 - val_mae: 975.1053\n",
      "Epoch 91/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1729091.2500 - mae: 966.2150 - val_loss: 1642408.2500 - val_mae: 1001.2497\n",
      "Epoch 92/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1739643.8750 - mae: 1009.5062 - val_loss: 1704361.1250 - val_mae: 960.9191\n",
      "Epoch 93/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1688689.5000 - mae: 940.6483 - val_loss: 1613945.1250 - val_mae: 990.5500\n",
      "Epoch 94/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1670143.3750 - mae: 988.0389 - val_loss: 1655708.1250 - val_mae: 951.2996\n",
      "Epoch 95/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1667463.6250 - mae: 942.0621 - val_loss: 1585432.1250 - val_mae: 970.5070\n",
      "Epoch 96/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1667528.3750 - mae: 978.5997 - val_loss: 1603386.3750 - val_mae: 943.6990\n",
      "Epoch 97/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1626356.1250 - mae: 931.9903 - val_loss: 1561370.1250 - val_mae: 950.7911\n",
      "Epoch 98/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1615013.6250 - mae: 947.0820 - val_loss: 1563588.3750 - val_mae: 934.6767\n",
      "Epoch 99/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1627785.5000 - mae: 933.5317 - val_loss: 1533341.8750 - val_mae: 937.4836\n",
      "Epoch 100/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1603245.0000 - mae: 940.7089 - val_loss: 1545793.6250 - val_mae: 919.2747\n",
      "Epoch 101/500\n",
      "5966/5966 [==============================] - 0s 42us/step - loss: 1568677.0000 - mae: 913.9260 - val_loss: 1501478.5000 - val_mae: 934.2731\n",
      "Epoch 102/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1582373.1250 - mae: 937.0786 - val_loss: 1536438.8750 - val_mae: 904.8823\n",
      "Epoch 103/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1565030.5000 - mae: 898.9303 - val_loss: 1475348.5000 - val_mae: 923.6829\n",
      "Epoch 104/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1561418.8750 - mae: 929.8724 - val_loss: 1523259.8750 - val_mae: 893.5439\n",
      "Epoch 105/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1566674.8750 - mae: 890.7957 - val_loss: 1453548.7500 - val_mae: 917.2141\n",
      "Epoch 106/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1540294.6250 - mae: 922.9366 - val_loss: 1499405.7500 - val_mae: 883.7908\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 44us/step - loss: 1551495.2500 - mae: 888.1002 - val_loss: 1430985.3750 - val_mae: 898.4554\n",
      "Epoch 108/500\n",
      "5966/5966 [==============================] - 0s 42us/step - loss: 1519820.3750 - mae: 905.6912 - val_loss: 1465064.2500 - val_mae: 874.8515\n",
      "Epoch 109/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1489530.5000 - mae: 874.2249 - val_loss: 1409470.6250 - val_mae: 888.8102\n",
      "Epoch 110/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1475893.7500 - mae: 899.3328 - val_loss: 1450002.8750 - val_mae: 865.0752\n",
      "Epoch 111/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1489655.3750 - mae: 863.0587 - val_loss: 1390655.3750 - val_mae: 885.6406\n",
      "Epoch 112/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1466457.2500 - mae: 888.3117 - val_loss: 1442939.0000 - val_mae: 856.5563\n",
      "Epoch 113/500\n",
      "5966/5966 [==============================] - 0s 42us/step - loss: 1451583.0000 - mae: 845.9659 - val_loss: 1374763.0000 - val_mae: 878.9134\n",
      "Epoch 114/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1461675.5000 - mae: 894.0743 - val_loss: 1438388.2500 - val_mae: 850.1685\n",
      "Epoch 115/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1439667.6250 - mae: 839.9198 - val_loss: 1361708.5000 - val_mae: 873.4565\n",
      "Epoch 116/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1416484.8750 - mae: 875.3782 - val_loss: 1407262.6250 - val_mae: 844.5065\n",
      "Epoch 117/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1465114.7500 - mae: 846.2115 - val_loss: 1345700.2500 - val_mae: 856.6160\n",
      "Epoch 118/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1454017.3750 - mae: 873.9156 - val_loss: 1382700.0000 - val_mae: 839.2689\n",
      "Epoch 119/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1414587.3750 - mae: 836.2147 - val_loss: 1333336.7500 - val_mae: 850.5118\n",
      "Epoch 120/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1412369.7500 - mae: 863.9496 - val_loss: 1369738.2500 - val_mae: 834.0340\n",
      "Epoch 121/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1430592.0000 - mae: 839.0654 - val_loss: 1321940.7500 - val_mae: 849.7396\n",
      "Epoch 122/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1446125.0000 - mae: 870.3912 - val_loss: 1380774.5000 - val_mae: 829.8945\n",
      "Epoch 123/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1434644.7500 - mae: 839.0853 - val_loss: 1312957.2500 - val_mae: 846.5112\n",
      "Epoch 124/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1400001.3750 - mae: 854.6783 - val_loss: 1369251.0000 - val_mae: 826.2527\n",
      "Epoch 125/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1397177.7500 - mae: 821.9802 - val_loss: 1304150.3750 - val_mae: 841.5801\n",
      "Epoch 126/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1396731.2500 - mae: 851.5285 - val_loss: 1353462.0000 - val_mae: 822.6902\n",
      "Epoch 127/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1391462.5000 - mae: 822.5575 - val_loss: 1295443.6250 - val_mae: 835.9594\n",
      "Epoch 128/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1399825.2500 - mae: 845.4078 - val_loss: 1340166.2500 - val_mae: 819.5709\n",
      "Epoch 129/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1400222.2500 - mae: 828.3754 - val_loss: 1287953.2500 - val_mae: 830.9709\n",
      "Epoch 130/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1415835.6250 - mae: 854.7931 - val_loss: 1337409.1250 - val_mae: 817.1796\n",
      "Epoch 131/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1381614.3750 - mae: 817.9023 - val_loss: 1283117.6250 - val_mae: 830.8246\n",
      "Epoch 132/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1424285.2500 - mae: 853.0351 - val_loss: 1343616.0000 - val_mae: 816.1229\n",
      "Epoch 133/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1379807.0000 - mae: 812.4012 - val_loss: 1277908.0000 - val_mae: 828.0809\n",
      "Epoch 134/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1386323.3750 - mae: 845.5217 - val_loss: 1335623.6250 - val_mae: 813.8687\n",
      "Epoch 135/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1368578.8750 - mae: 810.5268 - val_loss: 1273088.7500 - val_mae: 824.4066\n",
      "Epoch 136/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1385020.3750 - mae: 842.0743 - val_loss: 1311261.6250 - val_mae: 810.3741\n",
      "Epoch 137/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1364357.5000 - mae: 816.0564 - val_loss: 1267319.7500 - val_mae: 817.6821\n",
      "Epoch 138/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1382399.6250 - mae: 837.7587 - val_loss: 1319268.1250 - val_mae: 809.7584\n",
      "Epoch 139/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1374635.5000 - mae: 816.3306 - val_loss: 1265409.3750 - val_mae: 820.1492\n",
      "Epoch 140/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1400503.3750 - mae: 845.9840 - val_loss: 1326668.6250 - val_mae: 809.6687\n",
      "Epoch 141/500\n",
      "5966/5966 [==============================] - 0s 58us/step - loss: 1354816.7500 - mae: 810.2504 - val_loss: 1263764.6250 - val_mae: 820.3256\n",
      "Epoch 142/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1356878.6250 - mae: 831.5361 - val_loss: 1312024.3750 - val_mae: 807.0773\n",
      "Epoch 143/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1368044.3750 - mae: 814.8845 - val_loss: 1257839.0000 - val_mae: 812.7177\n",
      "Epoch 144/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1375766.6250 - mae: 833.8271 - val_loss: 1306239.1250 - val_mae: 805.5973\n",
      "Epoch 145/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1385942.7500 - mae: 815.1143 - val_loss: 1254716.3750 - val_mae: 811.6703\n",
      "Epoch 146/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1360190.3750 - mae: 829.8109 - val_loss: 1311163.7500 - val_mae: 805.5615\n",
      "Epoch 147/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1386584.8750 - mae: 815.7217 - val_loss: 1254876.1250 - val_mae: 815.4682\n",
      "Epoch 148/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1377704.5000 - mae: 833.0438 - val_loss: 1312355.8750 - val_mae: 805.2982\n",
      "Epoch 149/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1348571.7500 - mae: 808.7598 - val_loss: 1252869.6250 - val_mae: 814.3448\n",
      "Epoch 150/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1359993.7500 - mae: 830.6852 - val_loss: 1314764.5000 - val_mae: 805.4139\n",
      "Epoch 151/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1370456.8750 - mae: 810.4306 - val_loss: 1251647.1250 - val_mae: 813.3743\n",
      "Epoch 152/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1357812.0000 - mae: 827.9885 - val_loss: 1310487.0000 - val_mae: 804.1484\n",
      "Epoch 153/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1380660.3750 - mae: 818.9423 - val_loss: 1247328.5000 - val_mae: 807.6141\n",
      "Epoch 154/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1355432.6250 - mae: 827.5854 - val_loss: 1303572.8750 - val_mae: 802.7399\n",
      "Epoch 155/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1329270.3750 - mae: 801.3560 - val_loss: 1246225.5000 - val_mae: 808.1509\n",
      "Epoch 156/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1318925.0000 - mae: 813.8589 - val_loss: 1283206.7500 - val_mae: 799.4235\n",
      "Epoch 157/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1357390.0000 - mae: 810.1053 - val_loss: 1243236.3750 - val_mae: 803.0919\n",
      "Epoch 158/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1355708.5000 - mae: 819.6494 - val_loss: 1275973.8750 - val_mae: 797.9427\n",
      "Epoch 159/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1333077.8750 - mae: 803.6718 - val_loss: 1241348.7500 - val_mae: 802.5197\n",
      "Epoch 160/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1341180.7500 - mae: 817.9149 - val_loss: 1283597.0000 - val_mae: 798.4466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1338952.7500 - mae: 803.9976 - val_loss: 1242172.7500 - val_mae: 805.8186\n",
      "Epoch 162/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1393873.6250 - mae: 831.1451 - val_loss: 1324971.8750 - val_mae: 805.4006\n",
      "Epoch 163/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1384040.2500 - mae: 813.0079 - val_loss: 1243250.8750 - val_mae: 807.3655\n",
      "Epoch 164/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1349730.3750 - mae: 822.6013 - val_loss: 1310480.7500 - val_mae: 802.2560\n",
      "Epoch 165/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1394636.2500 - mae: 815.7129 - val_loss: 1241243.6250 - val_mae: 805.6266\n",
      "Epoch 166/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1343994.6250 - mae: 818.0553 - val_loss: 1281391.8750 - val_mae: 797.1288\n",
      "Epoch 167/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1344110.7500 - mae: 805.1982 - val_loss: 1237724.7500 - val_mae: 799.9717\n",
      "Epoch 168/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1329483.0000 - mae: 817.2129 - val_loss: 1261838.2500 - val_mae: 794.4947\n",
      "Epoch 169/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1353248.1250 - mae: 809.6202 - val_loss: 1237393.6250 - val_mae: 796.6943\n",
      "Epoch 170/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1319029.6250 - mae: 809.4409 - val_loss: 1266910.7500 - val_mae: 794.5394\n",
      "Epoch 171/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1313826.0000 - mae: 799.9540 - val_loss: 1235685.7500 - val_mae: 799.3261\n",
      "Epoch 172/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1349219.7500 - mae: 816.2760 - val_loss: 1299741.3750 - val_mae: 799.5468\n",
      "Epoch 173/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1341691.7500 - mae: 804.0004 - val_loss: 1243237.5000 - val_mae: 808.7294\n",
      "Epoch 174/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1375578.7500 - mae: 831.2996 - val_loss: 1319942.5000 - val_mae: 803.3665\n",
      "Epoch 175/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1393184.2500 - mae: 816.8674 - val_loss: 1237233.3750 - val_mae: 803.7750\n",
      "Epoch 176/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1313770.0000 - mae: 813.1866 - val_loss: 1285170.0000 - val_mae: 796.3002\n",
      "Epoch 177/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1322361.7500 - mae: 795.9852 - val_loss: 1232912.3750 - val_mae: 797.5755\n",
      "Epoch 178/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1312629.3750 - mae: 809.0623 - val_loss: 1284553.0000 - val_mae: 795.9264\n",
      "Epoch 179/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1343591.6250 - mae: 807.4221 - val_loss: 1232572.5000 - val_mae: 796.6148\n",
      "Epoch 180/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1336406.3750 - mae: 815.1006 - val_loss: 1276863.8750 - val_mae: 794.2171\n",
      "Epoch 181/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1360759.2500 - mae: 806.1494 - val_loss: 1231990.2500 - val_mae: 796.5415\n",
      "Epoch 182/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1302731.7500 - mae: 805.9078 - val_loss: 1280879.5000 - val_mae: 794.3636\n",
      "Epoch 183/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1333022.6250 - mae: 799.2788 - val_loss: 1232614.8750 - val_mae: 798.0472\n",
      "Epoch 184/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1365125.5000 - mae: 824.6287 - val_loss: 1296970.1250 - val_mae: 797.0898\n",
      "Epoch 185/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1360382.5000 - mae: 811.4605 - val_loss: 1232737.7500 - val_mae: 799.0138\n",
      "Epoch 186/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1340038.6250 - mae: 818.3788 - val_loss: 1288012.2500 - val_mae: 795.2209\n",
      "Epoch 187/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1348339.3750 - mae: 801.5673 - val_loss: 1231409.0000 - val_mae: 797.9643\n",
      "Epoch 188/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1350360.0000 - mae: 822.3030 - val_loss: 1299218.6250 - val_mae: 797.0876\n",
      "Epoch 189/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1334180.3750 - mae: 801.2664 - val_loss: 1231777.1250 - val_mae: 799.1655\n",
      "Epoch 190/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1354898.3750 - mae: 819.5802 - val_loss: 1285237.2500 - val_mae: 794.2418\n",
      "Epoch 191/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1343989.2500 - mae: 804.0546 - val_loss: 1229081.1250 - val_mae: 795.4001\n",
      "Epoch 192/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1346264.6250 - mae: 817.5256 - val_loss: 1287860.6250 - val_mae: 794.5640\n",
      "Epoch 193/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1350092.6250 - mae: 804.6563 - val_loss: 1230359.7500 - val_mae: 797.6160\n",
      "Epoch 194/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1375405.3750 - mae: 820.7153 - val_loss: 1294302.8750 - val_mae: 795.4529\n",
      "Epoch 195/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1337695.8750 - mae: 799.6321 - val_loss: 1230404.7500 - val_mae: 798.0602\n",
      "Epoch 196/500\n",
      "5966/5966 [==============================] - 0s 54us/step - loss: 1363957.1250 - mae: 826.0379 - val_loss: 1285186.6250 - val_mae: 793.6564\n",
      "Epoch 197/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1344677.5000 - mae: 802.5671 - val_loss: 1229090.3750 - val_mae: 794.8334\n",
      "Epoch 198/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1333833.0000 - mae: 815.9854 - val_loss: 1279206.3750 - val_mae: 792.3038\n",
      "Epoch 199/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1350739.3750 - mae: 803.0474 - val_loss: 1228365.3750 - val_mae: 794.1196\n",
      "Epoch 200/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1356039.2500 - mae: 817.7250 - val_loss: 1288434.6250 - val_mae: 793.5977\n",
      "Epoch 201/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1346712.7500 - mae: 802.0936 - val_loss: 1227473.0000 - val_mae: 793.4551\n",
      "Epoch 202/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1339135.0000 - mae: 808.2271 - val_loss: 1273739.8750 - val_mae: 790.8984\n",
      "Epoch 203/500\n",
      "5966/5966 [==============================] - 0s 52us/step - loss: 1334263.3750 - mae: 797.5056 - val_loss: 1225949.1250 - val_mae: 792.0668\n",
      "Epoch 204/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1324222.0000 - mae: 811.2587 - val_loss: 1276185.6250 - val_mae: 790.9810\n",
      "Epoch 205/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1309226.2500 - mae: 792.5038 - val_loss: 1227570.7500 - val_mae: 795.6661\n",
      "Epoch 206/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1364211.8750 - mae: 816.4634 - val_loss: 1285349.6250 - val_mae: 792.4022\n",
      "Epoch 207/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1339926.0000 - mae: 801.2415 - val_loss: 1225636.6250 - val_mae: 793.2462\n",
      "Epoch 208/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 1341902.6250 - mae: 812.8005 - val_loss: 1282492.8750 - val_mae: 791.7504\n",
      "Epoch 209/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1377238.2500 - mae: 813.3520 - val_loss: 1224714.7500 - val_mae: 792.4110\n",
      "Epoch 210/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1358670.7500 - mae: 813.3745 - val_loss: 1285605.0000 - val_mae: 792.0925\n",
      "Epoch 211/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1354074.2500 - mae: 807.4496 - val_loss: 1224762.1250 - val_mae: 792.8357\n",
      "Epoch 212/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1374743.3750 - mae: 821.6566 - val_loss: 1304333.7500 - val_mae: 795.5332\n",
      "Epoch 213/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1342593.7500 - mae: 801.3077 - val_loss: 1226722.3750 - val_mae: 794.8717\n",
      "Epoch 214/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1340196.2500 - mae: 813.1797 - val_loss: 1278554.7500 - val_mae: 790.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1326238.1250 - mae: 798.1866 - val_loss: 1224029.5000 - val_mae: 792.1102\n",
      "Epoch 216/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1350847.7500 - mae: 813.3380 - val_loss: 1267641.3750 - val_mae: 788.4774\n",
      "Epoch 217/500\n",
      "5966/5966 [==============================] - 0s 55us/step - loss: 1342314.5000 - mae: 799.7438 - val_loss: 1223434.7500 - val_mae: 788.6184\n",
      "Epoch 218/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1298333.1250 - mae: 797.5241 - val_loss: 1246806.2500 - val_mae: 785.6514\n",
      "Epoch 219/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1293455.0000 - mae: 790.2623 - val_loss: 1222032.6250 - val_mae: 788.8101\n",
      "Epoch 220/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1312068.7500 - mae: 800.9549 - val_loss: 1271757.1250 - val_mae: 788.8504\n",
      "Epoch 221/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1339880.6250 - mae: 801.6611 - val_loss: 1222344.6250 - val_mae: 791.4262\n",
      "Epoch 222/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1294805.1250 - mae: 801.8751 - val_loss: 1280848.6250 - val_mae: 790.4352\n",
      "Epoch 223/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1335703.2500 - mae: 797.5066 - val_loss: 1226286.6250 - val_mae: 796.2414\n",
      "Epoch 224/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 1327563.5000 - mae: 810.2434 - val_loss: 1301899.1250 - val_mae: 794.4210\n",
      "Epoch 225/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1339493.7500 - mae: 797.4839 - val_loss: 1226110.5000 - val_mae: 796.0302\n",
      "Epoch 226/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1333119.1250 - mae: 814.0580 - val_loss: 1292156.1250 - val_mae: 792.3542\n",
      "Epoch 227/500\n",
      "5966/5966 [==============================] - 0s 43us/step - loss: 1313767.7500 - mae: 791.7997 - val_loss: 1222547.1250 - val_mae: 791.9568\n",
      "Epoch 228/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1293696.2500 - mae: 798.4487 - val_loss: 1266847.0000 - val_mae: 787.2679\n",
      "Epoch 229/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1336729.3750 - mae: 799.1937 - val_loss: 1220442.6250 - val_mae: 788.3182\n",
      "Epoch 230/500\n",
      "5966/5966 [==============================] - 0s 54us/step - loss: 1309929.0000 - mae: 802.9068 - val_loss: 1257906.7500 - val_mae: 785.7177\n",
      "Epoch 231/500\n",
      "5966/5966 [==============================] - 0s 52us/step - loss: 1312452.1250 - mae: 794.1666 - val_loss: 1219983.7500 - val_mae: 787.3186\n",
      "Epoch 232/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1328341.6250 - mae: 801.1370 - val_loss: 1257377.7500 - val_mae: 785.4999\n",
      "Epoch 233/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1296099.8750 - mae: 787.7498 - val_loss: 1219469.7500 - val_mae: 788.3165\n",
      "Epoch 234/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1325051.1250 - mae: 797.0346 - val_loss: 1263138.0000 - val_mae: 786.1514\n",
      "Epoch 235/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1304819.1250 - mae: 790.0546 - val_loss: 1218646.1250 - val_mae: 788.9919\n",
      "Epoch 236/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1323710.6250 - mae: 809.6804 - val_loss: 1261619.0000 - val_mae: 785.6839\n",
      "Epoch 237/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1288952.7500 - mae: 784.6758 - val_loss: 1218468.2500 - val_mae: 788.4833\n",
      "Epoch 238/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1321042.0000 - mae: 803.0353 - val_loss: 1280060.3750 - val_mae: 789.0750\n",
      "Epoch 239/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1341107.5000 - mae: 798.0948 - val_loss: 1222893.6250 - val_mae: 793.9595\n",
      "Epoch 240/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1336069.5000 - mae: 810.7462 - val_loss: 1318325.1250 - val_mae: 796.9331\n",
      "Epoch 241/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1369596.6250 - mae: 804.8133 - val_loss: 1222887.2500 - val_mae: 794.6130\n",
      "Epoch 242/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1338673.8750 - mae: 819.6332 - val_loss: 1280369.3750 - val_mae: 788.8629\n",
      "Epoch 243/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1342666.5000 - mae: 797.8781 - val_loss: 1217608.8750 - val_mae: 788.0710\n",
      "Epoch 244/500\n",
      "5966/5966 [==============================] - 0s 57us/step - loss: 1318888.3750 - mae: 803.5224 - val_loss: 1264102.1250 - val_mae: 785.6542\n",
      "Epoch 245/500\n",
      "5966/5966 [==============================] - 0s 56us/step - loss: 1304397.0000 - mae: 788.2378 - val_loss: 1217469.1250 - val_mae: 785.2720\n",
      "Epoch 246/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1295229.2500 - mae: 796.1752 - val_loss: 1245846.2500 - val_mae: 782.6931\n",
      "Epoch 247/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1294214.6250 - mae: 790.9332 - val_loss: 1217321.0000 - val_mae: 786.4841\n",
      "Epoch 248/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1315165.8750 - mae: 798.9531 - val_loss: 1265291.2500 - val_mae: 785.8112\n",
      "Epoch 249/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1350736.8750 - mae: 799.2197 - val_loss: 1217342.8750 - val_mae: 787.2349\n",
      "Epoch 250/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1346935.1250 - mae: 814.4955 - val_loss: 1292410.0000 - val_mae: 790.8198\n",
      "Epoch 251/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1342540.0000 - mae: 796.5223 - val_loss: 1222994.2500 - val_mae: 794.1906\n",
      "Epoch 252/500\n",
      "5966/5966 [==============================] - 0s 52us/step - loss: 1341994.0000 - mae: 816.4803 - val_loss: 1301697.3750 - val_mae: 792.6500\n",
      "Epoch 253/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 1325082.5000 - mae: 791.4604 - val_loss: 1220630.0000 - val_mae: 792.1648\n",
      "Epoch 254/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1353063.6250 - mae: 815.9782 - val_loss: 1272664.1250 - val_mae: 786.9682\n",
      "Epoch 255/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1328217.2500 - mae: 794.3713 - val_loss: 1216592.6250 - val_mae: 787.1536\n",
      "Epoch 256/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1312773.3750 - mae: 807.2788 - val_loss: 1251671.8750 - val_mae: 782.9534\n",
      "Epoch 257/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1293109.6250 - mae: 789.4915 - val_loss: 1216619.0000 - val_mae: 783.1635\n",
      "Epoch 258/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1279052.6250 - mae: 791.9274 - val_loss: 1242047.7500 - val_mae: 781.5756\n",
      "Epoch 259/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1322891.8750 - mae: 793.1930 - val_loss: 1215083.1250 - val_mae: 784.4449\n",
      "Epoch 260/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1294600.0000 - mae: 793.7768 - val_loss: 1254555.1250 - val_mae: 783.0927\n",
      "Epoch 261/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1337228.0000 - mae: 796.0356 - val_loss: 1215324.7500 - val_mae: 785.2458\n",
      "Epoch 262/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1335347.3750 - mae: 808.2403 - val_loss: 1285437.5000 - val_mae: 788.8662\n",
      "Epoch 263/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1375551.0000 - mae: 806.1544 - val_loss: 1220940.8750 - val_mae: 792.5205\n",
      "Epoch 264/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1324915.6250 - mae: 806.2877 - val_loss: 1295722.3750 - val_mae: 790.8871\n",
      "Epoch 265/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1344662.1250 - mae: 798.8860 - val_loss: 1219999.7500 - val_mae: 791.8575\n",
      "Epoch 266/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1330723.7500 - mae: 808.1541 - val_loss: 1274242.1250 - val_mae: 786.6680\n",
      "Epoch 267/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1297585.6250 - mae: 788.5859 - val_loss: 1215765.8750 - val_mae: 787.5779\n",
      "Epoch 268/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1318783.6250 - mae: 804.7197 - val_loss: 1266278.3750 - val_mae: 784.8732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1297327.8750 - mae: 782.7293 - val_loss: 1215129.0000 - val_mae: 786.8086\n",
      "Epoch 270/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1323187.3750 - mae: 807.8634 - val_loss: 1263007.3750 - val_mae: 784.3573\n",
      "Epoch 271/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1317975.5000 - mae: 789.4849 - val_loss: 1214273.3750 - val_mae: 785.1143\n",
      "Epoch 272/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1314057.2500 - mae: 801.4654 - val_loss: 1264006.7500 - val_mae: 784.2722\n",
      "Epoch 273/500\n",
      "5966/5966 [==============================] - 0s 44us/step - loss: 1351919.1250 - mae: 800.2234 - val_loss: 1214067.8750 - val_mae: 783.8655\n",
      "Epoch 274/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1338325.6250 - mae: 809.4202 - val_loss: 1253184.0000 - val_mae: 782.4288\n",
      "Epoch 275/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1330870.0000 - mae: 795.6279 - val_loss: 1212945.7500 - val_mae: 783.5148\n",
      "Epoch 276/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1274882.6250 - mae: 794.4202 - val_loss: 1268101.5000 - val_mae: 784.9797\n",
      "Epoch 277/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1312980.5000 - mae: 788.5070 - val_loss: 1217913.0000 - val_mae: 790.6402\n",
      "Epoch 278/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1334896.7500 - mae: 810.3089 - val_loss: 1294607.1250 - val_mae: 790.1059\n",
      "Epoch 279/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1334611.1250 - mae: 792.3970 - val_loss: 1218430.8750 - val_mae: 791.4597\n",
      "Epoch 280/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1315366.1250 - mae: 805.5333 - val_loss: 1286612.6250 - val_mae: 788.2692\n",
      "Epoch 281/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1330698.1250 - mae: 790.9766 - val_loss: 1214558.6250 - val_mae: 787.4569\n",
      "Epoch 282/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1297212.6250 - mae: 798.8140 - val_loss: 1253483.8750 - val_mae: 781.8706\n",
      "Epoch 283/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1333978.3750 - mae: 796.6880 - val_loss: 1211887.5000 - val_mae: 783.5652\n",
      "Epoch 284/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1300308.2500 - mae: 797.6199 - val_loss: 1245814.1250 - val_mae: 780.4952\n",
      "Epoch 285/500\n",
      "5966/5966 [==============================] - 0s 56us/step - loss: 1293053.8750 - mae: 787.5695 - val_loss: 1211338.2500 - val_mae: 782.2477\n",
      "Epoch 286/500\n",
      "5966/5966 [==============================] - 0s 56us/step - loss: 1285810.7500 - mae: 794.0710 - val_loss: 1255877.3750 - val_mae: 782.0863\n",
      "Epoch 287/500\n",
      "5966/5966 [==============================] - 0s 55us/step - loss: 1310116.6250 - mae: 785.0954 - val_loss: 1212814.8750 - val_mae: 785.8901\n",
      "Epoch 288/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1295784.7500 - mae: 799.3809 - val_loss: 1271622.0000 - val_mae: 785.0410\n",
      "Epoch 289/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1330456.5000 - mae: 793.6615 - val_loss: 1213018.8750 - val_mae: 786.5364\n",
      "Epoch 290/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1303694.5000 - mae: 800.7263 - val_loss: 1266599.2500 - val_mae: 783.9022\n",
      "Epoch 291/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1292799.1250 - mae: 785.2463 - val_loss: 1212480.6250 - val_mae: 785.7963\n",
      "Epoch 292/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1320092.0000 - mae: 805.9764 - val_loss: 1274644.5000 - val_mae: 785.5873\n",
      "Epoch 293/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1366246.3750 - mae: 800.6411 - val_loss: 1212742.2500 - val_mae: 786.5955\n",
      "Epoch 294/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1344516.6250 - mae: 807.0784 - val_loss: 1282884.3750 - val_mae: 787.1212\n",
      "Epoch 295/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1338367.0000 - mae: 795.7662 - val_loss: 1214188.3750 - val_mae: 788.0535\n",
      "Epoch 296/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1310236.2500 - mae: 803.7977 - val_loss: 1271374.6250 - val_mae: 784.7649\n",
      "Epoch 297/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1310398.2500 - mae: 790.9949 - val_loss: 1211383.2500 - val_mae: 784.6417\n",
      "Epoch 298/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1292022.2500 - mae: 792.9904 - val_loss: 1257685.0000 - val_mae: 782.1119\n",
      "Epoch 299/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1302011.0000 - mae: 783.0696 - val_loss: 1210103.7500 - val_mae: 782.3149\n",
      "Epoch 300/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1324563.1250 - mae: 803.3718 - val_loss: 1251241.8750 - val_mae: 780.9188\n",
      "Epoch 301/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1329540.5000 - mae: 791.5189 - val_loss: 1210230.7500 - val_mae: 781.4418\n",
      "Epoch 302/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1304204.1250 - mae: 799.0164 - val_loss: 1238276.0000 - val_mae: 778.8292\n",
      "Epoch 303/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1295933.7500 - mae: 791.1362 - val_loss: 1210755.8750 - val_mae: 779.5809\n",
      "Epoch 304/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1266455.6250 - mae: 786.5988 - val_loss: 1239937.5000 - val_mae: 778.8344\n",
      "Epoch 305/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1293138.0000 - mae: 783.5815 - val_loss: 1209836.5000 - val_mae: 781.4908\n",
      "Epoch 306/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1255383.1250 - mae: 786.6556 - val_loss: 1267898.7500 - val_mae: 783.6986\n",
      "Epoch 307/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1306905.7500 - mae: 792.1260 - val_loss: 1214500.8750 - val_mae: 788.6409\n",
      "Epoch 308/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1338775.0000 - mae: 810.4470 - val_loss: 1322390.6250 - val_mae: 795.9817\n",
      "Epoch 309/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1355075.0000 - mae: 796.1336 - val_loss: 1217904.3750 - val_mae: 791.8275\n",
      "Epoch 310/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1326723.8750 - mae: 812.2941 - val_loss: 1288742.3750 - val_mae: 788.1356\n",
      "Epoch 311/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1319873.3750 - mae: 791.1985 - val_loss: 1210925.6250 - val_mae: 785.4266\n",
      "Epoch 312/500\n",
      "5966/5966 [==============================] - 0s 55us/step - loss: 1295941.2500 - mae: 794.6783 - val_loss: 1251205.3750 - val_mae: 780.5200\n",
      "Epoch 313/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1323304.1250 - mae: 790.7938 - val_loss: 1208932.8750 - val_mae: 779.6843\n",
      "Epoch 314/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1288741.7500 - mae: 791.6733 - val_loss: 1245313.6250 - val_mae: 779.4493\n",
      "Epoch 315/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1291716.8750 - mae: 789.8771 - val_loss: 1207805.1250 - val_mae: 780.9173\n",
      "Epoch 316/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1325769.3750 - mae: 801.0368 - val_loss: 1263023.3750 - val_mae: 782.7021\n",
      "Epoch 317/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1289909.1250 - mae: 781.3745 - val_loss: 1209793.8750 - val_mae: 784.9183\n",
      "Epoch 318/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1308254.8750 - mae: 796.6019 - val_loss: 1276954.1250 - val_mae: 785.3530\n",
      "Epoch 319/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1318607.5000 - mae: 787.4785 - val_loss: 1209419.5000 - val_mae: 784.3444\n",
      "Epoch 320/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1288074.5000 - mae: 792.1911 - val_loss: 1258194.2500 - val_mae: 781.5493\n",
      "Epoch 321/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1286890.2500 - mae: 781.0321 - val_loss: 1209744.2500 - val_mae: 784.3231\n",
      "Epoch 322/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1307179.2500 - mae: 795.6917 - val_loss: 1260514.7500 - val_mae: 782.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1307450.6250 - mae: 787.2091 - val_loss: 1208633.7500 - val_mae: 783.2409\n",
      "Epoch 324/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1322721.2500 - mae: 796.3955 - val_loss: 1276375.5000 - val_mae: 785.2336\n",
      "Epoch 325/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1330715.2500 - mae: 791.6234 - val_loss: 1210379.6250 - val_mae: 785.0229\n",
      "Epoch 326/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1301511.7500 - mae: 795.3989 - val_loss: 1263749.6250 - val_mae: 782.6857\n",
      "Epoch 327/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1311570.3750 - mae: 790.0575 - val_loss: 1209516.6250 - val_mae: 784.3387\n",
      "Epoch 328/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1282909.5000 - mae: 793.6230 - val_loss: 1274448.7500 - val_mae: 784.6595\n",
      "Epoch 329/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1329436.6250 - mae: 792.0594 - val_loss: 1208917.1250 - val_mae: 783.9532\n",
      "Epoch 330/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1347639.1250 - mae: 806.7878 - val_loss: 1265691.6250 - val_mae: 782.8963\n",
      "Epoch 331/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1305673.0000 - mae: 785.9888 - val_loss: 1207584.6250 - val_mae: 782.2371\n",
      "Epoch 332/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1346826.3750 - mae: 806.0189 - val_loss: 1262519.3750 - val_mae: 782.1387\n",
      "Epoch 333/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1315543.8750 - mae: 786.0306 - val_loss: 1207512.5000 - val_mae: 783.2949\n",
      "Epoch 334/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1289505.3750 - mae: 794.8063 - val_loss: 1256188.6250 - val_mae: 781.0062\n",
      "Epoch 335/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1311004.2500 - mae: 787.5582 - val_loss: 1206939.1250 - val_mae: 779.5984\n",
      "Epoch 336/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1294983.6250 - mae: 794.8112 - val_loss: 1247657.6250 - val_mae: 779.4068\n",
      "Epoch 337/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1307434.7500 - mae: 785.0200 - val_loss: 1206691.0000 - val_mae: 781.0015\n",
      "Epoch 338/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1295927.5000 - mae: 793.7521 - val_loss: 1269081.6250 - val_mae: 783.6082\n",
      "Epoch 339/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1324105.6250 - mae: 793.2621 - val_loss: 1210788.0000 - val_mae: 786.5844\n",
      "Epoch 340/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1334197.6250 - mae: 807.8958 - val_loss: 1281149.6250 - val_mae: 786.1335\n",
      "Epoch 341/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1308294.3750 - mae: 785.8376 - val_loss: 1209547.0000 - val_mae: 785.1988\n",
      "Epoch 342/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1324934.1250 - mae: 803.9711 - val_loss: 1269927.7500 - val_mae: 783.5397\n",
      "Epoch 343/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1306926.1250 - mae: 783.4349 - val_loss: 1209028.1250 - val_mae: 784.5606\n",
      "Epoch 344/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1273719.5000 - mae: 789.2593 - val_loss: 1261813.7500 - val_mae: 781.8431\n",
      "Epoch 345/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1303414.1250 - mae: 787.2435 - val_loss: 1206560.5000 - val_mae: 781.3258\n",
      "Epoch 346/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1301712.2500 - mae: 797.8070 - val_loss: 1261469.5000 - val_mae: 781.6818\n",
      "Epoch 347/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1356152.5000 - mae: 789.9962 - val_loss: 1206090.8750 - val_mae: 779.9346\n",
      "Epoch 348/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1303934.1250 - mae: 792.9366 - val_loss: 1257711.8750 - val_mae: 780.7995\n",
      "Epoch 349/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1329693.3750 - mae: 790.5419 - val_loss: 1206521.7500 - val_mae: 781.1865\n",
      "Epoch 350/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1301212.1250 - mae: 796.7365 - val_loss: 1254990.7500 - val_mae: 780.4598\n",
      "Epoch 351/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1316676.0000 - mae: 789.3070 - val_loss: 1207064.0000 - val_mae: 782.0460\n",
      "Epoch 352/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1295408.5000 - mae: 794.8625 - val_loss: 1264706.3750 - val_mae: 782.2770\n",
      "Epoch 353/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1288076.6250 - mae: 778.2424 - val_loss: 1208330.0000 - val_mae: 784.3979\n",
      "Epoch 354/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1325136.7500 - mae: 801.2294 - val_loss: 1282543.5000 - val_mae: 786.0452\n",
      "Epoch 355/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1317921.3750 - mae: 789.2338 - val_loss: 1209447.6250 - val_mae: 785.4628\n",
      "Epoch 356/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1297125.6250 - mae: 798.5232 - val_loss: 1269724.6250 - val_mae: 783.1659\n",
      "Epoch 357/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1331388.8750 - mae: 787.5146 - val_loss: 1206061.0000 - val_mae: 781.5291\n",
      "Epoch 358/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1275172.5000 - mae: 792.7947 - val_loss: 1257885.2500 - val_mae: 780.6464\n",
      "Epoch 359/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1284205.1250 - mae: 777.3644 - val_loss: 1205659.8750 - val_mae: 781.3181\n",
      "Epoch 360/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1304972.5000 - mae: 804.4097 - val_loss: 1251897.1250 - val_mae: 779.2730\n",
      "Epoch 361/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1281782.5000 - mae: 780.6605 - val_loss: 1204949.3750 - val_mae: 781.1951\n",
      "Epoch 362/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1299939.7500 - mae: 795.5015 - val_loss: 1256402.1250 - val_mae: 780.2690\n",
      "Epoch 363/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1307187.3750 - mae: 783.3277 - val_loss: 1204380.1250 - val_mae: 779.3198\n",
      "Epoch 364/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1307907.8750 - mae: 802.1498 - val_loss: 1255516.2500 - val_mae: 780.0053\n",
      "Epoch 365/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1288789.2500 - mae: 781.4789 - val_loss: 1204008.0000 - val_mae: 780.8356\n",
      "Epoch 366/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1328048.8750 - mae: 802.0375 - val_loss: 1265396.0000 - val_mae: 781.9337\n",
      "Epoch 367/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1316199.6250 - mae: 789.7028 - val_loss: 1204771.8750 - val_mae: 781.1202\n",
      "Epoch 368/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1274001.7500 - mae: 793.6562 - val_loss: 1265828.2500 - val_mae: 782.0778\n",
      "Epoch 369/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1285669.3750 - mae: 778.6606 - val_loss: 1207894.1250 - val_mae: 785.0865\n",
      "Epoch 370/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1309088.1250 - mae: 803.1139 - val_loss: 1284339.0000 - val_mae: 786.2120\n",
      "Epoch 371/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1332831.1250 - mae: 791.1420 - val_loss: 1208494.7500 - val_mae: 785.5558\n",
      "Epoch 372/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1312015.5000 - mae: 805.9589 - val_loss: 1266127.5000 - val_mae: 782.1779\n",
      "Epoch 373/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1297315.3750 - mae: 778.9500 - val_loss: 1204039.0000 - val_mae: 780.3478\n",
      "Epoch 374/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1297957.3750 - mae: 796.0222 - val_loss: 1252969.6250 - val_mae: 779.3795\n",
      "Epoch 375/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1270285.5000 - mae: 773.1207 - val_loss: 1203557.1250 - val_mae: 778.0330\n",
      "Epoch 376/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1284140.7500 - mae: 788.5125 - val_loss: 1240314.6250 - val_mae: 777.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1301412.2500 - mae: 784.7369 - val_loss: 1204095.5000 - val_mae: 776.5586\n",
      "Epoch 378/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1288626.0000 - mae: 788.1141 - val_loss: 1241021.3750 - val_mae: 777.0136\n",
      "Epoch 379/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1285963.3750 - mae: 782.3807 - val_loss: 1203546.7500 - val_mae: 777.1313\n",
      "Epoch 380/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1249037.8750 - mae: 784.0990 - val_loss: 1246700.3750 - val_mae: 778.1048\n",
      "Epoch 381/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1249242.0000 - mae: 771.3699 - val_loss: 1205953.3750 - val_mae: 782.6253\n",
      "Epoch 382/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1284447.3750 - mae: 791.2750 - val_loss: 1282564.8750 - val_mae: 785.8494\n",
      "Epoch 383/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1323366.8750 - mae: 787.8315 - val_loss: 1214271.1250 - val_mae: 790.1774\n",
      "Epoch 384/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1316608.5000 - mae: 805.1143 - val_loss: 1298571.7500 - val_mae: 789.3005\n",
      "Epoch 385/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1331859.0000 - mae: 785.8929 - val_loss: 1208848.3750 - val_mae: 786.1104\n",
      "Epoch 386/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1320027.0000 - mae: 804.0584 - val_loss: 1261663.2500 - val_mae: 781.0706\n",
      "Epoch 387/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1345847.1250 - mae: 796.3924 - val_loss: 1204175.8750 - val_mae: 777.4368\n",
      "Epoch 388/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1303013.3750 - mae: 793.7734 - val_loss: 1243191.8750 - val_mae: 777.4344\n",
      "Epoch 389/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1302226.5000 - mae: 784.2924 - val_loss: 1204170.2500 - val_mae: 776.7594\n",
      "Epoch 390/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1304303.3750 - mae: 789.7978 - val_loss: 1227884.5000 - val_mae: 775.0476\n",
      "Epoch 391/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1291767.8750 - mae: 782.5608 - val_loss: 1205572.7500 - val_mae: 774.8898\n",
      "Epoch 392/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1264225.7500 - mae: 779.1323 - val_loss: 1224998.7500 - val_mae: 774.4869\n",
      "Epoch 393/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1269482.3750 - mae: 779.9342 - val_loss: 1203080.2500 - val_mae: 777.0208\n",
      "Epoch 394/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1315902.0000 - mae: 799.4822 - val_loss: 1272398.5000 - val_mae: 783.5377\n",
      "Epoch 395/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 1313917.5000 - mae: 787.8641 - val_loss: 1213547.8750 - val_mae: 790.0146\n",
      "Epoch 396/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1332875.8750 - mae: 812.0797 - val_loss: 1313580.7500 - val_mae: 792.9039\n",
      "Epoch 397/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1346775.7500 - mae: 786.4332 - val_loss: 1211755.0000 - val_mae: 788.9993\n",
      "Epoch 398/500\n",
      "5966/5966 [==============================] - 0s 53us/step - loss: 1335658.0000 - mae: 808.8187 - val_loss: 1293086.3750 - val_mae: 787.6743\n",
      "Epoch 399/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1317339.2500 - mae: 786.7579 - val_loss: 1204539.0000 - val_mae: 781.8209\n",
      "Epoch 400/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1321628.5000 - mae: 802.7540 - val_loss: 1251503.6250 - val_mae: 778.8853\n",
      "Epoch 401/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1289623.5000 - mae: 778.1708 - val_loss: 1203642.3750 - val_mae: 779.2057\n",
      "Epoch 402/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1311535.0000 - mae: 797.0389 - val_loss: 1248962.2500 - val_mae: 778.5232\n",
      "Epoch 403/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1280265.2500 - mae: 778.3038 - val_loss: 1203915.0000 - val_mae: 778.9196\n",
      "Epoch 404/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1295547.6250 - mae: 790.5822 - val_loss: 1245772.7500 - val_mae: 777.7847\n",
      "Epoch 405/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1289760.6250 - mae: 781.2662 - val_loss: 1203426.5000 - val_mae: 777.3828\n",
      "Epoch 406/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1264772.6250 - mae: 789.4929 - val_loss: 1239886.8750 - val_mae: 776.7882\n",
      "Epoch 407/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1286407.7500 - mae: 779.5721 - val_loss: 1203498.0000 - val_mae: 779.6568\n",
      "Epoch 408/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1282655.0000 - mae: 790.7736 - val_loss: 1257864.3750 - val_mae: 780.1140\n",
      "Epoch 409/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1269824.5000 - mae: 775.2024 - val_loss: 1205405.2500 - val_mae: 783.0726\n",
      "Epoch 410/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1273814.3750 - mae: 787.0096 - val_loss: 1268877.6250 - val_mae: 782.4714\n",
      "Epoch 411/500\n",
      "5966/5966 [==============================] - 0s 52us/step - loss: 1294202.1250 - mae: 774.2491 - val_loss: 1205578.3750 - val_mae: 783.7628\n",
      "Epoch 412/500\n",
      "5966/5966 [==============================] - 0s 52us/step - loss: 1306896.3750 - mae: 800.0469 - val_loss: 1285076.0000 - val_mae: 785.9937\n",
      "Epoch 413/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1307977.5000 - mae: 785.6783 - val_loss: 1207332.0000 - val_mae: 785.5275\n",
      "Epoch 414/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1315567.3750 - mae: 800.4377 - val_loss: 1269533.7500 - val_mae: 782.3759\n",
      "Epoch 415/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1297270.8750 - mae: 782.9213 - val_loss: 1202323.7500 - val_mae: 779.2302\n",
      "Epoch 416/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1281976.5000 - mae: 787.4041 - val_loss: 1240972.1250 - val_mae: 776.7386\n",
      "Epoch 417/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1273680.5000 - mae: 776.5852 - val_loss: 1201595.6250 - val_mae: 776.9284\n",
      "Epoch 418/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1296753.7500 - mae: 793.2839 - val_loss: 1238917.0000 - val_mae: 776.4688\n",
      "Epoch 419/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1253638.8750 - mae: 768.2372 - val_loss: 1201991.6250 - val_mae: 777.3198\n",
      "Epoch 420/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1314718.5000 - mae: 800.4454 - val_loss: 1247629.0000 - val_mae: 778.0561\n",
      "Epoch 421/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1312413.1250 - mae: 783.0126 - val_loss: 1201864.0000 - val_mae: 778.5688\n",
      "Epoch 422/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1269942.6250 - mae: 787.5283 - val_loss: 1269677.7500 - val_mae: 782.6548\n",
      "Epoch 423/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1328981.2500 - mae: 789.3428 - val_loss: 1207464.7500 - val_mae: 785.2231\n",
      "Epoch 424/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1310610.5000 - mae: 799.9537 - val_loss: 1283559.6250 - val_mae: 785.7849\n",
      "Epoch 425/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1314959.3750 - mae: 780.9766 - val_loss: 1207703.1250 - val_mae: 785.5493\n",
      "Epoch 426/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1303779.8750 - mae: 801.7073 - val_loss: 1270993.6250 - val_mae: 782.8167\n",
      "Epoch 427/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1318534.6250 - mae: 786.7590 - val_loss: 1203588.7500 - val_mae: 780.6520\n",
      "Epoch 428/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1296507.8750 - mae: 795.4571 - val_loss: 1259778.3750 - val_mae: 780.3931\n",
      "Epoch 429/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1295632.2500 - mae: 778.6050 - val_loss: 1203046.0000 - val_mae: 779.7681\n",
      "Epoch 430/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1312283.2500 - mae: 797.7177 - val_loss: 1259139.0000 - val_mae: 780.3331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1296825.2500 - mae: 779.4982 - val_loss: 1205059.8750 - val_mae: 783.0019\n",
      "Epoch 432/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1307002.6250 - mae: 795.7934 - val_loss: 1270278.7500 - val_mae: 782.6044\n",
      "Epoch 433/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1286116.6250 - mae: 779.6206 - val_loss: 1202448.3750 - val_mae: 779.1967\n",
      "Epoch 434/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1275116.0000 - mae: 787.4933 - val_loss: 1247580.3750 - val_mae: 777.9731\n",
      "Epoch 435/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1295903.2500 - mae: 782.4694 - val_loss: 1202486.2500 - val_mae: 778.7704\n",
      "Epoch 436/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1282396.3750 - mae: 787.1068 - val_loss: 1246636.0000 - val_mae: 777.9429\n",
      "Epoch 437/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1260197.7500 - mae: 777.0309 - val_loss: 1202803.2500 - val_mae: 779.0425\n",
      "Epoch 438/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1269628.7500 - mae: 787.3252 - val_loss: 1244842.2500 - val_mae: 777.5198\n",
      "Epoch 439/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1289216.2500 - mae: 777.3158 - val_loss: 1202895.7500 - val_mae: 778.6094\n",
      "Epoch 440/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1263679.3750 - mae: 779.6506 - val_loss: 1246513.5000 - val_mae: 777.8176\n",
      "Epoch 441/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1285789.8750 - mae: 781.8495 - val_loss: 1203252.1250 - val_mae: 780.0970\n",
      "Epoch 442/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1294229.8750 - mae: 795.2379 - val_loss: 1264936.8750 - val_mae: 781.5837\n",
      "Epoch 443/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1328039.3750 - mae: 788.6397 - val_loss: 1206705.1250 - val_mae: 784.5110\n",
      "Epoch 444/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1295849.1250 - mae: 796.7786 - val_loss: 1284001.0000 - val_mae: 785.8943\n",
      "Epoch 445/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1309160.0000 - mae: 783.7687 - val_loss: 1208211.7500 - val_mae: 785.8480\n",
      "Epoch 446/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1327466.6250 - mae: 801.5249 - val_loss: 1280020.2500 - val_mae: 784.8494\n",
      "Epoch 447/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1296004.1250 - mae: 782.2590 - val_loss: 1205065.1250 - val_mae: 782.7545\n",
      "Epoch 448/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1338838.1250 - mae: 803.2296 - val_loss: 1271005.6250 - val_mae: 782.8536\n",
      "Epoch 449/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1296538.5000 - mae: 778.2969 - val_loss: 1203266.5000 - val_mae: 780.5701\n",
      "Epoch 450/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1278768.2500 - mae: 786.0605 - val_loss: 1242043.3750 - val_mae: 776.9144\n",
      "Epoch 451/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1254826.6250 - mae: 767.6688 - val_loss: 1201789.1250 - val_mae: 777.5318\n",
      "Epoch 452/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1290236.1250 - mae: 790.9284 - val_loss: 1242887.6250 - val_mae: 777.0468\n",
      "Epoch 453/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1289528.7500 - mae: 780.1573 - val_loss: 1201549.1250 - val_mae: 779.1190\n",
      "Epoch 454/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1309551.1250 - mae: 795.7232 - val_loss: 1258162.2500 - val_mae: 780.0105\n",
      "Epoch 455/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1289973.7500 - mae: 779.7161 - val_loss: 1204998.7500 - val_mae: 783.7199\n",
      "Epoch 456/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1289376.1250 - mae: 798.9221 - val_loss: 1268430.3750 - val_mae: 782.2380\n",
      "Epoch 457/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1279475.7500 - mae: 774.2051 - val_loss: 1203131.5000 - val_mae: 781.7126\n",
      "Epoch 458/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1305531.0000 - mae: 793.6975 - val_loss: 1264066.6250 - val_mae: 781.0913\n",
      "Epoch 459/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1286941.8750 - mae: 776.4370 - val_loss: 1202859.8750 - val_mae: 781.6232\n",
      "Epoch 460/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1302983.0000 - mae: 799.9596 - val_loss: 1268940.6250 - val_mae: 782.2027\n",
      "Epoch 461/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 1303502.8750 - mae: 778.7629 - val_loss: 1201906.8750 - val_mae: 779.4572\n",
      "Epoch 462/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1295502.8750 - mae: 793.2833 - val_loss: 1249005.7500 - val_mae: 778.0588\n",
      "Epoch 463/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1317478.2500 - mae: 782.4548 - val_loss: 1201157.8750 - val_mae: 777.6634\n",
      "Epoch 464/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1284710.8750 - mae: 788.4736 - val_loss: 1240080.2500 - val_mae: 776.4746\n",
      "Epoch 465/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1263528.2500 - mae: 778.4941 - val_loss: 1201630.0000 - val_mae: 778.4351\n",
      "Epoch 466/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1303893.8750 - mae: 791.7577 - val_loss: 1252421.1250 - val_mae: 778.8224\n",
      "Epoch 467/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1314145.6250 - mae: 785.2500 - val_loss: 1201529.1250 - val_mae: 778.9669\n",
      "Epoch 468/500\n",
      "5966/5966 [==============================] - 0s 51us/step - loss: 1307562.0000 - mae: 795.2597 - val_loss: 1264292.0000 - val_mae: 781.3651\n",
      "Epoch 469/500\n",
      "5966/5966 [==============================] - 0s 54us/step - loss: 1280202.5000 - mae: 778.7576 - val_loss: 1202932.3750 - val_mae: 781.4698\n",
      "Epoch 470/500\n",
      "5966/5966 [==============================] - 0s 54us/step - loss: 1277691.1250 - mae: 789.5429 - val_loss: 1268298.7500 - val_mae: 782.2861\n",
      "Epoch 471/500\n",
      "5966/5966 [==============================] - 0s 56us/step - loss: 1296184.1250 - mae: 782.1311 - val_loss: 1204271.7500 - val_mae: 782.8408\n",
      "Epoch 472/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1321004.1250 - mae: 800.5459 - val_loss: 1263350.7500 - val_mae: 781.1055\n",
      "Epoch 473/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1291858.8750 - mae: 778.6537 - val_loss: 1203658.1250 - val_mae: 782.1273\n",
      "Epoch 474/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1276550.0000 - mae: 790.4418 - val_loss: 1253780.0000 - val_mae: 779.1232\n",
      "Epoch 475/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1285917.7500 - mae: 773.4883 - val_loss: 1201761.5000 - val_mae: 779.9070\n",
      "Epoch 476/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1267787.3750 - mae: 781.8604 - val_loss: 1257301.3750 - val_mae: 779.8161\n",
      "Epoch 477/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1276205.8750 - mae: 773.8047 - val_loss: 1202776.2500 - val_mae: 780.8218\n",
      "Epoch 478/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1275242.8750 - mae: 788.6117 - val_loss: 1261341.5000 - val_mae: 780.6865\n",
      "Epoch 479/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1289954.2500 - mae: 777.9042 - val_loss: 1203402.1250 - val_mae: 781.9393\n",
      "Epoch 480/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1269849.3750 - mae: 787.4690 - val_loss: 1250696.7500 - val_mae: 778.5131\n",
      "Epoch 481/500\n",
      "5966/5966 [==============================] - 0s 50us/step - loss: 1269921.8750 - mae: 767.0084 - val_loss: 1203392.6250 - val_mae: 781.4871\n",
      "Epoch 482/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1266680.8750 - mae: 787.8985 - val_loss: 1252315.5000 - val_mae: 778.7736\n",
      "Epoch 483/500\n",
      "5966/5966 [==============================] - 0s 48us/step - loss: 1297666.6250 - mae: 781.1190 - val_loss: 1201625.7500 - val_mae: 779.4142\n",
      "Epoch 484/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1288675.5000 - mae: 790.7996 - val_loss: 1249287.2500 - val_mae: 778.0609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1309405.2500 - mae: 782.4131 - val_loss: 1201758.3750 - val_mae: 780.1970\n",
      "Epoch 486/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1279027.3750 - mae: 790.6519 - val_loss: 1262646.6250 - val_mae: 780.8463\n",
      "Epoch 487/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1269636.7500 - mae: 771.6676 - val_loss: 1202976.3750 - val_mae: 781.7435\n",
      "Epoch 488/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1342953.3750 - mae: 809.2635 - val_loss: 1270497.6250 - val_mae: 782.6871\n",
      "Epoch 489/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1298984.3750 - mae: 785.0802 - val_loss: 1203997.7500 - val_mae: 782.2930\n",
      "Epoch 490/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1285622.7500 - mae: 797.1982 - val_loss: 1271964.0000 - val_mae: 783.1459\n",
      "Epoch 491/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1280697.5000 - mae: 777.8628 - val_loss: 1202400.6250 - val_mae: 780.1789\n",
      "Epoch 492/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1262554.3750 - mae: 783.1821 - val_loss: 1250583.8750 - val_mae: 778.5141\n",
      "Epoch 493/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1282354.2500 - mae: 776.5016 - val_loss: 1201185.2500 - val_mae: 778.9353\n",
      "Epoch 494/500\n",
      "5966/5966 [==============================] - 0s 47us/step - loss: 1275689.0000 - mae: 786.2986 - val_loss: 1246334.8750 - val_mae: 777.6951\n",
      "Epoch 495/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1291617.2500 - mae: 779.3560 - val_loss: 1200937.1250 - val_mae: 778.8432\n",
      "Epoch 496/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1307304.1250 - mae: 790.8533 - val_loss: 1247381.1250 - val_mae: 777.9800\n",
      "Epoch 497/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1282259.7500 - mae: 779.3025 - val_loss: 1200976.7500 - val_mae: 778.1823\n",
      "Epoch 498/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1292450.6250 - mae: 790.4619 - val_loss: 1258477.3750 - val_mae: 780.1613\n",
      "Epoch 499/500\n",
      "5966/5966 [==============================] - 0s 46us/step - loss: 1285643.5000 - mae: 780.1543 - val_loss: 1204578.1250 - val_mae: 783.4274\n",
      "Epoch 500/500\n",
      "5966/5966 [==============================] - 0s 45us/step - loss: 1297619.1250 - mae: 793.8207 - val_loss: 1279278.5000 - val_mae: 784.6657\n"
     ]
    }
   ],
   "source": [
    "# removing history from memory\n",
    "#del history\n",
    "# training the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=len(X_train),validation_data =(X_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:56:18.435251Z",
     "start_time": "2020-12-07T10:56:18.046492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076.2093234196254\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:56:22.517713Z",
     "start_time": "2020-12-07T10:56:22.106969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 64us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1158226.5124455246, 737.131591796875]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:56:29.799188Z",
     "start_time": "2020-12-07T10:56:29.077635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1edf28d1908>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, 500)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "#plt.figure(figure)\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"mae\"], label=\"train_MAE\")\n",
    "plt.plot(N, history.history[\"val_mae\"], label=\"val_MAE\")\n",
    "plt.title(\"Training Loss and Mean Absolute Error on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/MAE\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "#plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:56:59.626651Z",
     "start_time": "2020-12-07T10:56:59.614658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the same transformations to test dataset\n",
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "test['Outlet_Age']=test['Outlet_Establishment_Year'].max() - test['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:01.845269Z",
     "start_time": "2020-12-07T10:57:01.837277Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = test[['Item_Identifier','Outlet_Identifier']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:04.486631Z",
     "start_time": "2020-12-07T10:57:04.474636Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "test = test.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:05.909747Z",
     "start_time": "2020-12-07T10:57:05.888760Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Visibility']=test['Item_Visibility'].mask(test['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:07.268902Z",
     "start_time": "2020-12-07T10:57:07.247914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight              976\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          353\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             1606\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:09.283650Z",
     "start_time": "2020-12-07T10:57:09.270654Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Weight'].fillna(test['Item_Weight'].mean(),inplace=True)\n",
    "test['Outlet_Size'].fillna(test['Outlet_Size'].mode()[0],inplace=True)\n",
    "test['Item_Visibility'].fillna(test['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:10.487898Z",
     "start_time": "2020-12-07T10:57:10.472906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    3396\n",
       "Regular    1935\n",
       "LF          206\n",
       "reg          78\n",
       "low fat      66\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "test['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:13.347122Z",
     "start_time": "2020-12-07T10:57:13.337127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:15.251941Z",
     "start_time": "2020-12-07T10:57:15.238946Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Import label encoder \n",
    "# from sklearn import preprocessing\n",
    "# # label_encoder object knows how to understand word labels. \n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "# # Encode labels in column 'Country'. \n",
    "# test['Item_Fat_Content']=label_encoder.fit_transform(test['Item_Fat_Content']) \n",
    "# #,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "# test['Outlet_Size']=label_encoder.fit_transform(test['Outlet_Size'])\n",
    "# test['Outlet_Location_Type']=label_encoder.fit_transform(test['Outlet_Location_Type'])\n",
    "# test['Outlet_Type']=label_encoder.fit_transform(test['Outlet_Type'])\n",
    "# test['Item_Type']=label_encoder.fit_transform(test['Item_Type'])\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:57:45.425282Z",
     "start_time": "2020-12-07T10:57:45.366319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Fat_is_Low Fat</th>\n",
       "      <th>Fat_is_Regular</th>\n",
       "      <th>Type_is_Baking Goods</th>\n",
       "      <th>Type_is_Breads</th>\n",
       "      <th>Type_is_Breakfast</th>\n",
       "      <th>Type_is_Canned</th>\n",
       "      <th>...</th>\n",
       "      <th>Loc_is_Tier 1</th>\n",
       "      <th>Loc_is_Tier 2</th>\n",
       "      <th>Loc_is_Tier 3</th>\n",
       "      <th>Size_is_High</th>\n",
       "      <th>Size_is_Medium</th>\n",
       "      <th>Size_is_Small</th>\n",
       "      <th>Outlet_is_Grocery Store</th>\n",
       "      <th>Outlet_is_Supermarket Type1</th>\n",
       "      <th>Outlet_is_Supermarket Type2</th>\n",
       "      <th>Outlet_is_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.750000</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300000</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315000</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.695633</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Age  Fat_is_Low Fat  \\\n",
       "0    20.750000         0.007565  107.8622          10               1   \n",
       "1     8.300000         0.038428   87.3198           2               0   \n",
       "2    14.600000         0.099575  241.7538          11               1   \n",
       "3     7.315000         0.015388  155.0340           2               1   \n",
       "4    12.695633         0.118599  234.2300          24               0   \n",
       "\n",
       "   Fat_is_Regular  Type_is_Baking Goods  Type_is_Breads  Type_is_Breakfast  \\\n",
       "0               0                     0               0                  0   \n",
       "1               1                     0               0                  0   \n",
       "2               0                     0               0                  0   \n",
       "3               0                     0               0                  0   \n",
       "4               1                     0               0                  0   \n",
       "\n",
       "   Type_is_Canned  ...  Loc_is_Tier 1  Loc_is_Tier 2  Loc_is_Tier 3  \\\n",
       "0               0  ...              1              0              0   \n",
       "1               0  ...              0              1              0   \n",
       "2               0  ...              0              0              1   \n",
       "3               0  ...              0              1              0   \n",
       "4               0  ...              0              0              1   \n",
       "\n",
       "   Size_is_High  Size_is_Medium  Size_is_Small  Outlet_is_Grocery Store  \\\n",
       "0             0               1              0                        0   \n",
       "1             0               1              0                        0   \n",
       "2             0               1              0                        1   \n",
       "3             0               1              0                        0   \n",
       "4             0               1              0                        0   \n",
       "\n",
       "   Outlet_is_Supermarket Type1  Outlet_is_Supermarket Type2  \\\n",
       "0                            1                            0   \n",
       "1                            1                            0   \n",
       "2                            0                            0   \n",
       "3                            1                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   Outlet_is_Supermarket Type3  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dum=pd.get_dummies(test,columns=['Item_Fat_Content','Item_Type','Outlet_Location_Type','Outlet_Size','Outlet_Type'],prefix=['Fat_is','Type_is','Loc_is','Size_is','Outlet_is'])\n",
    "test_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.816388Z",
     "start_time": "2020-12-07T10:52:38.829Z"
    }
   },
   "outputs": [],
   "source": [
    "# #normalizing the test from 0 to 1 using MinMaxScalar\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# min_max_scaler=MinMaxScaler()\n",
    "# test=min_max_scaler.fit_transform(test)\n",
    "# test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.818388Z",
     "start_time": "2020-12-07T10:52:38.834Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in ['Item_Weight','Item_Visibility','Item_MRP','Outlet_Age',]:\n",
    "    test_dum[i] = (test_dum[i]-test_dum[i].min())/(test_dum[i].max()-test_dum[i].min())\n",
    "\n",
    "test_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.820385Z",
     "start_time": "2020-12-07T10:52:38.836Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.823383Z",
     "start_time": "2020-12-07T10:52:38.839Z"
    }
   },
   "outputs": [],
   "source": [
    "submission['Item_Outlet_Sales']=predictions\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T10:53:16.825383Z",
     "start_time": "2020-12-07T10:52:38.841Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission7.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
