{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Mart Sales Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:54:14.087401Z",
     "start_time": "2020-12-05T11:54:14.084401Z"
    }
   },
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:54.376125Z",
     "start_time": "2020-12-05T20:13:51.860822Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:55:08.808846Z",
     "start_time": "2020-12-05T11:55:08.790857Z"
    }
   },
   "source": [
    "### importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:54.438784Z",
     "start_time": "2020-12-05T20:13:54.378419Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the test and train csv files\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:54.547142Z",
     "start_time": "2020-12-05T20:13:54.441790Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data exploration of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:54.810396Z",
     "start_time": "2020-12-05T20:13:54.550145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of train set are (8523, 12)\n",
      "dimension of test set are (5681, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('dimension of train set are {}\\ndimension of test set are {}\\n'.format(train.shape,test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:54.979560Z",
     "start_time": "2020-12-05T20:13:54.813394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            8523 non-null   object \n",
      " 1   Item_Weight                7060 non-null   float64\n",
      " 2   Item_Fat_Content           8523 non-null   object \n",
      " 3   Item_Visibility            8523 non-null   float64\n",
      " 4   Item_Type                  8523 non-null   object \n",
      " 5   Item_MRP                   8523 non-null   float64\n",
      " 6   Outlet_Identifier          8523 non-null   object \n",
      " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
      " 8   Outlet_Size                6113 non-null   object \n",
      " 9   Outlet_Location_Type       8523 non-null   object \n",
      " 10  Outlet_Type                8523 non-null   object \n",
      " 11  Item_Outlet_Sales          8523 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.149721Z",
     "start_time": "2020-12-05T20:13:54.982549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.857645</td>\n",
       "      <td>0.066132</td>\n",
       "      <td>140.992782</td>\n",
       "      <td>1997.831867</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.643456</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>62.275067</td>\n",
       "      <td>8.371760</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.773750</td>\n",
       "      <td>0.026989</td>\n",
       "      <td>93.826500</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>143.012800</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.850000</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>185.643700</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_Weight  Item_Visibility     Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  7060.000000      8523.000000  8523.000000                8523.000000   \n",
       "mean     12.857645         0.066132   140.992782                1997.831867   \n",
       "std       4.643456         0.051598    62.275067                   8.371760   \n",
       "min       4.555000         0.000000    31.290000                1985.000000   \n",
       "25%       8.773750         0.026989    93.826500                1987.000000   \n",
       "50%      12.600000         0.053931   143.012800                1999.000000   \n",
       "75%      16.850000         0.094585   185.643700                2004.000000   \n",
       "max      21.350000         0.328391   266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.290994Z",
     "start_time": "2020-12-05T20:13:55.152718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.413789Z",
     "start_time": "2020-12-05T20:13:55.294991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape is (8523, 11)\n",
      "ytrain shape is (8523,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Extracting X and y from train dataset\n",
    "X = train.iloc[:,0:-1]\n",
    "y =train['Item_Outlet_Sales']\n",
    "print(\"Xtrain shape is {}\\nytrain shape is {}\\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.554440Z",
     "start_time": "2020-12-05T20:13:55.418785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "X['Outlet_Age']=X['Outlet_Establishment_Year'].max() - X['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.681149Z",
     "start_time": "2020-12-05T20:13:55.556310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Outlet_Age  \n",
       "0  Supermarket Type1          10  \n",
       "1  Supermarket Type2           0  \n",
       "2  Supermarket Type1          10  \n",
       "3      Grocery Store          11  \n",
       "4  Supermarket Type1          22  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.804814Z",
     "start_time": "2020-12-05T20:13:55.683146Z"
    }
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "X = X.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:55.943733Z",
     "start_time": "2020-12-05T20:13:55.806787Z"
    }
   },
   "outputs": [],
   "source": [
    "### Item visibilty of 0 does not make any sense so imputing these 0 values with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.067404Z",
     "start_time": "2020-12-05T20:13:55.945708Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Visibility']=X['Item_Visibility'].mask(X['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.255472Z",
     "start_time": "2020-12-05T20:13:56.069394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             1463\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          526\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             2410\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.440954Z",
     "start_time": "2020-12-05T20:13:56.258472Z"
    }
   },
   "outputs": [],
   "source": [
    "### missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.580817Z",
     "start_time": "2020-12-05T20:13:56.442926Z"
    }
   },
   "outputs": [],
   "source": [
    "X['Item_Weight'].fillna(X['Item_Weight'].mean(),inplace=True)\n",
    "X['Outlet_Size'].fillna(X['Outlet_Size'].mode()[0],inplace=True)\n",
    "X['Item_Visibility'].fillna(X['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.719701Z",
     "start_time": "2020-12-05T20:13:56.582788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight             0\n",
       "Item_Fat_Content        0\n",
       "Item_Visibility         0\n",
       "Item_Type               0\n",
       "Item_MRP                0\n",
       "Outlet_Size             0\n",
       "Outlet_Location_Type    0\n",
       "Outlet_Type             0\n",
       "Outlet_Age              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:56.860422Z",
     "start_time": "2020-12-05T20:13:56.722675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5089\n",
       "Regular    2889\n",
       "LF          316\n",
       "reg         117\n",
       "low fat     112\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.047642Z",
     "start_time": "2020-12-05T20:13:56.863393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "X['Item_Fat_Content'] = X['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.232554Z",
     "start_time": "2020-12-05T20:13:57.050639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    5517\n",
       "Regular    3006\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.416720Z",
     "start_time": "2020-12-05T20:13:57.235553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label encoding the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.557551Z",
     "start_time": "2020-12-05T20:13:57.419723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>4</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>14</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>10</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>6</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>9</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  Item_MRP  \\\n",
       "0         9.30                 0         0.016047          4  249.8092   \n",
       "1         5.92                 1         0.019278         14   48.2692   \n",
       "2        17.50                 0         0.016760         10  141.6180   \n",
       "3        19.20                 1         0.070482          6  182.0950   \n",
       "4         8.93                 0         0.070482          9   53.8614   \n",
       "\n",
       "   Outlet_Size  Outlet_Location_Type  Outlet_Type  Outlet_Age  \n",
       "0            1                     0            1          10  \n",
       "1            1                     2            2           0  \n",
       "2            1                     0            1          10  \n",
       "3            1                     2            0          11  \n",
       "4            0                     2            1          22  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "X['Item_Fat_Content']=label_encoder.fit_transform(X['Item_Fat_Content']) \n",
    "#,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "X['Outlet_Size']=label_encoder.fit_transform(X['Outlet_Size'])\n",
    "X['Outlet_Location_Type']=label_encoder.fit_transform(X['Outlet_Location_Type'])\n",
    "X['Outlet_Type']=label_encoder.fit_transform(X['Outlet_Type'])\n",
    "X['Item_Type']=label_encoder.fit_transform(X['Item_Type'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.758805Z",
     "start_time": "2020-12-05T20:13:57.563546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021157</td>\n",
       "      <td>-0.017763</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>-0.007225</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.008301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <td>-0.021157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>-0.139434</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>-0.017763</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035922</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>-0.179380</td>\n",
       "      <td>0.078316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Type</th>\n",
       "      <td>0.028015</td>\n",
       "      <td>-0.139434</td>\n",
       "      <td>-0.035922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>-0.004970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>-0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Size</th>\n",
       "      <td>-0.007225</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614311</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>-0.193389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <td>0.004088</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>-0.614311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467219</td>\n",
       "      <td>0.089216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.179380</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>0.467219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Age</th>\n",
       "      <td>0.008301</td>\n",
       "      <td>-0.003151</td>\n",
       "      <td>0.078316</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.193389</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.122304</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Item_Weight  Item_Fat_Content  Item_Visibility  \\\n",
       "Item_Weight              1.000000         -0.021157        -0.017763   \n",
       "Item_Fat_Content        -0.021157          1.000000         0.049915   \n",
       "Item_Visibility         -0.017763          0.049915         1.000000   \n",
       "Item_Type                0.028015         -0.139434        -0.035922   \n",
       "Item_MRP                 0.024756          0.006063        -0.005515   \n",
       "Outlet_Size             -0.007225         -0.000622         0.072297   \n",
       "Outlet_Location_Type     0.004088         -0.001598        -0.027742   \n",
       "Outlet_Type             -0.000566          0.002199        -0.179380   \n",
       "Outlet_Age               0.008301         -0.003151         0.078316   \n",
       "\n",
       "                      Item_Type  Item_MRP  Outlet_Size  Outlet_Location_Type  \\\n",
       "Item_Weight            0.028015  0.024756    -0.007225              0.004088   \n",
       "Item_Fat_Content      -0.139434  0.006063    -0.000622             -0.001598   \n",
       "Item_Visibility       -0.035922 -0.005515     0.072297             -0.027742   \n",
       "Item_Type              1.000000  0.032651    -0.001859              0.003084   \n",
       "Item_MRP               0.032651  1.000000     0.006059              0.000232   \n",
       "Outlet_Size           -0.001859  0.006059     1.000000             -0.614311   \n",
       "Outlet_Location_Type   0.003084  0.000232    -0.614311              1.000000   \n",
       "Outlet_Type            0.003053 -0.001975    -0.201483              0.467219   \n",
       "Outlet_Age            -0.004970 -0.005020    -0.193389              0.089216   \n",
       "\n",
       "                      Outlet_Type  Outlet_Age  \n",
       "Item_Weight             -0.000566    0.008301  \n",
       "Item_Fat_Content         0.002199   -0.003151  \n",
       "Item_Visibility         -0.179380    0.078316  \n",
       "Item_Type                0.003053   -0.004970  \n",
       "Item_MRP                -0.001975   -0.005020  \n",
       "Outlet_Size             -0.201483   -0.193389  \n",
       "Outlet_Location_Type     0.467219    0.089216  \n",
       "Outlet_Type              1.000000    0.122304  \n",
       "Outlet_Age               0.122304    1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking correlation to check if there is any highly correlated variable\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:57.929997Z",
     "start_time": "2020-12-05T20:13:57.762803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (8523, 9) \n",
      "y shape is (8523,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape is {} \\ny shape is {} \\n\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:58.069160Z",
     "start_time": "2020-12-05T20:13:57.932995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28252456, 0.        , 0.03839895, 0.26666667, 0.92750715,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.08127419, 1.        , 0.04834585, 0.93333333, 0.0720684 ,\n",
       "        0.5       , 1.        , 0.66666667, 0.        ],\n",
       "       [0.77076511, 0.        , 0.04059334, 0.66666667, 0.46828841,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.87198571, 1.        , 0.20598459, 0.4       , 0.64009348,\n",
       "        0.5       , 1.        , 0.        , 0.45833333],\n",
       "       [0.26049419, 0.        , 0.20598459, 0.6       , 0.09580456,\n",
       "        0.        , 1.        , 0.33333333, 0.91666667]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the X from 0 to 1 using MinMaxScalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler=MinMaxScaler()\n",
    "X=min_max_scaler.fit_transform(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:13:58.226160Z",
     "start_time": "2020-12-05T20:13:58.072159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5966, 9) (5966,)\n",
      "(2557, 9) (2557,)\n"
     ]
    }
   ],
   "source": [
    "# Test Train split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y, test_size = 0.3 ,shuffle = True,random_state =0)\n",
    "print(X_train.shape,y_train.shape);print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:14:01.002850Z",
     "start_time": "2020-12-05T20:13:58.229168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Building the Model using Keras\n",
    "from keras.models import Sequential\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense , Dropout\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:14:01.018847Z",
     "start_time": "2020-12-05T20:14:01.004854Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the input and output neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:14:01.222594Z",
     "start_time": "2020-12-05T20:14:01.021846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer1 (Dense)         (None, 500)               5000      \n",
      "_________________________________________________________________\n",
      "hidden_Layer1 (Dense)        (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "hidden_Layer2 (Dense)        (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "output_Layer (Dense)         (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 60,201\n",
      "Trainable params: 60,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(input_neurons,)))\n",
    "model.add(Dense(units=500,activation='relu',name='Input_Layer1'))\n",
    "model.add(Dense(units=100,activation='relu',name='hidden_Layer1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=50,activation='relu',name='hidden_Layer2'))\n",
    "model.add(Dense(units=output_neurons,activation='linear',name ='output_Layer'))\n",
    "\n",
    "model.compile(loss= \"mse\" , optimizer=\"RMSprop\", metrics=[\"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:14:01.269644Z",
     "start_time": "2020-12-05T20:14:01.225594Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(InputLayer(input_shape=(input_neurons,)))\n",
    "# model.add(Dense(units=64,activation='relu'))\n",
    "# model.add(Dense(units=32,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=16,activation='relu'))\n",
    "# model.add(Dense(units=output_neurons,activation='linear'))\n",
    "# learning_rate = 0.01\n",
    "# opt=RMSprop(lr=learning_rate)\n",
    "# #model.compile(loss='MSE', optimizer='Adam',metrics=['MAE'])\n",
    "# model.compile(optimizer=opt, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:15:28.407932Z",
     "start_time": "2020-12-05T20:14:16.386709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5966 samples, validate on 2557 samples\n",
      "Epoch 1/500\n",
      "5966/5966 [==============================] - 0s 49us/step - loss: 7544587.2746 - mae: 2165.8406 - val_loss: 7921720.4388 - val_mae: 2208.4885\n",
      "Epoch 2/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 7509492.3909 - mae: 2157.9600 - val_loss: 7861282.8221 - val_mae: 2195.3286\n",
      "Epoch 3/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 7429547.3711 - mae: 2140.0586 - val_loss: 7743968.6738 - val_mae: 2169.6372\n",
      "Epoch 4/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 7289759.6589 - mae: 2108.5864 - val_loss: 7561933.8852 - val_mae: 2129.4370\n",
      "Epoch 5/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 7086440.0789 - mae: 2062.9260 - val_loss: 7309309.5909 - val_mae: 2073.8071\n",
      "Epoch 6/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 6807152.1968 - mae: 2001.5012 - val_loss: 6983695.3516 - val_mae: 2004.6998\n",
      "Epoch 7/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 6472095.5458 - mae: 1929.2583 - val_loss: 6593771.7935 - val_mae: 1923.1279\n",
      "Epoch 8/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 6067065.0273 - mae: 1841.7847 - val_loss: 6137936.5330 - val_mae: 1830.3903\n",
      "Epoch 9/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 5597065.6881 - mae: 1744.4713 - val_loss: 5625524.2478 - val_mae: 1729.8015\n",
      "Epoch 10/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 5093925.2476 - mae: 1641.3523 - val_loss: 5084577.1924 - val_mae: 1627.6244\n",
      "Epoch 11/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 4557771.8661 - mae: 1536.1656 - val_loss: 4536301.3586 - val_mae: 1528.1982\n",
      "Epoch 12/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 4072221.0772 - mae: 1443.4138 - val_loss: 4019480.3637 - val_mae: 1441.4430\n",
      "Epoch 13/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 3600122.4522 - mae: 1357.8752 - val_loss: 3563335.0157 - val_mae: 1370.5990\n",
      "Epoch 14/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 3225186.6516 - mae: 1300.4569 - val_loss: 3206474.8326 - val_mae: 1322.3151\n",
      "Epoch 15/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 2956622.9070 - mae: 1270.9316 - val_loss: 2961383.5997 - val_mae: 1298.9835\n",
      "Epoch 16/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 2790048.7444 - mae: 1259.0154 - val_loss: 2823810.3925 - val_mae: 1293.4924\n",
      "Epoch 17/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 2712839.3704 - mae: 1263.7001 - val_loss: 2759735.2933 - val_mae: 1295.2878\n",
      "Epoch 18/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2669965.6338 - mae: 1265.7450 - val_loss: 2728062.6401 - val_mae: 1295.9010\n",
      "Epoch 19/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 2638393.2961 - mae: 1259.4717 - val_loss: 2704926.0655 - val_mae: 1293.0220\n",
      "Epoch 20/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 2616531.6421 - mae: 1261.9742 - val_loss: 2681751.1388 - val_mae: 1287.6775\n",
      "Epoch 21/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2600181.1889 - mae: 1258.1780 - val_loss: 2666697.5070 - val_mae: 1277.3053\n",
      "Epoch 22/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 2590715.3243 - mae: 1252.2164 - val_loss: 2632440.9293 - val_mae: 1273.3156\n",
      "Epoch 23/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2554127.7204 - mae: 1241.9806 - val_loss: 2594558.6558 - val_mae: 1270.9939\n",
      "Epoch 24/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2525350.9736 - mae: 1242.0250 - val_loss: 2579997.5193 - val_mae: 1254.6187\n",
      "Epoch 25/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2501789.2171 - mae: 1233.1194 - val_loss: 2534663.0570 - val_mae: 1250.3030\n",
      "Epoch 26/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2443019.3610 - mae: 1217.7456 - val_loss: 2487556.9637 - val_mae: 1247.6708\n",
      "Epoch 27/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2409640.2019 - mae: 1216.9137 - val_loss: 2460763.4836 - val_mae: 1230.8531\n",
      "Epoch 28/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2382479.5065 - mae: 1203.5510 - val_loss: 2416578.7000 - val_mae: 1224.5306\n",
      "Epoch 29/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2346880.2606 - mae: 1192.4991 - val_loss: 2374666.7486 - val_mae: 1213.5311\n",
      "Epoch 30/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 2284385.3090 - mae: 1184.2588 - val_loss: 2340270.7882 - val_mae: 1197.0708\n",
      "Epoch 31/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2251623.3619 - mae: 1166.2205 - val_loss: 2283679.4494 - val_mae: 1190.5214\n",
      "Epoch 32/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 2207999.7498 - mae: 1158.4199 - val_loss: 2244867.9487 - val_mae: 1170.0179\n",
      "Epoch 33/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2158484.0948 - mae: 1143.4086 - val_loss: 2183855.2395 - val_mae: 1158.5238\n",
      "Epoch 34/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2135758.3451 - mae: 1134.7306 - val_loss: 2127262.3644 - val_mae: 1143.6088\n",
      "Epoch 35/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 2069659.7641 - mae: 1116.5477 - val_loss: 2065618.4328 - val_mae: 1130.1058\n",
      "Epoch 36/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 2005755.6535 - mae: 1092.7854 - val_loss: 2008956.8432 - val_mae: 1117.9054\n",
      "Epoch 37/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1957391.9560 - mae: 1085.9437 - val_loss: 1965438.1476 - val_mae: 1089.0685\n",
      "Epoch 38/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1918772.5600 - mae: 1067.2418 - val_loss: 1910343.7739 - val_mae: 1070.0320\n",
      "Epoch 39/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1857224.0959 - mae: 1044.2827 - val_loss: 1846379.0902 - val_mae: 1057.5042\n",
      "Epoch 40/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1823916.3486 - mae: 1033.4673 - val_loss: 1797849.0233 - val_mae: 1035.1014\n",
      "Epoch 41/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1758601.0566 - mae: 1005.1033 - val_loss: 1746815.1433 - val_mae: 1021.0159\n",
      "Epoch 42/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1701061.9140 - mae: 987.6202 - val_loss: 1707086.3291 - val_mae: 1000.0699\n",
      "Epoch 43/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1669943.7614 - mae: 972.9807 - val_loss: 1662556.4158 - val_mae: 985.5355\n",
      "Epoch 44/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1649218.6027 - mae: 960.9872 - val_loss: 1641354.7398 - val_mae: 966.2191\n",
      "Epoch 45/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1626057.9796 - mae: 943.8412 - val_loss: 1598693.4619 - val_mae: 962.5551\n",
      "Epoch 46/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1574739.0009 - mae: 930.8212 - val_loss: 1569983.7458 - val_mae: 953.7903\n",
      "Epoch 47/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1600851.9505 - mae: 930.5168 - val_loss: 1556070.3008 - val_mae: 939.3004\n",
      "Epoch 48/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1553030.8034 - mae: 919.9814 - val_loss: 1542171.3794 - val_mae: 930.3801\n",
      "Epoch 49/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1527621.5216 - mae: 907.5405 - val_loss: 1527034.7047 - val_mae: 924.2516\n",
      "Epoch 50/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1535171.6619 - mae: 906.3565 - val_loss: 1508700.6942 - val_mae: 925.2620\n",
      "Epoch 51/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1505651.8414 - mae: 896.3250 - val_loss: 1508773.0614 - val_mae: 914.9068\n",
      "Epoch 52/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1516273.4396 - mae: 896.1583 - val_loss: 1493428.5480 - val_mae: 916.5697\n",
      "Epoch 53/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1494829.7010 - mae: 892.4447 - val_loss: 1497529.5166 - val_mae: 909.6180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1506107.8445 - mae: 896.8900 - val_loss: 1488737.7285 - val_mae: 909.2889\n",
      "Epoch 55/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1512648.0486 - mae: 896.3821 - val_loss: 1485503.5084 - val_mae: 907.6118\n",
      "Epoch 56/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1488919.1427 - mae: 890.0475 - val_loss: 1477199.6053 - val_mae: 910.1840\n",
      "Epoch 57/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1471449.0013 - mae: 882.2944 - val_loss: 1475761.9400 - val_mae: 913.7120\n",
      "Epoch 58/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1519884.5031 - mae: 902.8643 - val_loss: 1484469.5580 - val_mae: 902.6082\n",
      "Epoch 59/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1500851.7509 - mae: 890.8807 - val_loss: 1472401.9093 - val_mae: 905.9699\n",
      "Epoch 60/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1494254.5742 - mae: 895.3124 - val_loss: 1494843.2368 - val_mae: 900.6179\n",
      "Epoch 61/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1482869.8222 - mae: 887.8915 - val_loss: 1469609.1837 - val_mae: 905.6638\n",
      "Epoch 62/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1499195.3445 - mae: 891.2920 - val_loss: 1493460.7325 - val_mae: 899.2357\n",
      "Epoch 63/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1483493.6021 - mae: 886.1948 - val_loss: 1467090.5804 - val_mae: 903.1441\n",
      "Epoch 64/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1487001.6636 - mae: 882.8374 - val_loss: 1478752.2803 - val_mae: 898.7940\n",
      "Epoch 65/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1487663.8742 - mae: 885.6592 - val_loss: 1477928.7873 - val_mae: 898.0734\n",
      "Epoch 66/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1493180.2930 - mae: 885.3651 - val_loss: 1463200.7266 - val_mae: 903.8863\n",
      "Epoch 67/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1488630.7252 - mae: 891.5867 - val_loss: 1462264.7564 - val_mae: 901.5008\n",
      "Epoch 68/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1527214.5702 - mae: 898.1372 - val_loss: 1468818.9760 - val_mae: 897.1282\n",
      "Epoch 69/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1490418.3965 - mae: 883.1385 - val_loss: 1467988.0004 - val_mae: 896.4470\n",
      "Epoch 70/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1512656.5590 - mae: 891.5301 - val_loss: 1473468.7591 - val_mae: 895.1524\n",
      "Epoch 71/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1474486.9870 - mae: 876.9640 - val_loss: 1467334.4216 - val_mae: 894.9667\n",
      "Epoch 72/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1469150.6357 - mae: 879.4155 - val_loss: 1466885.0293 - val_mae: 894.1934\n",
      "Epoch 73/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1516228.7712 - mae: 889.8656 - val_loss: 1456930.7077 - val_mae: 895.9480\n",
      "Epoch 74/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1487082.9536 - mae: 882.2117 - val_loss: 1466005.9255 - val_mae: 892.5292\n",
      "Epoch 75/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1470470.9523 - mae: 879.6556 - val_loss: 1454444.0341 - val_mae: 893.5684\n",
      "Epoch 76/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1477377.6172 - mae: 882.4171 - val_loss: 1489565.2134 - val_mae: 891.3283\n",
      "Epoch 77/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1449123.7308 - mae: 873.5368 - val_loss: 1447697.8633 - val_mae: 895.2411\n",
      "Epoch 78/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1492370.2845 - mae: 883.6683 - val_loss: 1461341.1709 - val_mae: 889.2413\n",
      "Epoch 79/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1464826.6792 - mae: 875.1262 - val_loss: 1447368.9034 - val_mae: 890.8952\n",
      "Epoch 80/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1470929.1135 - mae: 876.4908 - val_loss: 1449403.9207 - val_mae: 889.1644\n",
      "Epoch 81/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1465203.9396 - mae: 875.5555 - val_loss: 1449783.9973 - val_mae: 887.9678\n",
      "Epoch 82/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1445280.8449 - mae: 871.8032 - val_loss: 1461993.8165 - val_mae: 886.0723\n",
      "Epoch 83/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1479971.5850 - mae: 879.1514 - val_loss: 1444183.6951 - val_mae: 886.7231\n",
      "Epoch 84/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1471898.1791 - mae: 876.7264 - val_loss: 1438321.5202 - val_mae: 887.2292\n",
      "Epoch 85/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1469008.3114 - mae: 872.0609 - val_loss: 1437419.3610 - val_mae: 885.3412\n",
      "Epoch 86/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1433312.0039 - mae: 864.9324 - val_loss: 1447859.1835 - val_mae: 882.1886\n",
      "Epoch 87/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1469859.2886 - mae: 873.0189 - val_loss: 1448289.3535 - val_mae: 881.2687\n",
      "Epoch 88/500\n",
      "5966/5966 [==============================] - 0s 19us/step - loss: 1479101.4670 - mae: 876.0725 - val_loss: 1441171.7695 - val_mae: 880.5603\n",
      "Epoch 89/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1480482.9879 - mae: 876.1646 - val_loss: 1427393.1429 - val_mae: 894.7867\n",
      "Epoch 90/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1465382.0527 - mae: 873.9099 - val_loss: 1433995.4612 - val_mae: 878.6977\n",
      "Epoch 91/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1433969.3532 - mae: 863.5728 - val_loss: 1421879.4495 - val_mae: 880.8163\n",
      "Epoch 92/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1443619.0970 - mae: 867.1818 - val_loss: 1416561.8917 - val_mae: 882.3029\n",
      "Epoch 93/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1443460.6637 - mae: 868.4611 - val_loss: 1469791.4062 - val_mae: 877.2893\n",
      "Epoch 94/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1436662.3072 - mae: 862.7933 - val_loss: 1411731.6408 - val_mae: 881.2774\n",
      "Epoch 95/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1442208.7917 - mae: 866.9989 - val_loss: 1413869.8907 - val_mae: 874.7780\n",
      "Epoch 96/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1441061.6769 - mae: 866.1055 - val_loss: 1408745.2930 - val_mae: 876.6295\n",
      "Epoch 97/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1418746.7909 - mae: 862.0234 - val_loss: 1430542.6307 - val_mae: 870.6774\n",
      "Epoch 98/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1453129.1423 - mae: 864.6852 - val_loss: 1403866.0766 - val_mae: 874.6046\n",
      "Epoch 99/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1444233.3681 - mae: 863.0840 - val_loss: 1401283.0978 - val_mae: 874.2847\n",
      "Epoch 100/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1443231.1115 - mae: 867.1042 - val_loss: 1400648.1676 - val_mae: 870.7135\n",
      "Epoch 101/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1404494.5636 - mae: 858.7245 - val_loss: 1398906.6033 - val_mae: 868.2468\n",
      "Epoch 102/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1432086.1829 - mae: 863.4515 - val_loss: 1391990.5783 - val_mae: 873.5231\n",
      "Epoch 103/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1439801.9687 - mae: 858.4352 - val_loss: 1404488.3532 - val_mae: 864.1704\n",
      "Epoch 104/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1424978.0189 - mae: 858.2069 - val_loss: 1393840.1579 - val_mae: 864.4371\n",
      "Epoch 105/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1392492.6426 - mae: 848.6397 - val_loss: 1384030.3736 - val_mae: 871.2609\n",
      "Epoch 106/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1423019.3354 - mae: 858.7588 - val_loss: 1387998.2740 - val_mae: 861.7233\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 22us/step - loss: 1399916.1152 - mae: 848.2203 - val_loss: 1377967.0067 - val_mae: 866.5619\n",
      "Epoch 108/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1400090.0231 - mae: 853.8317 - val_loss: 1385260.2901 - val_mae: 858.2101\n",
      "Epoch 109/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1415723.3326 - mae: 852.6198 - val_loss: 1372715.7347 - val_mae: 863.6205\n",
      "Epoch 110/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1416698.5641 - mae: 858.3204 - val_loss: 1386552.8657 - val_mae: 855.4785\n",
      "Epoch 111/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1388144.5678 - mae: 850.4495 - val_loss: 1379368.9951 - val_mae: 855.1398\n",
      "Epoch 112/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1389919.9614 - mae: 847.7507 - val_loss: 1373172.0815 - val_mae: 853.7889\n",
      "Epoch 113/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1397327.1114 - mae: 847.4009 - val_loss: 1370434.6824 - val_mae: 853.1852\n",
      "Epoch 114/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1393844.7153 - mae: 843.6386 - val_loss: 1374563.4483 - val_mae: 850.7933\n",
      "Epoch 115/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1390937.0376 - mae: 849.0514 - val_loss: 1360227.3154 - val_mae: 851.8999\n",
      "Epoch 116/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1407153.7888 - mae: 851.7452 - val_loss: 1363454.2203 - val_mae: 849.2349\n",
      "Epoch 117/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1388217.6945 - mae: 841.9333 - val_loss: 1351516.2728 - val_mae: 851.4443\n",
      "Epoch 118/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1393448.6764 - mae: 842.4144 - val_loss: 1362940.7108 - val_mae: 846.6805\n",
      "Epoch 119/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1379028.6869 - mae: 840.3790 - val_loss: 1349829.4696 - val_mae: 846.9451\n",
      "Epoch 120/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1372800.3261 - mae: 841.7947 - val_loss: 1361404.7716 - val_mae: 843.5006\n",
      "Epoch 121/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1400621.8918 - mae: 842.8994 - val_loss: 1342438.7596 - val_mae: 847.3554\n",
      "Epoch 122/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1374792.9122 - mae: 838.5317 - val_loss: 1341754.3015 - val_mae: 844.0442\n",
      "Epoch 123/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1386118.9356 - mae: 840.6723 - val_loss: 1342816.4145 - val_mae: 842.2670\n",
      "Epoch 124/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1382476.9595 - mae: 840.5513 - val_loss: 1341815.1938 - val_mae: 840.3699\n",
      "Epoch 125/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1336715.3869 - mae: 833.7841 - val_loss: 1345079.4307 - val_mae: 837.9930\n",
      "Epoch 126/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1355176.9596 - mae: 830.0195 - val_loss: 1331749.6267 - val_mae: 839.9752\n",
      "Epoch 127/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1371415.1007 - mae: 838.3953 - val_loss: 1338024.4875 - val_mae: 836.0497\n",
      "Epoch 128/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1392117.8318 - mae: 842.7159 - val_loss: 1339855.6864 - val_mae: 834.8759\n",
      "Epoch 129/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1370873.0402 - mae: 832.2548 - val_loss: 1334270.8740 - val_mae: 834.5219\n",
      "Epoch 130/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1365738.2254 - mae: 837.0112 - val_loss: 1339461.9236 - val_mae: 832.9090\n",
      "Epoch 131/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1366599.8573 - mae: 833.2498 - val_loss: 1330367.9183 - val_mae: 833.5587\n",
      "Epoch 132/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1384883.6681 - mae: 837.3551 - val_loss: 1332985.3904 - val_mae: 831.9880\n",
      "Epoch 133/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1345018.6373 - mae: 825.8200 - val_loss: 1321352.3398 - val_mae: 832.9291\n",
      "Epoch 134/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1377118.2457 - mae: 836.5070 - val_loss: 1335648.1000 - val_mae: 830.0301\n",
      "Epoch 135/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1345539.0829 - mae: 825.5742 - val_loss: 1322220.3531 - val_mae: 829.1970\n",
      "Epoch 136/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1368923.3137 - mae: 832.8684 - val_loss: 1343580.3413 - val_mae: 828.6413\n",
      "Epoch 137/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1372290.2733 - mae: 827.1280 - val_loss: 1309412.2136 - val_mae: 830.6470\n",
      "Epoch 138/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1351391.1180 - mae: 824.6509 - val_loss: 1313080.9140 - val_mae: 827.5031\n",
      "Epoch 139/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1363552.4224 - mae: 831.2109 - val_loss: 1304904.3339 - val_mae: 827.6826\n",
      "Epoch 140/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1337448.6654 - mae: 826.3316 - val_loss: 1314838.5375 - val_mae: 824.0559\n",
      "Epoch 141/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1386646.6077 - mae: 838.3783 - val_loss: 1320851.3225 - val_mae: 822.9220\n",
      "Epoch 142/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1337207.8556 - mae: 823.7535 - val_loss: 1343508.5670 - val_mae: 824.3140\n",
      "Epoch 143/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1339875.0798 - mae: 820.6689 - val_loss: 1295356.3766 - val_mae: 827.5414\n",
      "Epoch 144/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1359001.1897 - mae: 830.4677 - val_loss: 1299790.8861 - val_mae: 822.0027\n",
      "Epoch 145/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1320136.1938 - mae: 817.3953 - val_loss: 1294921.3314 - val_mae: 821.8212\n",
      "Epoch 146/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1336948.6633 - mae: 826.2742 - val_loss: 1311043.7651 - val_mae: 819.8209\n",
      "Epoch 147/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1333990.8826 - mae: 818.6985 - val_loss: 1311856.0340 - val_mae: 818.7623\n",
      "Epoch 148/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1324379.4634 - mae: 815.9160 - val_loss: 1300686.1943 - val_mae: 817.9114\n",
      "Epoch 149/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1346030.3377 - mae: 821.7451 - val_loss: 1295129.0575 - val_mae: 817.2312\n",
      "Epoch 150/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1352072.8422 - mae: 824.8956 - val_loss: 1286803.7856 - val_mae: 818.7997\n",
      "Epoch 151/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1325958.6081 - mae: 817.4197 - val_loss: 1284748.0290 - val_mae: 817.3948\n",
      "Epoch 152/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1333012.8782 - mae: 816.3041 - val_loss: 1317883.1632 - val_mae: 816.0792\n",
      "Epoch 153/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1333055.9252 - mae: 816.8028 - val_loss: 1281643.6773 - val_mae: 815.1625\n",
      "Epoch 154/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1311698.1160 - mae: 815.2983 - val_loss: 1280667.8935 - val_mae: 814.8315\n",
      "Epoch 155/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1297831.4902 - mae: 816.8163 - val_loss: 1308166.0312 - val_mae: 813.2343\n",
      "Epoch 156/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1304537.7847 - mae: 811.2752 - val_loss: 1282178.0528 - val_mae: 812.0797\n",
      "Epoch 157/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1329817.8395 - mae: 819.1423 - val_loss: 1273607.1748 - val_mae: 815.5692\n",
      "Epoch 158/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1328712.7338 - mae: 820.5950 - val_loss: 1294109.7779 - val_mae: 810.3111\n",
      "Epoch 159/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1322733.8709 - mae: 818.6500 - val_loss: 1293382.0398 - val_mae: 809.6111\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 24us/step - loss: 1344360.7873 - mae: 819.9084 - val_loss: 1266960.2028 - val_mae: 811.8923\n",
      "Epoch 161/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1307839.9867 - mae: 812.6419 - val_loss: 1280134.3107 - val_mae: 807.6174\n",
      "Epoch 162/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1325701.5812 - mae: 811.6516 - val_loss: 1267023.7917 - val_mae: 820.6387\n",
      "Epoch 163/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1328449.9543 - mae: 815.0185 - val_loss: 1270996.0835 - val_mae: 808.1491\n",
      "Epoch 164/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1319466.5841 - mae: 815.0834 - val_loss: 1270719.1894 - val_mae: 806.0656\n",
      "Epoch 165/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1325912.5016 - mae: 814.3154 - val_loss: 1265970.2006 - val_mae: 807.3861\n",
      "Epoch 166/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1293400.6274 - mae: 811.8920 - val_loss: 1269684.6802 - val_mae: 804.3241\n",
      "Epoch 167/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1307588.6364 - mae: 810.8648 - val_loss: 1266179.9465 - val_mae: 803.6096\n",
      "Epoch 168/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1313051.0489 - mae: 808.8728 - val_loss: 1276111.9946 - val_mae: 803.4426\n",
      "Epoch 169/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1324976.8688 - mae: 812.3637 - val_loss: 1252931.5028 - val_mae: 806.8658\n",
      "Epoch 170/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1303682.4598 - mae: 812.5072 - val_loss: 1259395.1993 - val_mae: 802.3408\n",
      "Epoch 171/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1300082.7327 - mae: 809.8787 - val_loss: 1252027.1416 - val_mae: 803.0876\n",
      "Epoch 172/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1314530.8297 - mae: 810.9650 - val_loss: 1257647.0954 - val_mae: 801.5237\n",
      "Epoch 173/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1292986.2868 - mae: 808.2568 - val_loss: 1260501.3120 - val_mae: 800.2809\n",
      "Epoch 174/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1329212.0549 - mae: 814.1103 - val_loss: 1249093.1779 - val_mae: 800.9156\n",
      "Epoch 175/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1297705.1341 - mae: 811.6146 - val_loss: 1250863.5465 - val_mae: 799.5325\n",
      "Epoch 176/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1298666.9668 - mae: 809.8426 - val_loss: 1265580.1023 - val_mae: 798.6612\n",
      "Epoch 177/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1302911.7107 - mae: 809.8134 - val_loss: 1257272.8220 - val_mae: 798.3837\n",
      "Epoch 178/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1307176.8140 - mae: 808.6242 - val_loss: 1240306.8554 - val_mae: 801.4181\n",
      "Epoch 179/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1270881.9615 - mae: 798.0764 - val_loss: 1251140.2849 - val_mae: 797.0483\n",
      "Epoch 180/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1323004.8465 - mae: 815.1864 - val_loss: 1239679.5000 - val_mae: 803.1482\n",
      "Epoch 181/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1302140.5805 - mae: 810.2415 - val_loss: 1257029.2679 - val_mae: 795.4691\n",
      "Epoch 182/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1297042.8367 - mae: 803.5087 - val_loss: 1237937.9586 - val_mae: 805.8196\n",
      "Epoch 183/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1307448.5838 - mae: 812.1355 - val_loss: 1236395.3249 - val_mae: 797.0021\n",
      "Epoch 184/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1307454.7843 - mae: 811.3296 - val_loss: 1254998.9977 - val_mae: 794.5230\n",
      "Epoch 185/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1286041.3783 - mae: 804.7154 - val_loss: 1236281.8629 - val_mae: 794.2323\n",
      "Epoch 186/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1291278.7210 - mae: 803.6108 - val_loss: 1269420.8968 - val_mae: 795.4498\n",
      "Epoch 187/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1311647.9825 - mae: 811.5681 - val_loss: 1250291.7403 - val_mae: 793.4125\n",
      "Epoch 188/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1295412.1304 - mae: 802.7659 - val_loss: 1233495.6026 - val_mae: 793.8869\n",
      "Epoch 189/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1286020.2422 - mae: 803.2562 - val_loss: 1228137.5038 - val_mae: 795.3415\n",
      "Epoch 190/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1273046.1431 - mae: 801.9230 - val_loss: 1234423.2450 - val_mae: 792.8021\n",
      "Epoch 191/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1299536.0203 - mae: 802.5068 - val_loss: 1232928.9780 - val_mae: 792.5281\n",
      "Epoch 192/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1296195.2987 - mae: 798.0703 - val_loss: 1253851.7427 - val_mae: 792.6600\n",
      "Epoch 193/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1291927.4310 - mae: 807.0205 - val_loss: 1268475.5032 - val_mae: 794.4937\n",
      "Epoch 194/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1313469.6592 - mae: 806.9811 - val_loss: 1237858.3820 - val_mae: 790.5347\n",
      "Epoch 195/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1293845.1170 - mae: 799.4128 - val_loss: 1243551.0144 - val_mae: 790.8640\n",
      "Epoch 196/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1303383.6638 - mae: 804.9557 - val_loss: 1225235.6772 - val_mae: 792.8242\n",
      "Epoch 197/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1300795.9060 - mae: 805.1722 - val_loss: 1235683.5550 - val_mae: 789.9434\n",
      "Epoch 198/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1300445.0520 - mae: 804.9412 - val_loss: 1230100.6053 - val_mae: 789.2914\n",
      "Epoch 199/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1286616.7995 - mae: 797.2066 - val_loss: 1223725.1621 - val_mae: 796.1459\n",
      "Epoch 200/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1282428.6874 - mae: 801.3173 - val_loss: 1241399.9844 - val_mae: 788.8911\n",
      "Epoch 201/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1284652.8975 - mae: 801.1107 - val_loss: 1231885.1929 - val_mae: 788.8681\n",
      "Epoch 202/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1266346.6328 - mae: 795.6507 - val_loss: 1254781.3634 - val_mae: 791.0259\n",
      "Epoch 203/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1282397.9112 - mae: 802.2444 - val_loss: 1233786.5992 - val_mae: 787.8411\n",
      "Epoch 204/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1275065.9342 - mae: 794.1238 - val_loss: 1220509.2035 - val_mae: 796.1138\n",
      "Epoch 205/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1303250.8541 - mae: 805.3735 - val_loss: 1226207.2922 - val_mae: 787.9006\n",
      "Epoch 206/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1287303.9762 - mae: 802.8286 - val_loss: 1218948.2519 - val_mae: 792.6503\n",
      "Epoch 207/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1283268.9081 - mae: 800.4747 - val_loss: 1231453.0847 - val_mae: 787.8884\n",
      "Epoch 208/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1296706.5962 - mae: 801.6276 - val_loss: 1221193.7973 - val_mae: 788.8373\n",
      "Epoch 209/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1273866.7772 - mae: 792.3080 - val_loss: 1229744.7081 - val_mae: 787.0607\n",
      "Epoch 210/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1296305.4299 - mae: 804.7000 - val_loss: 1241735.3097 - val_mae: 787.9275\n",
      "Epoch 211/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1279616.9229 - mae: 802.4373 - val_loss: 1224550.1925 - val_mae: 787.0746\n",
      "Epoch 212/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1282999.3798 - mae: 804.3230 - val_loss: 1242517.7067 - val_mae: 787.9428\n",
      "Epoch 213/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 26us/step - loss: 1274588.0504 - mae: 794.7204 - val_loss: 1227376.6563 - val_mae: 786.7883\n",
      "Epoch 214/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1292247.0876 - mae: 803.4409 - val_loss: 1232761.6148 - val_mae: 787.1241\n",
      "Epoch 215/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1291737.0304 - mae: 802.0869 - val_loss: 1217441.5719 - val_mae: 787.9802\n",
      "Epoch 216/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1289498.4048 - mae: 802.8897 - val_loss: 1214770.4631 - val_mae: 792.6805\n",
      "Epoch 217/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1267436.7268 - mae: 799.9814 - val_loss: 1224869.0061 - val_mae: 785.1658\n",
      "Epoch 218/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1276165.8856 - mae: 794.9644 - val_loss: 1239848.3900 - val_mae: 787.5087\n",
      "Epoch 219/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1272989.8199 - mae: 796.6238 - val_loss: 1228284.4236 - val_mae: 786.3029\n",
      "Epoch 220/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1264121.0861 - mae: 794.9445 - val_loss: 1216294.4920 - val_mae: 787.8267\n",
      "Epoch 221/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1306363.8138 - mae: 807.9998 - val_loss: 1219318.5204 - val_mae: 786.0078\n",
      "Epoch 222/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1273193.0197 - mae: 793.2415 - val_loss: 1215475.8050 - val_mae: 794.7565\n",
      "Epoch 223/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1286742.8905 - mae: 803.4510 - val_loss: 1239134.9378 - val_mae: 786.1409\n",
      "Epoch 224/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1261368.4080 - mae: 790.0342 - val_loss: 1223293.4130 - val_mae: 785.6988\n",
      "Epoch 225/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1268567.2621 - mae: 793.1851 - val_loss: 1215205.6757 - val_mae: 786.9315\n",
      "Epoch 226/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1280700.0959 - mae: 799.5164 - val_loss: 1217172.5551 - val_mae: 784.7477\n",
      "Epoch 227/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1257221.0246 - mae: 787.5035 - val_loss: 1216986.5484 - val_mae: 785.7241\n",
      "Epoch 228/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1302741.2602 - mae: 803.8315 - val_loss: 1215631.7939 - val_mae: 785.1320\n",
      "Epoch 229/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1266699.3432 - mae: 796.9214 - val_loss: 1230734.8583 - val_mae: 785.3353\n",
      "Epoch 230/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1270967.5857 - mae: 796.5732 - val_loss: 1214515.1886 - val_mae: 785.6218\n",
      "Epoch 231/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1290461.8439 - mae: 795.6485 - val_loss: 1222357.3582 - val_mae: 784.9894\n",
      "Epoch 232/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1262975.2590 - mae: 796.8940 - val_loss: 1245377.0271 - val_mae: 787.5045\n",
      "Epoch 233/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1276857.7000 - mae: 792.5988 - val_loss: 1224168.0362 - val_mae: 784.5174\n",
      "Epoch 234/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1280913.8072 - mae: 793.0730 - val_loss: 1211990.4437 - val_mae: 785.4894\n",
      "Epoch 235/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1273630.7448 - mae: 792.7739 - val_loss: 1237873.7501 - val_mae: 785.5175\n",
      "Epoch 236/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1268971.9683 - mae: 789.0191 - val_loss: 1212558.6468 - val_mae: 785.2996\n",
      "Epoch 237/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1309515.4107 - mae: 805.0726 - val_loss: 1218774.5695 - val_mae: 784.5781\n",
      "Epoch 238/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1274775.9092 - mae: 795.2834 - val_loss: 1222702.2059 - val_mae: 783.6724\n",
      "Epoch 239/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1274110.4165 - mae: 797.4933 - val_loss: 1253470.0530 - val_mae: 787.8371\n",
      "Epoch 240/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1289236.0844 - mae: 802.7034 - val_loss: 1225213.1632 - val_mae: 784.8825\n",
      "Epoch 241/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1247991.4742 - mae: 790.0854 - val_loss: 1217127.9673 - val_mae: 783.3200\n",
      "Epoch 242/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1259112.3808 - mae: 789.8574 - val_loss: 1210828.9005 - val_mae: 787.2553\n",
      "Epoch 243/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1278903.4152 - mae: 795.7125 - val_loss: 1224651.8047 - val_mae: 783.2587\n",
      "Epoch 244/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1266682.6627 - mae: 797.2907 - val_loss: 1216568.8348 - val_mae: 783.0510\n",
      "Epoch 245/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1282988.3419 - mae: 793.4068 - val_loss: 1211625.1594 - val_mae: 784.7666\n",
      "Epoch 246/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1269421.0315 - mae: 799.6182 - val_loss: 1232547.5560 - val_mae: 783.9719\n",
      "Epoch 247/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1272481.6019 - mae: 790.3046 - val_loss: 1215531.1776 - val_mae: 783.2734\n",
      "Epoch 248/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1290024.6178 - mae: 803.0638 - val_loss: 1227357.8490 - val_mae: 782.4832\n",
      "Epoch 249/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1295544.5316 - mae: 796.3439 - val_loss: 1208239.1715 - val_mae: 788.0011\n",
      "Epoch 250/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1289416.4604 - mae: 800.7015 - val_loss: 1213401.2535 - val_mae: 783.1902\n",
      "Epoch 251/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1283987.6717 - mae: 795.7744 - val_loss: 1216600.3552 - val_mae: 782.3597\n",
      "Epoch 252/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1275257.9418 - mae: 792.6893 - val_loss: 1215588.0915 - val_mae: 782.4989\n",
      "Epoch 253/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1282492.0499 - mae: 801.2709 - val_loss: 1216652.2120 - val_mae: 782.1646\n",
      "Epoch 254/500\n",
      "5966/5966 [==============================] - 0s 30us/step - loss: 1274217.2545 - mae: 798.6061 - val_loss: 1213883.5189 - val_mae: 782.8536\n",
      "Epoch 255/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1289874.6827 - mae: 796.8684 - val_loss: 1217620.8231 - val_mae: 782.0972\n",
      "Epoch 256/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1252975.8197 - mae: 788.2305 - val_loss: 1214354.9139 - val_mae: 782.1003\n",
      "Epoch 257/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1286319.1157 - mae: 803.0411 - val_loss: 1207482.2706 - val_mae: 784.1417\n",
      "Epoch 258/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1280878.0015 - mae: 796.8253 - val_loss: 1209696.4022 - val_mae: 783.1154\n",
      "Epoch 259/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1247923.2880 - mae: 788.0310 - val_loss: 1206931.7023 - val_mae: 783.3975\n",
      "Epoch 260/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1270623.2325 - mae: 790.6801 - val_loss: 1217394.7942 - val_mae: 781.6020\n",
      "Epoch 261/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1249048.1420 - mae: 789.2551 - val_loss: 1215989.1050 - val_mae: 781.2509\n",
      "Epoch 262/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1274331.6590 - mae: 797.1752 - val_loss: 1212923.4345 - val_mae: 781.0589\n",
      "Epoch 263/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1288862.2491 - mae: 794.7971 - val_loss: 1206862.3749 - val_mae: 783.6696\n",
      "Epoch 264/500\n",
      "5966/5966 [==============================] - 0s 36us/step - loss: 1260807.0745 - mae: 790.2951 - val_loss: 1226581.2297 - val_mae: 782.4638\n",
      "Epoch 265/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1280900.6460 - mae: 795.9171 - val_loss: 1228102.7795 - val_mae: 782.8965\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 34us/step - loss: 1273616.2612 - mae: 792.4587 - val_loss: 1208333.9809 - val_mae: 784.7316\n",
      "Epoch 267/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1290434.3395 - mae: 792.9429 - val_loss: 1208535.0501 - val_mae: 784.1066\n",
      "Epoch 268/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1272004.2836 - mae: 797.8976 - val_loss: 1231550.6554 - val_mae: 782.0245\n",
      "Epoch 269/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1273626.3200 - mae: 795.7040 - val_loss: 1223188.0876 - val_mae: 781.9368\n",
      "Epoch 270/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1248801.3274 - mae: 789.3261 - val_loss: 1208692.1360 - val_mae: 783.3065\n",
      "Epoch 271/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1281377.7401 - mae: 794.6565 - val_loss: 1227173.4808 - val_mae: 782.7171\n",
      "Epoch 272/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1260517.7046 - mae: 787.2726 - val_loss: 1241588.8717 - val_mae: 783.6973\n",
      "Epoch 273/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1274187.7767 - mae: 794.8165 - val_loss: 1211587.3454 - val_mae: 781.3738\n",
      "Epoch 274/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1263273.3934 - mae: 792.1865 - val_loss: 1223605.2228 - val_mae: 780.7017\n",
      "Epoch 275/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1306071.4539 - mae: 801.0290 - val_loss: 1218594.1299 - val_mae: 781.3040\n",
      "Epoch 276/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1262882.6459 - mae: 785.9089 - val_loss: 1230896.9496 - val_mae: 782.4220\n",
      "Epoch 277/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1248489.7598 - mae: 784.7790 - val_loss: 1212840.8768 - val_mae: 780.3486\n",
      "Epoch 278/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1285162.1095 - mae: 801.0938 - val_loss: 1208704.1310 - val_mae: 781.9810\n",
      "Epoch 279/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1275890.7388 - mae: 795.5546 - val_loss: 1239444.5184 - val_mae: 783.1426\n",
      "Epoch 280/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1284081.6962 - mae: 795.5936 - val_loss: 1240987.6178 - val_mae: 783.0888\n",
      "Epoch 281/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1274168.7336 - mae: 795.7348 - val_loss: 1224326.9053 - val_mae: 781.2776\n",
      "Epoch 282/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1285430.2094 - mae: 793.3420 - val_loss: 1239092.9649 - val_mae: 784.0275\n",
      "Epoch 283/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1272684.9957 - mae: 790.0884 - val_loss: 1225072.8418 - val_mae: 781.1413\n",
      "Epoch 284/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1280680.9058 - mae: 790.3196 - val_loss: 1210256.3878 - val_mae: 780.3215\n",
      "Epoch 285/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1255585.1550 - mae: 786.0148 - val_loss: 1205138.3025 - val_mae: 783.6836\n",
      "Epoch 286/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1250306.3680 - mae: 787.7192 - val_loss: 1245946.8485 - val_mae: 783.9403\n",
      "Epoch 287/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1270418.6595 - mae: 791.7311 - val_loss: 1228118.3169 - val_mae: 781.0234\n",
      "Epoch 288/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1244963.2097 - mae: 789.9993 - val_loss: 1213683.7018 - val_mae: 779.8636\n",
      "Epoch 289/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1288513.8939 - mae: 794.5570 - val_loss: 1253194.2980 - val_mae: 784.9478\n",
      "Epoch 290/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1287803.7033 - mae: 796.9763 - val_loss: 1206293.9986 - val_mae: 782.2409\n",
      "Epoch 291/500\n",
      "5966/5966 [==============================] - 0s 30us/step - loss: 1288603.1630 - mae: 797.6996 - val_loss: 1235016.9627 - val_mae: 781.3561\n",
      "Epoch 292/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1264950.4503 - mae: 792.0578 - val_loss: 1208326.7395 - val_mae: 780.4338\n",
      "Epoch 293/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1276594.8850 - mae: 790.6799 - val_loss: 1205884.6439 - val_mae: 783.6274\n",
      "Epoch 294/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1287629.3644 - mae: 796.0962 - val_loss: 1208978.9509 - val_mae: 781.0632\n",
      "Epoch 295/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1264086.3793 - mae: 786.0588 - val_loss: 1231690.3322 - val_mae: 781.9866\n",
      "Epoch 296/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1251556.2781 - mae: 789.1950 - val_loss: 1204668.9889 - val_mae: 784.8195\n",
      "Epoch 297/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1279113.2710 - mae: 794.9695 - val_loss: 1229532.9690 - val_mae: 780.6660\n",
      "Epoch 298/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1274177.9567 - mae: 791.9593 - val_loss: 1218498.9478 - val_mae: 779.3555\n",
      "Epoch 299/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1249363.2957 - mae: 789.4495 - val_loss: 1269270.4104 - val_mae: 787.4066\n",
      "Epoch 300/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1287900.1324 - mae: 786.8168 - val_loss: 1208032.6030 - val_mae: 780.9507\n",
      "Epoch 301/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1256518.7008 - mae: 784.2358 - val_loss: 1217043.6794 - val_mae: 778.7665\n",
      "Epoch 302/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1271317.2960 - mae: 790.8605 - val_loss: 1218633.9786 - val_mae: 780.7493\n",
      "Epoch 303/500\n",
      "5966/5966 [==============================] - 0s 30us/step - loss: 1253398.1286 - mae: 783.5653 - val_loss: 1225737.1260 - val_mae: 780.8382\n",
      "Epoch 304/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1269640.6105 - mae: 786.9045 - val_loss: 1268999.5913 - val_mae: 787.6460\n",
      "Epoch 305/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1282091.1541 - mae: 790.2974 - val_loss: 1206893.1350 - val_mae: 781.6455\n",
      "Epoch 306/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1253263.2613 - mae: 786.6864 - val_loss: 1222632.7113 - val_mae: 779.6493\n",
      "Epoch 307/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1252229.8530 - mae: 786.9706 - val_loss: 1204798.4265 - val_mae: 781.7854\n",
      "Epoch 308/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1294212.4008 - mae: 794.8254 - val_loss: 1222733.2750 - val_mae: 779.6627\n",
      "Epoch 309/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1298247.7439 - mae: 798.2701 - val_loss: 1207965.1792 - val_mae: 780.4210\n",
      "Epoch 310/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1285073.6326 - mae: 791.8223 - val_loss: 1223689.3350 - val_mae: 780.2172\n",
      "Epoch 311/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1250937.4076 - mae: 787.2459 - val_loss: 1234100.4273 - val_mae: 780.0488\n",
      "Epoch 312/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1270380.7941 - mae: 791.6981 - val_loss: 1204578.3466 - val_mae: 780.2626\n",
      "Epoch 313/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1268530.0137 - mae: 788.4420 - val_loss: 1204595.6719 - val_mae: 782.2206\n",
      "Epoch 314/500\n",
      "5966/5966 [==============================] - 0s 28us/step - loss: 1280351.2022 - mae: 793.1577 - val_loss: 1211037.9842 - val_mae: 778.5500\n",
      "Epoch 315/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1260819.7549 - mae: 785.1781 - val_loss: 1215416.2662 - val_mae: 779.3301\n",
      "Epoch 316/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1261321.7440 - mae: 795.8220 - val_loss: 1224618.8236 - val_mae: 778.7868\n",
      "Epoch 317/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1270363.1564 - mae: 793.5941 - val_loss: 1211989.8730 - val_mae: 778.5251\n",
      "Epoch 318/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1249929.9882 - mae: 786.8005 - val_loss: 1245771.9830 - val_mae: 782.0814\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 23us/step - loss: 1260174.6530 - mae: 788.5649 - val_loss: 1208948.7672 - val_mae: 778.3814\n",
      "Epoch 320/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1277742.3350 - mae: 790.3383 - val_loss: 1215960.5972 - val_mae: 779.0904\n",
      "Epoch 321/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1280157.6637 - mae: 791.3013 - val_loss: 1211290.0797 - val_mae: 779.0030\n",
      "Epoch 322/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1272623.4224 - mae: 786.4649 - val_loss: 1221944.6599 - val_mae: 778.7141\n",
      "Epoch 323/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1250910.9495 - mae: 785.6523 - val_loss: 1216341.3220 - val_mae: 778.5579\n",
      "Epoch 324/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1275458.7358 - mae: 794.4836 - val_loss: 1204270.8827 - val_mae: 781.2834\n",
      "Epoch 325/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1275370.1332 - mae: 791.3425 - val_loss: 1202259.2942 - val_mae: 780.5235\n",
      "Epoch 326/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1265852.0028 - mae: 792.0424 - val_loss: 1218305.5309 - val_mae: 777.5599\n",
      "Epoch 327/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1269474.8388 - mae: 789.6617 - val_loss: 1233697.4911 - val_mae: 780.5455\n",
      "Epoch 328/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1258695.8111 - mae: 788.6808 - val_loss: 1210511.9441 - val_mae: 778.5539\n",
      "Epoch 329/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1285526.4727 - mae: 793.9863 - val_loss: 1227889.1406 - val_mae: 779.0510\n",
      "Epoch 330/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1256417.7421 - mae: 785.4036 - val_loss: 1209530.6091 - val_mae: 778.2744\n",
      "Epoch 331/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1232318.7539 - mae: 785.4787 - val_loss: 1213651.6563 - val_mae: 777.4305\n",
      "Epoch 332/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1252121.0787 - mae: 787.2652 - val_loss: 1215207.1428 - val_mae: 778.9817\n",
      "Epoch 333/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1270245.2831 - mae: 788.8852 - val_loss: 1232736.1494 - val_mae: 780.2562\n",
      "Epoch 334/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1275445.9159 - mae: 793.1460 - val_loss: 1208853.2838 - val_mae: 780.4156\n",
      "Epoch 335/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1262037.6890 - mae: 787.9504 - val_loss: 1212135.1242 - val_mae: 778.3548\n",
      "Epoch 336/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1269657.2576 - mae: 792.1532 - val_loss: 1229909.7613 - val_mae: 779.6971\n",
      "Epoch 337/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1257671.3484 - mae: 783.5292 - val_loss: 1214237.3936 - val_mae: 777.9481\n",
      "Epoch 338/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1285106.4191 - mae: 791.1783 - val_loss: 1220020.6778 - val_mae: 778.6346\n",
      "Epoch 339/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1263705.1547 - mae: 788.7714 - val_loss: 1216597.6164 - val_mae: 777.0233\n",
      "Epoch 340/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1273896.3811 - mae: 791.8695 - val_loss: 1209871.5197 - val_mae: 777.8539\n",
      "Epoch 341/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1242382.8929 - mae: 784.6109 - val_loss: 1216886.3459 - val_mae: 777.2906\n",
      "Epoch 342/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1267358.8622 - mae: 788.0656 - val_loss: 1225746.7650 - val_mae: 778.2628\n",
      "Epoch 343/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1249418.9855 - mae: 786.1992 - val_loss: 1207223.2593 - val_mae: 778.5601\n",
      "Epoch 344/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1267006.0456 - mae: 792.6696 - val_loss: 1221084.0354 - val_mae: 777.5657\n",
      "Epoch 345/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1226639.8062 - mae: 778.1781 - val_loss: 1206651.0484 - val_mae: 780.8420\n",
      "Epoch 346/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1263117.0924 - mae: 791.1387 - val_loss: 1222495.6369 - val_mae: 777.1702\n",
      "Epoch 347/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1273456.3197 - mae: 791.9133 - val_loss: 1218383.4484 - val_mae: 777.7184\n",
      "Epoch 348/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1265951.9061 - mae: 787.1588 - val_loss: 1217922.7766 - val_mae: 778.1417\n",
      "Epoch 349/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1263058.4359 - mae: 784.2424 - val_loss: 1211455.6041 - val_mae: 776.9208\n",
      "Epoch 350/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1262765.8548 - mae: 786.0406 - val_loss: 1217075.4260 - val_mae: 777.1204\n",
      "Epoch 351/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1270032.6313 - mae: 786.4854 - val_loss: 1207209.9043 - val_mae: 777.7099\n",
      "Epoch 352/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1256796.9376 - mae: 784.9378 - val_loss: 1228631.7536 - val_mae: 778.4974\n",
      "Epoch 353/500\n",
      "5966/5966 [==============================] - 0s 30us/step - loss: 1266647.8920 - mae: 790.2797 - val_loss: 1209155.7492 - val_mae: 777.5173\n",
      "Epoch 354/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1265260.9656 - mae: 787.4739 - val_loss: 1206817.5895 - val_mae: 776.7703\n",
      "Epoch 355/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1267426.3702 - mae: 789.8124 - val_loss: 1202146.8320 - val_mae: 782.2750\n",
      "Epoch 356/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1262515.0659 - mae: 786.4970 - val_loss: 1232034.8678 - val_mae: 778.0544\n",
      "Epoch 357/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1259057.8150 - mae: 784.7646 - val_loss: 1206320.2317 - val_mae: 776.6642\n",
      "Epoch 358/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1283194.3551 - mae: 792.3299 - val_loss: 1209688.5921 - val_mae: 775.9160\n",
      "Epoch 359/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1254739.5443 - mae: 789.7402 - val_loss: 1201877.7616 - val_mae: 778.4725\n",
      "Epoch 360/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1250441.7642 - mae: 785.9299 - val_loss: 1213165.1217 - val_mae: 777.4719\n",
      "Epoch 361/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1232235.4925 - mae: 776.9888 - val_loss: 1204649.2855 - val_mae: 778.0267\n",
      "Epoch 362/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1274911.5957 - mae: 791.1315 - val_loss: 1217890.3895 - val_mae: 777.1981\n",
      "Epoch 363/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1281604.7549 - mae: 789.9227 - val_loss: 1223900.6582 - val_mae: 776.5632\n",
      "Epoch 364/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1270651.8877 - mae: 787.2866 - val_loss: 1216787.8200 - val_mae: 777.6685\n",
      "Epoch 365/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1271756.6526 - mae: 788.8639 - val_loss: 1208072.7761 - val_mae: 776.8585\n",
      "Epoch 366/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1242733.3913 - mae: 779.6161 - val_loss: 1202748.5899 - val_mae: 777.7970\n",
      "Epoch 367/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1251824.9465 - mae: 787.2586 - val_loss: 1215679.2736 - val_mae: 775.8405\n",
      "Epoch 368/500\n",
      "5966/5966 [==============================] - ETA: 0s - loss: 1242774.3125 - mae: 784.223 - 0s 21us/step - loss: 1242464.9785 - mae: 782.8945 - val_loss: 1237326.1303 - val_mae: 778.7261\n",
      "Epoch 369/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1279676.6290 - mae: 788.8602 - val_loss: 1241266.9203 - val_mae: 779.9602\n",
      "Epoch 370/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1267990.5939 - mae: 787.2884 - val_loss: 1209711.2039 - val_mae: 775.7776\n",
      "Epoch 371/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1265017.4182 - mae: 787.3757 - val_loss: 1222266.7458 - val_mae: 776.9357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1270974.7089 - mae: 789.0672 - val_loss: 1225348.2505 - val_mae: 776.9722\n",
      "Epoch 373/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1259527.9311 - mae: 785.1630 - val_loss: 1207095.7552 - val_mae: 776.5414\n",
      "Epoch 374/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1240216.5386 - mae: 783.5970 - val_loss: 1210937.1434 - val_mae: 775.8820\n",
      "Epoch 375/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1268807.6989 - mae: 786.0464 - val_loss: 1205057.0497 - val_mae: 777.5996\n",
      "Epoch 376/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1244061.1060 - mae: 784.4095 - val_loss: 1209554.8930 - val_mae: 777.9265\n",
      "Epoch 377/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1276699.4807 - mae: 788.4628 - val_loss: 1222324.6998 - val_mae: 778.0969\n",
      "Epoch 378/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1236404.6870 - mae: 781.9993 - val_loss: 1208900.6850 - val_mae: 775.4714\n",
      "Epoch 379/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1251835.3781 - mae: 785.2111 - val_loss: 1214110.3381 - val_mae: 775.5641\n",
      "Epoch 380/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1261870.5805 - mae: 784.1378 - val_loss: 1211202.5455 - val_mae: 775.3715\n",
      "Epoch 381/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1279850.5217 - mae: 789.3033 - val_loss: 1208223.9602 - val_mae: 776.8775\n",
      "Epoch 382/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1285768.2011 - mae: 790.6340 - val_loss: 1238192.2316 - val_mae: 778.4816\n",
      "Epoch 383/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1272309.9282 - mae: 786.9128 - val_loss: 1221759.9899 - val_mae: 776.2136\n",
      "Epoch 384/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1244836.3265 - mae: 779.0859 - val_loss: 1256791.1327 - val_mae: 782.6210\n",
      "Epoch 385/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1255220.9668 - mae: 788.9722 - val_loss: 1220279.9624 - val_mae: 775.3664\n",
      "Epoch 386/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1252768.8768 - mae: 785.2192 - val_loss: 1204553.6734 - val_mae: 776.7791\n",
      "Epoch 387/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1258807.1866 - mae: 786.7692 - val_loss: 1220898.7113 - val_mae: 778.4490\n",
      "Epoch 388/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1261921.2061 - mae: 785.3012 - val_loss: 1235377.2990 - val_mae: 777.8544\n",
      "Epoch 389/500\n",
      "5966/5966 [==============================] - 0s 27us/step - loss: 1265382.6209 - mae: 782.6898 - val_loss: 1209058.5856 - val_mae: 776.4153\n",
      "Epoch 390/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1257744.7328 - mae: 782.9731 - val_loss: 1207385.7524 - val_mae: 776.0586\n",
      "Epoch 391/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1266859.1843 - mae: 787.1619 - val_loss: 1244444.8679 - val_mae: 779.5055\n",
      "Epoch 392/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1252363.5074 - mae: 784.0731 - val_loss: 1208851.2007 - val_mae: 774.2491\n",
      "Epoch 393/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1264201.2766 - mae: 788.3459 - val_loss: 1210974.3092 - val_mae: 774.6691\n",
      "Epoch 394/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1266628.6050 - mae: 785.6481 - val_loss: 1236273.6625 - val_mae: 779.2818\n",
      "Epoch 395/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1254163.8116 - mae: 778.2213 - val_loss: 1211065.5780 - val_mae: 775.6224\n",
      "Epoch 396/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1279457.7850 - mae: 789.0231 - val_loss: 1235713.3871 - val_mae: 778.4517\n",
      "Epoch 397/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1279948.1052 - mae: 787.6902 - val_loss: 1204293.6080 - val_mae: 779.7020\n",
      "Epoch 398/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1257648.2046 - mae: 785.2295 - val_loss: 1204349.9272 - val_mae: 779.9239\n",
      "Epoch 399/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1299143.3144 - mae: 792.5236 - val_loss: 1216772.0857 - val_mae: 777.0068\n",
      "Epoch 400/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1254282.9902 - mae: 787.1967 - val_loss: 1223868.8744 - val_mae: 776.8986\n",
      "Epoch 401/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1265833.8208 - mae: 788.0753 - val_loss: 1213071.7307 - val_mae: 775.3772\n",
      "Epoch 402/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1282731.5117 - mae: 792.0093 - val_loss: 1214871.4163 - val_mae: 775.5348\n",
      "Epoch 403/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1269557.6188 - mae: 789.8167 - val_loss: 1209724.3678 - val_mae: 776.9509\n",
      "Epoch 404/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1243120.7846 - mae: 782.1894 - val_loss: 1215296.1963 - val_mae: 775.7410\n",
      "Epoch 405/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1298158.7775 - mae: 792.4198 - val_loss: 1211347.4133 - val_mae: 776.2206\n",
      "Epoch 406/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1238007.5758 - mae: 778.4092 - val_loss: 1204221.7845 - val_mae: 774.7843\n",
      "Epoch 407/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1256459.2041 - mae: 784.9389 - val_loss: 1219635.1263 - val_mae: 776.0905\n",
      "Epoch 408/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1232635.3844 - mae: 780.4412 - val_loss: 1211419.0233 - val_mae: 774.8663\n",
      "Epoch 409/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1258117.2056 - mae: 785.8149 - val_loss: 1200123.0658 - val_mae: 778.4972\n",
      "Epoch 410/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1258909.0465 - mae: 787.1637 - val_loss: 1206739.0879 - val_mae: 774.3991\n",
      "Epoch 411/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1260042.5688 - mae: 786.2540 - val_loss: 1213012.9565 - val_mae: 775.1395\n",
      "Epoch 412/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1250998.2213 - mae: 786.3345 - val_loss: 1202029.6361 - val_mae: 775.0835\n",
      "Epoch 413/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1249002.2860 - mae: 782.5681 - val_loss: 1201404.6475 - val_mae: 780.2694\n",
      "Epoch 414/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1288591.7133 - mae: 792.2935 - val_loss: 1216775.0935 - val_mae: 775.7643\n",
      "Epoch 415/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1264138.9606 - mae: 786.0115 - val_loss: 1204747.7499 - val_mae: 776.2419\n",
      "Epoch 416/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1256584.2888 - mae: 788.1783 - val_loss: 1207943.6408 - val_mae: 776.4246\n",
      "Epoch 417/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1278704.0344 - mae: 785.7467 - val_loss: 1214855.7999 - val_mae: 775.9739\n",
      "Epoch 418/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1251534.6131 - mae: 782.8907 - val_loss: 1206457.6197 - val_mae: 774.6332\n",
      "Epoch 419/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1254930.0243 - mae: 782.5255 - val_loss: 1217312.6413 - val_mae: 775.4864\n",
      "Epoch 420/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1237966.0077 - mae: 777.7534 - val_loss: 1214486.9207 - val_mae: 775.0892\n",
      "Epoch 421/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1246674.6962 - mae: 777.9940 - val_loss: 1215922.3843 - val_mae: 774.1347\n",
      "Epoch 422/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1271755.9538 - mae: 787.5523 - val_loss: 1207958.4826 - val_mae: 775.3610\n",
      "Epoch 423/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1265269.0668 - mae: 781.4802 - val_loss: 1220517.7872 - val_mae: 776.4304\n",
      "Epoch 424/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1261368.2266 - mae: 786.6056 - val_loss: 1246416.6088 - val_mae: 779.4370\n",
      "Epoch 425/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 24us/step - loss: 1264444.5054 - mae: 782.6129 - val_loss: 1234296.4571 - val_mae: 777.5394\n",
      "Epoch 426/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1265758.5357 - mae: 785.1505 - val_loss: 1220364.4414 - val_mae: 776.5421\n",
      "Epoch 427/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1268912.9863 - mae: 786.1226 - val_loss: 1253831.0384 - val_mae: 781.3971\n",
      "Epoch 428/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1251891.4982 - mae: 779.5865 - val_loss: 1206513.0191 - val_mae: 774.8058\n",
      "Epoch 429/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1237055.2003 - mae: 776.5234 - val_loss: 1220717.2306 - val_mae: 774.1125\n",
      "Epoch 430/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1224610.2038 - mae: 778.4106 - val_loss: 1204331.5481 - val_mae: 786.5201\n",
      "Epoch 431/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1264867.6387 - mae: 781.5245 - val_loss: 1203698.7412 - val_mae: 774.5652\n",
      "Epoch 432/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1273489.3586 - mae: 789.3801 - val_loss: 1203634.0556 - val_mae: 776.1122\n",
      "Epoch 433/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1238252.4691 - mae: 780.0289 - val_loss: 1217094.1814 - val_mae: 774.8840\n",
      "Epoch 434/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1260627.1597 - mae: 783.0984 - val_loss: 1251252.4651 - val_mae: 782.0593\n",
      "Epoch 435/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1259648.2418 - mae: 783.4650 - val_loss: 1205306.7385 - val_mae: 777.7117\n",
      "Epoch 436/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1263977.2638 - mae: 785.4581 - val_loss: 1248489.1239 - val_mae: 779.8637\n",
      "Epoch 437/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1275880.7210 - mae: 787.5218 - val_loss: 1215133.8771 - val_mae: 775.2325\n",
      "Epoch 438/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1251870.7287 - mae: 779.7915 - val_loss: 1212097.8819 - val_mae: 775.0734\n",
      "Epoch 439/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1260590.3704 - mae: 784.5160 - val_loss: 1202190.8501 - val_mae: 777.5837\n",
      "Epoch 440/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1266247.3736 - mae: 785.3063 - val_loss: 1202654.5712 - val_mae: 780.4583\n",
      "Epoch 441/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1238219.4379 - mae: 781.6089 - val_loss: 1202985.3093 - val_mae: 776.7496\n",
      "Epoch 442/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1266723.1073 - mae: 783.0731 - val_loss: 1208270.1234 - val_mae: 776.9235\n",
      "Epoch 443/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1252814.1599 - mae: 782.5811 - val_loss: 1217857.9924 - val_mae: 778.1987\n",
      "Epoch 444/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1243008.8607 - mae: 777.6851 - val_loss: 1203627.8467 - val_mae: 776.3058\n",
      "Epoch 445/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1242442.5153 - mae: 778.1087 - val_loss: 1215676.2782 - val_mae: 775.4205\n",
      "Epoch 446/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1238313.8643 - mae: 780.0515 - val_loss: 1208818.5035 - val_mae: 775.6898\n",
      "Epoch 447/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1264941.7914 - mae: 787.8443 - val_loss: 1223580.1025 - val_mae: 775.2141\n",
      "Epoch 448/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1226022.6372 - mae: 779.3248 - val_loss: 1200925.6131 - val_mae: 775.9956\n",
      "Epoch 449/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1248053.5717 - mae: 780.8686 - val_loss: 1204140.9254 - val_mae: 775.7052\n",
      "Epoch 450/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1284964.3196 - mae: 792.9949 - val_loss: 1245736.1668 - val_mae: 780.0424\n",
      "Epoch 451/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1268252.7254 - mae: 784.7219 - val_loss: 1251097.0319 - val_mae: 781.1774\n",
      "Epoch 452/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1271889.8866 - mae: 784.6985 - val_loss: 1207870.8818 - val_mae: 773.8320\n",
      "Epoch 453/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1250670.8058 - mae: 779.2525 - val_loss: 1208113.2500 - val_mae: 775.6912\n",
      "Epoch 454/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1238967.2621 - mae: 778.7258 - val_loss: 1206807.8772 - val_mae: 775.4894\n",
      "Epoch 455/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1257330.1834 - mae: 782.4747 - val_loss: 1208177.0226 - val_mae: 775.1497\n",
      "Epoch 456/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1263389.7542 - mae: 784.1502 - val_loss: 1212949.0373 - val_mae: 775.1828\n",
      "Epoch 457/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1284064.7191 - mae: 787.4039 - val_loss: 1215700.7405 - val_mae: 774.6528\n",
      "Epoch 458/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1229161.8226 - mae: 773.6633 - val_loss: 1206013.5889 - val_mae: 774.5795\n",
      "Epoch 459/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1268825.2141 - mae: 787.1298 - val_loss: 1220278.3685 - val_mae: 775.3458\n",
      "Epoch 460/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1256360.4960 - mae: 784.5003 - val_loss: 1210193.4148 - val_mae: 774.6129\n",
      "Epoch 461/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1246310.8581 - mae: 778.6803 - val_loss: 1202654.4561 - val_mae: 775.1259\n",
      "Epoch 462/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1249040.0201 - mae: 783.0658 - val_loss: 1207197.5636 - val_mae: 772.9802\n",
      "Epoch 463/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1244077.8304 - mae: 781.2310 - val_loss: 1212748.4456 - val_mae: 773.5260\n",
      "Epoch 464/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1275449.8841 - mae: 788.8529 - val_loss: 1260878.6159 - val_mae: 782.1916\n",
      "Epoch 465/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1257134.4091 - mae: 784.1660 - val_loss: 1203331.7727 - val_mae: 785.4920\n",
      "Epoch 466/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1253868.3500 - mae: 785.0602 - val_loss: 1199728.3133 - val_mae: 774.9785\n",
      "Epoch 467/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1266681.5396 - mae: 783.4633 - val_loss: 1206817.0530 - val_mae: 776.3385\n",
      "Epoch 468/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1232650.8301 - mae: 778.2397 - val_loss: 1212315.1774 - val_mae: 774.8149\n",
      "Epoch 469/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1241303.8964 - mae: 778.3121 - val_loss: 1205347.0089 - val_mae: 773.1784\n",
      "Epoch 470/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1260539.0769 - mae: 782.4369 - val_loss: 1208674.6111 - val_mae: 773.8162\n",
      "Epoch 471/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1219829.4633 - mae: 769.0505 - val_loss: 1215091.9448 - val_mae: 774.0301\n",
      "Epoch 472/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1271420.6739 - mae: 783.7014 - val_loss: 1219120.6460 - val_mae: 773.9005\n",
      "Epoch 473/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1251277.1937 - mae: 781.6262 - val_loss: 1198298.7402 - val_mae: 775.5819\n",
      "Epoch 474/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1250328.8500 - mae: 778.9070 - val_loss: 1207174.2691 - val_mae: 774.7390\n",
      "Epoch 475/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1253222.5326 - mae: 781.4935 - val_loss: 1207879.5792 - val_mae: 774.4793\n",
      "Epoch 476/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1250018.3854 - mae: 786.0609 - val_loss: 1205479.4142 - val_mae: 774.1069\n",
      "Epoch 477/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1256408.1586 - mae: 783.0589 - val_loss: 1200495.5582 - val_mae: 779.2546\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 22us/step - loss: 1260218.0072 - mae: 783.9628 - val_loss: 1210183.0784 - val_mae: 774.5219\n",
      "Epoch 479/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1262389.9168 - mae: 789.3973 - val_loss: 1238910.8594 - val_mae: 778.5247\n",
      "Epoch 480/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1270230.0192 - mae: 788.1235 - val_loss: 1209667.7158 - val_mae: 775.2348\n",
      "Epoch 481/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1248610.1297 - mae: 781.9518 - val_loss: 1206592.9029 - val_mae: 774.0880\n",
      "Epoch 482/500\n",
      "5966/5966 [==============================] - 0s 20us/step - loss: 1251523.6665 - mae: 779.4933 - val_loss: 1202214.7686 - val_mae: 775.9185\n",
      "Epoch 483/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1234313.6506 - mae: 778.2354 - val_loss: 1202146.9052 - val_mae: 775.2466\n",
      "Epoch 484/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1251748.2878 - mae: 778.5760 - val_loss: 1212788.9651 - val_mae: 772.8446\n",
      "Epoch 485/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1248636.8312 - mae: 777.4982 - val_loss: 1202103.5010 - val_mae: 773.4537\n",
      "Epoch 486/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1228815.9782 - mae: 777.8900 - val_loss: 1220595.8789 - val_mae: 775.3991\n",
      "Epoch 487/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1266887.6118 - mae: 782.8412 - val_loss: 1218873.9276 - val_mae: 774.0400\n",
      "Epoch 488/500\n",
      "5966/5966 [==============================] - 0s 30us/step - loss: 1246908.5275 - mae: 777.2787 - val_loss: 1227542.3484 - val_mae: 775.6232\n",
      "Epoch 489/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1243698.7325 - mae: 783.3726 - val_loss: 1215711.8755 - val_mae: 774.1526\n",
      "Epoch 490/500\n",
      "5966/5966 [==============================] - 0s 26us/step - loss: 1269488.9225 - mae: 787.9222 - val_loss: 1201076.0199 - val_mae: 776.6174\n",
      "Epoch 491/500\n",
      "5966/5966 [==============================] - 0s 29us/step - loss: 1224161.6198 - mae: 776.3270 - val_loss: 1222516.5973 - val_mae: 774.7058\n",
      "Epoch 492/500\n",
      "5966/5966 [==============================] - 0s 25us/step - loss: 1259708.3378 - mae: 781.5862 - val_loss: 1212630.4145 - val_mae: 773.8825\n",
      "Epoch 493/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1240738.9765 - mae: 776.4487 - val_loss: 1234131.1986 - val_mae: 776.3295\n",
      "Epoch 494/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1270548.5102 - mae: 788.0096 - val_loss: 1219478.1683 - val_mae: 776.3827\n",
      "Epoch 495/500\n",
      "5966/5966 [==============================] - 0s 22us/step - loss: 1241490.9236 - mae: 781.1954 - val_loss: 1215372.2957 - val_mae: 775.0596\n",
      "Epoch 496/500\n",
      "5966/5966 [==============================] - 0s 24us/step - loss: 1257056.3145 - mae: 783.6523 - val_loss: 1216230.8576 - val_mae: 773.9686\n",
      "Epoch 497/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1245609.7679 - mae: 780.4023 - val_loss: 1222051.5894 - val_mae: 775.3793\n",
      "Epoch 498/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1258293.0091 - mae: 782.2729 - val_loss: 1209856.1847 - val_mae: 773.8288\n",
      "Epoch 499/500\n",
      "5966/5966 [==============================] - 0s 23us/step - loss: 1266198.6591 - mae: 786.7935 - val_loss: 1211938.2602 - val_mae: 773.8077\n",
      "Epoch 500/500\n",
      "5966/5966 [==============================] - 0s 21us/step - loss: 1257344.4313 - mae: 785.8405 - val_loss: 1228945.7569 - val_mae: 776.3334\n"
     ]
    }
   ],
   "source": [
    "# removing history from memory\n",
    "#del history\n",
    "# training the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=1024,validation_data =(X_test,y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:15:34.566931Z",
     "start_time": "2020-12-05T20:15:34.372980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070.2234949921694\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:15:48.413682Z",
     "start_time": "2020-12-05T20:15:48.187822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5966/5966 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1145378.327103587, 739.8389282226562]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:00.307734Z",
     "start_time": "2020-12-05T20:15:59.966626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1764bc71788>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, 500)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "#plt.figure(figure)\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"mae\"], label=\"train_MAE\")\n",
    "plt.plot(N, history.history[\"val_mae\"], label=\"val_MAE\")\n",
    "plt.title(\"Training Loss and Mean Absolute Error on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/MAE\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "#plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:05.379414Z",
     "start_time": "2020-12-05T20:16:05.359427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the same transformations to test dataset\n",
    "# Outlet_Establishment_year does not carry any significance so adding the age of Outlet\n",
    "# adding extra feature of Outlet_Age = max(Outlet_Establishment_Year)-(Outlet_Establishment_year)\n",
    "test['Outlet_Age']=test['Outlet_Establishment_Year'].max() - test['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:06.500444Z",
     "start_time": "2020-12-05T20:16:06.481457Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = test[['Item_Identifier','Outlet_Identifier']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:07.814596Z",
     "start_time": "2020-12-05T20:16:07.797606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# at first droping item identifier , outlet_identifier , outlet establishment year\n",
    "test = test.drop(['Item_Identifier','Outlet_Identifier','Outlet_Establishment_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:09.285233Z",
     "start_time": "2020-12-05T20:16:09.276237Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Visibility']=test['Item_Visibility'].mask(test['Item_Visibility']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:10.244340Z",
     "start_time": "2020-12-05T20:16:10.229351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight              976\n",
       "Item_Fat_Content           0\n",
       "Item_Visibility          353\n",
       "Item_Type                  0\n",
       "Item_MRP                   0\n",
       "Outlet_Size             1606\n",
       "Outlet_Location_Type       0\n",
       "Outlet_Type                0\n",
       "Outlet_Age                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:11.727453Z",
     "start_time": "2020-12-05T20:16:11.717460Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Item_Weight'].fillna(test['Item_Weight'].mean(),inplace=True)\n",
    "test['Outlet_Size'].fillna(test['Outlet_Size'].mode()[0],inplace=True)\n",
    "test['Item_Visibility'].fillna(test['Item_Visibility'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:12.534365Z",
     "start_time": "2020-12-05T20:16:12.515381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    3396\n",
       "Regular    1935\n",
       "LF          206\n",
       "reg          78\n",
       "low fat      66\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the categorical variables\n",
    "test['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:13.387290Z",
     "start_time": "2020-12-05T20:16:13.375299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unifying categories to Low Fat and Regular only\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace({'reg':'Regular', 'LF':'Low Fat','low fat':'Low Fat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:14.301329Z",
     "start_time": "2020-12-05T20:16:14.249363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Outlet_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>13</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>4</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>11</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>13</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.695633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>4</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  Item_MRP  \\\n",
       "0    20.750000                 0         0.007565         13  107.8622   \n",
       "1     8.300000                 1         0.038428          4   87.3198   \n",
       "2    14.600000                 0         0.099575         11  241.7538   \n",
       "3     7.315000                 0         0.015388         13  155.0340   \n",
       "4    12.695633                 1         0.118599          4  234.2300   \n",
       "\n",
       "   Outlet_Size  Outlet_Location_Type  Outlet_Type  Outlet_Age  \n",
       "0            1                     0            1          10  \n",
       "1            1                     1            1           2  \n",
       "2            1                     2            0          11  \n",
       "3            1                     1            1           2  \n",
       "4            1                     2            3          24  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "test['Item_Fat_Content']=label_encoder.fit_transform(test['Item_Fat_Content']) \n",
    "#,'Item_Type','Outlet_Size','Outlet_Location_Type','Outlet_Type'\n",
    "test['Outlet_Size']=label_encoder.fit_transform(test['Outlet_Size'])\n",
    "test['Outlet_Location_Type']=label_encoder.fit_transform(test['Outlet_Location_Type'])\n",
    "test['Outlet_Type']=label_encoder.fit_transform(test['Outlet_Type'])\n",
    "test['Item_Type']=label_encoder.fit_transform(test['Item_Type'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:15.323506Z",
     "start_time": "2020-12-05T20:16:15.306513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96427508, 0.        , 0.01241517, 0.86666667, 0.32341312,\n",
       "        0.5       , 0.        , 0.33333333, 0.41666667],\n",
       "       [0.22298303, 1.        , 0.10884773, 0.26666667, 0.23584901,\n",
       "        0.5       , 0.5       , 0.33333333, 0.08333333],\n",
       "       [0.59809467, 0.        , 0.29990547, 0.73333333, 0.89413994,\n",
       "        0.5       , 1.        , 0.        , 0.45833333],\n",
       "       [0.16433462, 0.        , 0.03686028, 0.86666667, 0.52448781,\n",
       "        0.5       , 0.5       , 0.33333333, 0.08333333],\n",
       "       [0.48470577, 1.        , 0.35934822, 0.26666667, 0.86206897,\n",
       "        0.5       , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing the test from 0 to 1 using MinMaxScalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler=MinMaxScaler()\n",
    "test=min_max_scaler.fit_transform(test)\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:16.610158Z",
     "start_time": "2020-12-05T20:16:16.466207Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:18.140218Z",
     "start_time": "2020-12-05T20:16:18.117234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1671.079834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1391.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>631.308472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2471.795898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5553.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2295.564453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2407.322021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1518.888306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3412.813721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>924.115967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1671.079834\n",
       "1              FDW14            OUT017        1391.820312\n",
       "2              NCN55            OUT010         631.308472\n",
       "3              FDQ58            OUT017        2471.795898\n",
       "4              FDY38            OUT027        5553.149414\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2295.564453\n",
       "5677           FDD47            OUT018        2407.322021\n",
       "5678           NCO17            OUT045        1518.888306\n",
       "5679           FDJ26            OUT017        3412.813721\n",
       "5680           FDU37            OUT045         924.115967\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Item_Outlet_Sales']=predictions\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T20:16:27.184249Z",
     "start_time": "2020-12-05T20:16:27.145272Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
